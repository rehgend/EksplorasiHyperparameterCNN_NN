{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas 1B - Regresi Boston Housing Price dengan ANN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjJtCrfLqQeX3/oMHNYbw8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rehgend/EksplorasiHyperparameterCNN_NN/blob/main/Tugas%201B%20-%20Regresi%20Boston%20Housing%20Price%20dengan%20ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<center>Tugas 1B - Regresi Boston Housing Price dengan ANN**\n",
        "### **<center>Rahman Indra Kesuma - 33221026**\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "E2I4juaQUAxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tahapan 1.**\n",
        "Memuat library yang dibutuhkan dalam pemrosesan data hingga proses pembelajaran pada Dataset *Boston Housing Price* dengan menggunakan algoritma Artificial Neural Network."
      ],
      "metadata": {
        "id": "Bzf5YlkO0XJr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oK3Jrk06T4Jo"
      },
      "outputs": [],
      "source": [
        "# Library untuk kebutuhan pengaksesan dan pemrosesan awal data\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Library yang digunakan untuk membuat model dengan arsitektur ANN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "\n",
        "# Library yang digunakan untuk optimizer yang digunakan\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Library untuk melakukan plotting terhasil hasil yang diperoleh\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from  matplotlib.colors import LinearSegmentedColormap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tahapan 2.**\n",
        "Memuat dataset *Boston Housing Price* dari Keras Built-In Small Dataset sekaligus melakukan slip kembali untuk membagi testing data dan validation data, dan ditambilkan ukuran data dari tiap-tiap kategori."
      ],
      "metadata": {
        "id": "Veg52NBA1Ffs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_remaining, y_remaining) = boston_housing.load_data(path=\"boston_housing.npz\", test_split=0.3, seed=113)\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_remaining, y_remaining, test_size=0.5)\n",
        "\n",
        "print(\"Ukuran Training Data -> \", len(x_train), \"( Max_y : \",max(y_train),\" & Min_y : \",min(y_train),\")\")\n",
        "print(\"Ukuran Validation Data -> \", len(x_valid), \"( Max_y : \",max(y_valid),\" & Min_y : \",min(y_valid),\")\")\n",
        "print(\"Ukuran Testing Data -> \", len(x_test), \"( Max_y : \",max(y_test),\" & Min_y : \",min(y_test),\")\")\n",
        "print(\"TOTAL DATA = \", len(x_train)+len(x_valid)+len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrbsSlP01d7u",
        "outputId": "5c7cc625-23e5-4b50-9c21-f3e79f37ce33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n",
            "Ukuran Training Data ->  354 ( Max_y :  50.0  & Min_y :  5.0 )\n",
            "Ukuran Validation Data ->  76 ( Max_y :  50.0  & Min_y :  7.0 )\n",
            "Ukuran Testing Data ->  76 ( Max_y :  50.0  & Min_y :  5.6 )\n",
            "TOTAL DATA =  506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tahapan 3**.\n",
        "Pendefinisian fungsi untuk membentuk arsitektur ANN dengan parameter yang berubah yaitu:\n",
        "1.   Jumlah Hidden Layer (*NumHiddenLayer*)\n",
        "2.   Jumlah Hidden Neuron Per-Layer (*NumHiddenNeuronPerLayer*)\n",
        "3.   Activation Function Per-Layer (*ActivationFuncPerLayer*)\n"
      ],
      "metadata": {
        "id": "4yXxJOUv466a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ann_model(NumHiddenLayer, NumHiddenNeuronPerLayer, ActivationFuncPerLayer):\n",
        "  ann_model = Sequential()\n",
        "  ann_model.add(Flatten())\n",
        "\n",
        "  # Pendefinisian pada Hidden Layer\n",
        "  for idx_layer in range(NumHiddenLayer):\n",
        "    ann_model.add(Dense(NumHiddenNeuronPerLayer[idx_layer], activation=ActivationFuncPerLayer[idx_layer]))\n",
        "    \n",
        "  #Pendefinisian pada Outlut Layer\n",
        "  ann_model.add(Dense(1, activation=ActivationFuncPerLayer[NumHiddenLayer]))\n",
        "  \n",
        "  return ann_model"
      ],
      "metadata": {
        "id": "5PRCUW115omm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tahapan 4**.\n",
        "Percobaan dalam pembentukan regression model dengan Base Model."
      ],
      "metadata": {
        "id": "lw7NP1iKFswe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Nilai Dasar NumHiddenLayer = 1\n",
        "#Nilai Dasar NumHiddenNeuronPerLayer = [128, ]\n",
        "#Nilai Dasar ActivationFuncPerLayer = ['sigmoid', 'relu']\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 100\n",
        "Label_Epochs = []\n",
        "for i in range(EPOCHS):\n",
        "  Label_Epochs.append(i+1)\n",
        "\n",
        "NumHiddenLayer = 1\n",
        "NumHiddenNeuronPerLayer = [128]\n",
        "ActivationFuncPerLayer = ['sigmoid','relu']\n",
        "\n",
        "opt = RMSprop(learning_rate=0.001)\n",
        "\n",
        "model_percobaan1 = build_ann_model(NumHiddenLayer, NumHiddenNeuronPerLayer, ActivationFuncPerLayer)\n",
        "model_percobaan1.build((None, 13))\n",
        "model_percobaan1.compile(optimizer=opt, loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
        "model_percobaan1.summary()\n",
        "History_Base_Training = model_percobaan1.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "\n",
        "# Ploting Hasil Penggunaan dari Kullback-Leibler Divergence Function\n",
        "plt.rcParams['figure.figsize'] = (6.0, 5.0)\n",
        "plt.plot(Label_Epochs, History_Base_Training.history['mean_absolute_error'])\n",
        "plt.plot(Label_Epochs, History_Base_Training.history['val_mean_absolute_error'])\n",
        "plt.title('Base Model - Accuracy')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.savefig('BaseModel-Accuracy.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PtTj9wgCF6DI",
        "outputId": "428ca351-a359-4131-b4f9-cffe6b7b9c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,921\n",
            "Trainable params: 1,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 57s 8s/step - loss: 20.1234 - mean_absolute_error: 20.1234 - val_loss: 18.9507 - val_mean_absolute_error: 18.9507\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.8540 - mean_absolute_error: 18.8540 - val_loss: 17.8941 - val_mean_absolute_error: 17.8941\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.8391 - mean_absolute_error: 17.8391 - val_loss: 16.9371 - val_mean_absolute_error: 16.9371\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.9360 - mean_absolute_error: 16.9360 - val_loss: 16.1450 - val_mean_absolute_error: 16.1450\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.1524 - mean_absolute_error: 16.1524 - val_loss: 15.4149 - val_mean_absolute_error: 15.4149\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 15.3748 - mean_absolute_error: 15.3748 - val_loss: 14.6866 - val_mean_absolute_error: 14.6866\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.6000 - mean_absolute_error: 14.6000 - val_loss: 13.9814 - val_mean_absolute_error: 13.9814\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.8801 - mean_absolute_error: 13.8801 - val_loss: 13.3403 - val_mean_absolute_error: 13.3403\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.2052 - mean_absolute_error: 13.2052 - val_loss: 12.7250 - val_mean_absolute_error: 12.7250\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.5601 - mean_absolute_error: 12.5601 - val_loss: 12.1341 - val_mean_absolute_error: 12.1341\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.8663 - mean_absolute_error: 11.8663 - val_loss: 11.5528 - val_mean_absolute_error: 11.5528\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.2515 - mean_absolute_error: 11.2515 - val_loss: 11.0440 - val_mean_absolute_error: 11.0440\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.6824 - mean_absolute_error: 10.6824 - val_loss: 10.5569 - val_mean_absolute_error: 10.5569\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.1661 - mean_absolute_error: 10.1661 - val_loss: 10.1084 - val_mean_absolute_error: 10.1084\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.6838 - mean_absolute_error: 9.6838 - val_loss: 9.6538 - val_mean_absolute_error: 9.6538\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.2147 - mean_absolute_error: 9.2147 - val_loss: 9.2531 - val_mean_absolute_error: 9.2531\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8083 - mean_absolute_error: 8.8083 - val_loss: 8.9215 - val_mean_absolute_error: 8.9215\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4499 - mean_absolute_error: 8.4499 - val_loss: 8.5609 - val_mean_absolute_error: 8.5609\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0860 - mean_absolute_error: 8.0860 - val_loss: 8.3128 - val_mean_absolute_error: 8.3128\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8282 - mean_absolute_error: 7.8282 - val_loss: 7.9746 - val_mean_absolute_error: 7.9746\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5009 - mean_absolute_error: 7.5009 - val_loss: 7.7198 - val_mean_absolute_error: 7.7198\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2484 - mean_absolute_error: 7.2484 - val_loss: 7.4395 - val_mean_absolute_error: 7.4395\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.0090 - mean_absolute_error: 7.0090 - val_loss: 7.1485 - val_mean_absolute_error: 7.1485\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7602 - mean_absolute_error: 6.7602 - val_loss: 6.8452 - val_mean_absolute_error: 6.8452\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5440 - mean_absolute_error: 6.5440 - val_loss: 6.6574 - val_mean_absolute_error: 6.6574\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4040 - mean_absolute_error: 6.4040 - val_loss: 6.4748 - val_mean_absolute_error: 6.4748\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2681 - mean_absolute_error: 6.2681 - val_loss: 6.3414 - val_mean_absolute_error: 6.3414\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1901 - mean_absolute_error: 6.1901 - val_loss: 6.2142 - val_mean_absolute_error: 6.2142\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1095 - mean_absolute_error: 6.1095 - val_loss: 6.1380 - val_mean_absolute_error: 6.1380\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0705 - mean_absolute_error: 6.0705 - val_loss: 6.0029 - val_mean_absolute_error: 6.0029\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.0286 - mean_absolute_error: 6.0286 - val_loss: 5.9663 - val_mean_absolute_error: 5.9663\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0083 - mean_absolute_error: 6.0083 - val_loss: 5.9527 - val_mean_absolute_error: 5.9527\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9705 - mean_absolute_error: 5.9705 - val_loss: 5.9529 - val_mean_absolute_error: 5.9529\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9331 - mean_absolute_error: 5.9331 - val_loss: 5.8496 - val_mean_absolute_error: 5.8496\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8990 - mean_absolute_error: 5.8990 - val_loss: 5.8651 - val_mean_absolute_error: 5.8651\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8431 - mean_absolute_error: 5.8431 - val_loss: 5.8390 - val_mean_absolute_error: 5.8390\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7854 - mean_absolute_error: 5.7854 - val_loss: 5.7164 - val_mean_absolute_error: 5.7164\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7457 - mean_absolute_error: 5.7457 - val_loss: 5.6740 - val_mean_absolute_error: 5.6740\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6986 - mean_absolute_error: 5.6986 - val_loss: 5.6746 - val_mean_absolute_error: 5.6746\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6707 - mean_absolute_error: 5.6707 - val_loss: 5.6108 - val_mean_absolute_error: 5.6108\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6417 - mean_absolute_error: 5.6417 - val_loss: 5.6245 - val_mean_absolute_error: 5.6245\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6281 - mean_absolute_error: 5.6281 - val_loss: 5.5990 - val_mean_absolute_error: 5.5990\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6080 - mean_absolute_error: 5.6080 - val_loss: 5.5701 - val_mean_absolute_error: 5.5701\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5963 - mean_absolute_error: 5.5963 - val_loss: 5.6412 - val_mean_absolute_error: 5.6412\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5801 - mean_absolute_error: 5.5801 - val_loss: 5.6247 - val_mean_absolute_error: 5.6247\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5607 - mean_absolute_error: 5.5607 - val_loss: 5.6008 - val_mean_absolute_error: 5.6008\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5481 - mean_absolute_error: 5.5481 - val_loss: 5.5811 - val_mean_absolute_error: 5.5811\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5345 - mean_absolute_error: 5.5345 - val_loss: 5.5205 - val_mean_absolute_error: 5.5205\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5202 - mean_absolute_error: 5.5202 - val_loss: 5.5058 - val_mean_absolute_error: 5.5058\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5059 - mean_absolute_error: 5.5059 - val_loss: 5.5674 - val_mean_absolute_error: 5.5674\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4992 - mean_absolute_error: 5.4992 - val_loss: 5.5092 - val_mean_absolute_error: 5.5092\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4841 - mean_absolute_error: 5.4841 - val_loss: 5.5001 - val_mean_absolute_error: 5.5001\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4839 - mean_absolute_error: 5.4839 - val_loss: 5.5016 - val_mean_absolute_error: 5.5016\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4695 - mean_absolute_error: 5.4695 - val_loss: 5.4599 - val_mean_absolute_error: 5.4599\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4485 - mean_absolute_error: 5.4485 - val_loss: 5.4184 - val_mean_absolute_error: 5.4184\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4394 - mean_absolute_error: 5.4394 - val_loss: 5.4734 - val_mean_absolute_error: 5.4734\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4039 - mean_absolute_error: 5.4039 - val_loss: 5.4700 - val_mean_absolute_error: 5.4700\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3962 - mean_absolute_error: 5.3962 - val_loss: 5.4767 - val_mean_absolute_error: 5.4767\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.3749 - mean_absolute_error: 5.3749 - val_loss: 5.4609 - val_mean_absolute_error: 5.4609\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3610 - mean_absolute_error: 5.3610 - val_loss: 5.4164 - val_mean_absolute_error: 5.4164\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3467 - mean_absolute_error: 5.3467 - val_loss: 5.5087 - val_mean_absolute_error: 5.5087\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3443 - mean_absolute_error: 5.3443 - val_loss: 5.4103 - val_mean_absolute_error: 5.4103\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3335 - mean_absolute_error: 5.3335 - val_loss: 5.4012 - val_mean_absolute_error: 5.4012\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3107 - mean_absolute_error: 5.3107 - val_loss: 5.3874 - val_mean_absolute_error: 5.3874\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3113 - mean_absolute_error: 5.3113 - val_loss: 5.4343 - val_mean_absolute_error: 5.4343\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2894 - mean_absolute_error: 5.2894 - val_loss: 5.3075 - val_mean_absolute_error: 5.3075\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2749 - mean_absolute_error: 5.2749 - val_loss: 5.2713 - val_mean_absolute_error: 5.2713\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2714 - mean_absolute_error: 5.2714 - val_loss: 5.2521 - val_mean_absolute_error: 5.2521\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2679 - mean_absolute_error: 5.2679 - val_loss: 5.2946 - val_mean_absolute_error: 5.2946\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2480 - mean_absolute_error: 5.2480 - val_loss: 5.3203 - val_mean_absolute_error: 5.3203\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2393 - mean_absolute_error: 5.2393 - val_loss: 5.3726 - val_mean_absolute_error: 5.3726\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2406 - mean_absolute_error: 5.2406 - val_loss: 5.2437 - val_mean_absolute_error: 5.2437\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2251 - mean_absolute_error: 5.2251 - val_loss: 5.2283 - val_mean_absolute_error: 5.2283\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2096 - mean_absolute_error: 5.2096 - val_loss: 5.2687 - val_mean_absolute_error: 5.2687\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1975 - mean_absolute_error: 5.1975 - val_loss: 5.2741 - val_mean_absolute_error: 5.2741\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1927 - mean_absolute_error: 5.1927 - val_loss: 5.2392 - val_mean_absolute_error: 5.2392\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1932 - mean_absolute_error: 5.1932 - val_loss: 5.1928 - val_mean_absolute_error: 5.1928\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1778 - mean_absolute_error: 5.1778 - val_loss: 5.2967 - val_mean_absolute_error: 5.2967\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1744 - mean_absolute_error: 5.1744 - val_loss: 5.1746 - val_mean_absolute_error: 5.1746\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1730 - mean_absolute_error: 5.1730 - val_loss: 5.1503 - val_mean_absolute_error: 5.1503\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1713 - mean_absolute_error: 5.1713 - val_loss: 5.2248 - val_mean_absolute_error: 5.2248\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1531 - mean_absolute_error: 5.1531 - val_loss: 5.1784 - val_mean_absolute_error: 5.1784\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.1784 - mean_absolute_error: 5.1784 - val_loss: 5.1357 - val_mean_absolute_error: 5.1357\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1333 - mean_absolute_error: 5.1333 - val_loss: 5.2952 - val_mean_absolute_error: 5.2952\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1380 - mean_absolute_error: 5.1380 - val_loss: 5.2667 - val_mean_absolute_error: 5.2667\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1258 - mean_absolute_error: 5.1258 - val_loss: 5.1937 - val_mean_absolute_error: 5.1937\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1280 - mean_absolute_error: 5.1280 - val_loss: 5.1174 - val_mean_absolute_error: 5.1174\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1351 - mean_absolute_error: 5.1351 - val_loss: 5.1625 - val_mean_absolute_error: 5.1625\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0984 - mean_absolute_error: 5.0984 - val_loss: 5.3069 - val_mean_absolute_error: 5.3069\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1273 - mean_absolute_error: 5.1273 - val_loss: 5.2294 - val_mean_absolute_error: 5.2294\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0970 - mean_absolute_error: 5.0970 - val_loss: 5.1185 - val_mean_absolute_error: 5.1185\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0860 - mean_absolute_error: 5.0860 - val_loss: 5.0972 - val_mean_absolute_error: 5.0972\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0710 - mean_absolute_error: 5.0710 - val_loss: 5.0534 - val_mean_absolute_error: 5.0534\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0865 - mean_absolute_error: 5.0865 - val_loss: 5.2376 - val_mean_absolute_error: 5.2376\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0675 - mean_absolute_error: 5.0675 - val_loss: 5.1794 - val_mean_absolute_error: 5.1794\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0497 - mean_absolute_error: 5.0497 - val_loss: 5.1023 - val_mean_absolute_error: 5.1023\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0325 - mean_absolute_error: 5.0325 - val_loss: 5.1701 - val_mean_absolute_error: 5.1701\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0424 - mean_absolute_error: 5.0424 - val_loss: 5.1562 - val_mean_absolute_error: 5.1562\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0333 - mean_absolute_error: 5.0333 - val_loss: 5.0674 - val_mean_absolute_error: 5.0674\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0327 - mean_absolute_error: 5.0327 - val_loss: 5.0409 - val_mean_absolute_error: 5.0409\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tahapan 5**.\n",
        "Percobaan ke-2 dilakukan untuk mencari jumlah hidden layer terbaik (1-5 hidden layer) dalam regression model dengan tahapan dimana setiap hidden layer memiliki 128 neuron dan menggunaan fungsi aktifasi Sigmoid"
      ],
      "metadata": {
        "id": "xxSntmvBJktl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Nilai Pencarian NumHiddenLayer = 1, 2, 3, 4, 5\n",
        "#Nilai Dasar NumHiddenNeuronPerLayer = [128, ..., 128]\n",
        "#Nilai Dasar ActivationFuncPerLayer = ['sigmoid', ..., 'sigmoid', 'relu']\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 80\n",
        "opt = RMSprop(learning_rate=0.001)\n",
        "History_NumHiddenLayer_Training = []\n",
        "\n",
        "for JumHiddenLayer in range(5) :\n",
        "  NumHiddenLayer = JumHiddenLayer+1 # Karena looping JumHiddenLayer dimulai dari 0  \n",
        "\n",
        "  # Pendefinisian Jumlah Hidden Neuron pada Setiap Layer dengan 128\n",
        "  NumHiddenNeuronPerLayer = []\n",
        "  for idx in range(NumHiddenLayer) :\n",
        "    NumHiddenNeuronPerLayer.append(128)\n",
        "\n",
        "  # Pendefinisian Fungsi Aktifasi Sigmoid di Hidden Layer dan Relu pada Output Layer\n",
        "  ActivationFuncPerLayer = []\n",
        "  for idx in range(NumHiddenLayer) :\n",
        "    ActivationFuncPerLayer.append('sigmoid')\n",
        "  ActivationFuncPerLayer.append('relu')\n",
        "\n",
        "  model_percobaan2 = build_ann_model(NumHiddenLayer, NumHiddenNeuronPerLayer, ActivationFuncPerLayer)\n",
        "  model_percobaan2.build((None, 13))\n",
        "  model_percobaan2.compile(optimizer=opt, loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
        "  model_percobaan2.summary()\n",
        "  Temp_Hasil = model_percobaan2.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "  History_NumHiddenLayer_Training.append(Temp_Hasil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3ziq8MYRkvu",
        "outputId": "ef187fdb-5992-486c-c9ed-0f99a7b71672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_20 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,921\n",
            "Trainable params: 1,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 22ms/step - loss: 21.7202 - mean_absolute_error: 21.7202 - val_loss: 21.2723 - val_mean_absolute_error: 21.2723\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 19.7992 - mean_absolute_error: 19.7992 - val_loss: 19.6468 - val_mean_absolute_error: 19.6468\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.4774 - mean_absolute_error: 18.4774 - val_loss: 18.5838 - val_mean_absolute_error: 18.5838\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.4524 - mean_absolute_error: 17.4524 - val_loss: 17.5208 - val_mean_absolute_error: 17.5208\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.4621 - mean_absolute_error: 16.4621 - val_loss: 16.6153 - val_mean_absolute_error: 16.6153\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 15.6229 - mean_absolute_error: 15.6229 - val_loss: 15.7816 - val_mean_absolute_error: 15.7816\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.7426 - mean_absolute_error: 14.7426 - val_loss: 14.8621 - val_mean_absolute_error: 14.8621\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.8398 - mean_absolute_error: 13.8398 - val_loss: 14.0762 - val_mean_absolute_error: 14.0762\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.1013 - mean_absolute_error: 13.1013 - val_loss: 13.4075 - val_mean_absolute_error: 13.4075\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.4244 - mean_absolute_error: 12.4244 - val_loss: 12.7765 - val_mean_absolute_error: 12.7765\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.8026 - mean_absolute_error: 11.8026 - val_loss: 12.1457 - val_mean_absolute_error: 12.1457\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.1977 - mean_absolute_error: 11.1977 - val_loss: 11.5370 - val_mean_absolute_error: 11.5370\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.5986 - mean_absolute_error: 10.5986 - val_loss: 10.9313 - val_mean_absolute_error: 10.9313\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.0523 - mean_absolute_error: 10.0523 - val_loss: 10.3414 - val_mean_absolute_error: 10.3414\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.5428 - mean_absolute_error: 9.5428 - val_loss: 9.8106 - val_mean_absolute_error: 9.8106\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.0798 - mean_absolute_error: 9.0798 - val_loss: 9.3066 - val_mean_absolute_error: 9.3066\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.6583 - mean_absolute_error: 8.6583 - val_loss: 8.8736 - val_mean_absolute_error: 8.8736\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.2822 - mean_absolute_error: 8.2822 - val_loss: 8.4019 - val_mean_absolute_error: 8.4019\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9058 - mean_absolute_error: 7.9058 - val_loss: 8.0127 - val_mean_absolute_error: 8.0127\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5860 - mean_absolute_error: 7.5860 - val_loss: 7.6570 - val_mean_absolute_error: 7.6570\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.2889 - mean_absolute_error: 7.2889 - val_loss: 7.3223 - val_mean_absolute_error: 7.3223\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.0075 - mean_absolute_error: 7.0075 - val_loss: 6.9930 - val_mean_absolute_error: 6.9930\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7497 - mean_absolute_error: 6.7497 - val_loss: 6.6273 - val_mean_absolute_error: 6.6273\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5171 - mean_absolute_error: 6.5171 - val_loss: 6.4694 - val_mean_absolute_error: 6.4694\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3786 - mean_absolute_error: 6.3786 - val_loss: 6.2192 - val_mean_absolute_error: 6.2192\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2217 - mean_absolute_error: 6.2217 - val_loss: 6.0001 - val_mean_absolute_error: 6.0001\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0865 - mean_absolute_error: 6.0865 - val_loss: 5.9157 - val_mean_absolute_error: 5.9157\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9915 - mean_absolute_error: 5.9915 - val_loss: 5.7326 - val_mean_absolute_error: 5.7326\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9068 - mean_absolute_error: 5.9068 - val_loss: 5.6624 - val_mean_absolute_error: 5.6624\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8496 - mean_absolute_error: 5.8496 - val_loss: 5.6192 - val_mean_absolute_error: 5.6192\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7798 - mean_absolute_error: 5.7798 - val_loss: 5.5879 - val_mean_absolute_error: 5.5879\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7173 - mean_absolute_error: 5.7173 - val_loss: 5.4528 - val_mean_absolute_error: 5.4528\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6588 - mean_absolute_error: 5.6588 - val_loss: 5.3695 - val_mean_absolute_error: 5.3695\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6381 - mean_absolute_error: 5.6381 - val_loss: 5.3675 - val_mean_absolute_error: 5.3675\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6085 - mean_absolute_error: 5.6085 - val_loss: 5.4380 - val_mean_absolute_error: 5.4380\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5765 - mean_absolute_error: 5.5765 - val_loss: 5.4429 - val_mean_absolute_error: 5.4429\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5443 - mean_absolute_error: 5.5443 - val_loss: 5.3243 - val_mean_absolute_error: 5.3243\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5283 - mean_absolute_error: 5.5283 - val_loss: 5.3199 - val_mean_absolute_error: 5.3199\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4789 - mean_absolute_error: 5.4789 - val_loss: 5.2438 - val_mean_absolute_error: 5.2438\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4573 - mean_absolute_error: 5.4573 - val_loss: 5.2673 - val_mean_absolute_error: 5.2673\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4417 - mean_absolute_error: 5.4417 - val_loss: 5.2527 - val_mean_absolute_error: 5.2527\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4368 - mean_absolute_error: 5.4368 - val_loss: 5.1686 - val_mean_absolute_error: 5.1686\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4173 - mean_absolute_error: 5.4173 - val_loss: 5.3021 - val_mean_absolute_error: 5.3021\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4050 - mean_absolute_error: 5.4050 - val_loss: 5.2911 - val_mean_absolute_error: 5.2911\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3815 - mean_absolute_error: 5.3815 - val_loss: 5.1667 - val_mean_absolute_error: 5.1667\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3579 - mean_absolute_error: 5.3579 - val_loss: 5.1604 - val_mean_absolute_error: 5.1604\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3458 - mean_absolute_error: 5.3458 - val_loss: 5.1092 - val_mean_absolute_error: 5.1092\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3387 - mean_absolute_error: 5.3387 - val_loss: 5.1747 - val_mean_absolute_error: 5.1747\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3188 - mean_absolute_error: 5.3188 - val_loss: 5.2118 - val_mean_absolute_error: 5.2118\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2960 - mean_absolute_error: 5.2960 - val_loss: 5.1734 - val_mean_absolute_error: 5.1734\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2758 - mean_absolute_error: 5.2758 - val_loss: 5.0950 - val_mean_absolute_error: 5.0950\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2656 - mean_absolute_error: 5.2656 - val_loss: 5.1954 - val_mean_absolute_error: 5.1954\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2492 - mean_absolute_error: 5.2492 - val_loss: 5.1970 - val_mean_absolute_error: 5.1970\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2267 - mean_absolute_error: 5.2267 - val_loss: 5.1486 - val_mean_absolute_error: 5.1486\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2129 - mean_absolute_error: 5.2129 - val_loss: 5.1495 - val_mean_absolute_error: 5.1495\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1982 - mean_absolute_error: 5.1982 - val_loss: 5.1437 - val_mean_absolute_error: 5.1437\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1754 - mean_absolute_error: 5.1754 - val_loss: 5.2339 - val_mean_absolute_error: 5.2339\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1650 - mean_absolute_error: 5.1650 - val_loss: 5.2949 - val_mean_absolute_error: 5.2949\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1533 - mean_absolute_error: 5.1533 - val_loss: 5.1685 - val_mean_absolute_error: 5.1685\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1279 - mean_absolute_error: 5.1279 - val_loss: 5.2901 - val_mean_absolute_error: 5.2901\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1411 - mean_absolute_error: 5.1411 - val_loss: 5.1976 - val_mean_absolute_error: 5.1976\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1030 - mean_absolute_error: 5.1030 - val_loss: 5.2160 - val_mean_absolute_error: 5.2160\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0819 - mean_absolute_error: 5.0819 - val_loss: 5.2717 - val_mean_absolute_error: 5.2717\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0875 - mean_absolute_error: 5.0875 - val_loss: 5.1449 - val_mean_absolute_error: 5.1449\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0816 - mean_absolute_error: 5.0816 - val_loss: 5.1994 - val_mean_absolute_error: 5.1994\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0707 - mean_absolute_error: 5.0707 - val_loss: 5.2534 - val_mean_absolute_error: 5.2534\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0742 - mean_absolute_error: 5.0742 - val_loss: 5.2667 - val_mean_absolute_error: 5.2667\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0666 - mean_absolute_error: 5.0666 - val_loss: 5.1361 - val_mean_absolute_error: 5.1361\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0263 - mean_absolute_error: 5.0263 - val_loss: 5.1081 - val_mean_absolute_error: 5.1081\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0307 - mean_absolute_error: 5.0307 - val_loss: 5.1600 - val_mean_absolute_error: 5.1600\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0099 - mean_absolute_error: 5.0099 - val_loss: 5.1103 - val_mean_absolute_error: 5.1103\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0038 - mean_absolute_error: 5.0038 - val_loss: 5.2048 - val_mean_absolute_error: 5.2048\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0129 - mean_absolute_error: 5.0129 - val_loss: 5.1648 - val_mean_absolute_error: 5.1648\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9993 - mean_absolute_error: 4.9993 - val_loss: 5.1724 - val_mean_absolute_error: 5.1724\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9953 - mean_absolute_error: 4.9953 - val_loss: 5.2081 - val_mean_absolute_error: 5.2081\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9834 - mean_absolute_error: 4.9834 - val_loss: 5.2114 - val_mean_absolute_error: 5.2114\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9900 - mean_absolute_error: 4.9900 - val_loss: 5.1503 - val_mean_absolute_error: 5.1503\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9670 - mean_absolute_error: 4.9670 - val_loss: 5.0602 - val_mean_absolute_error: 5.0602\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9571 - mean_absolute_error: 4.9571 - val_loss: 5.0812 - val_mean_absolute_error: 5.0812\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9487 - mean_absolute_error: 4.9487 - val_loss: 5.0588 - val_mean_absolute_error: 5.0588\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_21 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,433\n",
            "Trainable params: 18,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 22ms/step - loss: 19.4861 - mean_absolute_error: 19.4861 - val_loss: 18.0084 - val_mean_absolute_error: 18.0084\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.3267 - mean_absolute_error: 16.3267 - val_loss: 15.6523 - val_mean_absolute_error: 15.6523\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.3302 - mean_absolute_error: 14.3302 - val_loss: 14.1776 - val_mean_absolute_error: 14.1776\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.9855 - mean_absolute_error: 12.9855 - val_loss: 13.1762 - val_mean_absolute_error: 13.1762\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.0625 - mean_absolute_error: 12.0625 - val_loss: 12.2458 - val_mean_absolute_error: 12.2458\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.2260 - mean_absolute_error: 11.2260 - val_loss: 11.5283 - val_mean_absolute_error: 11.5283\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.5633 - mean_absolute_error: 10.5633 - val_loss: 10.8498 - val_mean_absolute_error: 10.8498\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.9698 - mean_absolute_error: 9.9698 - val_loss: 10.1846 - val_mean_absolute_error: 10.1846\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.4131 - mean_absolute_error: 9.4131 - val_loss: 9.6398 - val_mean_absolute_error: 9.6398\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.9757 - mean_absolute_error: 8.9757 - val_loss: 9.1259 - val_mean_absolute_error: 9.1259\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.5728 - mean_absolute_error: 8.5728 - val_loss: 8.7486 - val_mean_absolute_error: 8.7486\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2760 - mean_absolute_error: 8.2760 - val_loss: 8.2431 - val_mean_absolute_error: 8.2431\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9140 - mean_absolute_error: 7.9140 - val_loss: 7.8471 - val_mean_absolute_error: 7.8471\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.6138 - mean_absolute_error: 7.6138 - val_loss: 7.5651 - val_mean_absolute_error: 7.5651\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.3937 - mean_absolute_error: 7.3937 - val_loss: 7.2304 - val_mean_absolute_error: 7.2304\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1449 - mean_absolute_error: 7.1449 - val_loss: 6.8492 - val_mean_absolute_error: 6.8492\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8819 - mean_absolute_error: 6.8819 - val_loss: 6.5149 - val_mean_absolute_error: 6.5149\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6218 - mean_absolute_error: 6.6218 - val_loss: 6.2394 - val_mean_absolute_error: 6.2394\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3461 - mean_absolute_error: 6.3461 - val_loss: 6.0866 - val_mean_absolute_error: 6.0866\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1019 - mean_absolute_error: 6.1019 - val_loss: 5.8875 - val_mean_absolute_error: 5.8875\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9572 - mean_absolute_error: 5.9572 - val_loss: 5.9172 - val_mean_absolute_error: 5.9172\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8142 - mean_absolute_error: 5.8142 - val_loss: 5.5254 - val_mean_absolute_error: 5.5254\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7051 - mean_absolute_error: 5.7051 - val_loss: 5.5710 - val_mean_absolute_error: 5.5710\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6159 - mean_absolute_error: 5.6159 - val_loss: 5.6906 - val_mean_absolute_error: 5.6906\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5678 - mean_absolute_error: 5.5678 - val_loss: 5.6040 - val_mean_absolute_error: 5.6040\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4922 - mean_absolute_error: 5.4922 - val_loss: 5.5312 - val_mean_absolute_error: 5.5312\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4389 - mean_absolute_error: 5.4389 - val_loss: 5.3360 - val_mean_absolute_error: 5.3360\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3893 - mean_absolute_error: 5.3893 - val_loss: 5.4596 - val_mean_absolute_error: 5.4596\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3736 - mean_absolute_error: 5.3736 - val_loss: 5.2090 - val_mean_absolute_error: 5.2090\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2878 - mean_absolute_error: 5.2878 - val_loss: 5.6781 - val_mean_absolute_error: 5.6781\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3224 - mean_absolute_error: 5.3224 - val_loss: 5.3121 - val_mean_absolute_error: 5.3121\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2281 - mean_absolute_error: 5.2281 - val_loss: 5.1572 - val_mean_absolute_error: 5.1572\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2096 - mean_absolute_error: 5.2096 - val_loss: 5.5035 - val_mean_absolute_error: 5.5035\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2086 - mean_absolute_error: 5.2086 - val_loss: 5.1061 - val_mean_absolute_error: 5.1061\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1309 - mean_absolute_error: 5.1309 - val_loss: 5.0484 - val_mean_absolute_error: 5.0484\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1330 - mean_absolute_error: 5.1330 - val_loss: 5.3562 - val_mean_absolute_error: 5.3562\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1023 - mean_absolute_error: 5.1023 - val_loss: 5.2102 - val_mean_absolute_error: 5.2102\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0773 - mean_absolute_error: 5.0773 - val_loss: 5.0728 - val_mean_absolute_error: 5.0728\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0331 - mean_absolute_error: 5.0331 - val_loss: 4.9603 - val_mean_absolute_error: 4.9603\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0298 - mean_absolute_error: 5.0298 - val_loss: 5.0342 - val_mean_absolute_error: 5.0342\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9749 - mean_absolute_error: 4.9749 - val_loss: 4.8699 - val_mean_absolute_error: 4.8699\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9641 - mean_absolute_error: 4.9641 - val_loss: 4.8338 - val_mean_absolute_error: 4.8338\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9197 - mean_absolute_error: 4.9197 - val_loss: 5.0033 - val_mean_absolute_error: 5.0033\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9063 - mean_absolute_error: 4.9063 - val_loss: 4.8929 - val_mean_absolute_error: 4.8929\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8652 - mean_absolute_error: 4.8652 - val_loss: 4.7957 - val_mean_absolute_error: 4.7957\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8830 - mean_absolute_error: 4.8830 - val_loss: 4.7884 - val_mean_absolute_error: 4.7884\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8317 - mean_absolute_error: 4.8317 - val_loss: 4.7947 - val_mean_absolute_error: 4.7947\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8010 - mean_absolute_error: 4.8010 - val_loss: 4.8017 - val_mean_absolute_error: 4.8017\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8462 - mean_absolute_error: 4.8462 - val_loss: 4.6929 - val_mean_absolute_error: 4.6929\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7590 - mean_absolute_error: 4.7590 - val_loss: 5.4875 - val_mean_absolute_error: 5.4875\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8919 - mean_absolute_error: 4.8919 - val_loss: 4.7660 - val_mean_absolute_error: 4.7660\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7166 - mean_absolute_error: 4.7166 - val_loss: 4.8167 - val_mean_absolute_error: 4.8167\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7126 - mean_absolute_error: 4.7126 - val_loss: 4.6723 - val_mean_absolute_error: 4.6723\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6913 - mean_absolute_error: 4.6913 - val_loss: 4.9996 - val_mean_absolute_error: 4.9996\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7327 - mean_absolute_error: 4.7327 - val_loss: 5.1203 - val_mean_absolute_error: 5.1203\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7055 - mean_absolute_error: 4.7055 - val_loss: 4.5718 - val_mean_absolute_error: 4.5718\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6302 - mean_absolute_error: 4.6302 - val_loss: 5.2778 - val_mean_absolute_error: 5.2778\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6413 - mean_absolute_error: 4.6413 - val_loss: 4.6917 - val_mean_absolute_error: 4.6917\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5983 - mean_absolute_error: 4.5983 - val_loss: 4.6069 - val_mean_absolute_error: 4.6069\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5750 - mean_absolute_error: 4.5750 - val_loss: 4.8608 - val_mean_absolute_error: 4.8608\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7987 - mean_absolute_error: 4.7987 - val_loss: 4.4961 - val_mean_absolute_error: 4.4961\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4997 - mean_absolute_error: 4.4997 - val_loss: 4.7346 - val_mean_absolute_error: 4.7346\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5169 - mean_absolute_error: 4.5169 - val_loss: 4.6139 - val_mean_absolute_error: 4.6139\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5402 - mean_absolute_error: 4.5402 - val_loss: 4.6151 - val_mean_absolute_error: 4.6151\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4660 - mean_absolute_error: 4.4660 - val_loss: 4.3912 - val_mean_absolute_error: 4.3912\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5040 - mean_absolute_error: 4.5040 - val_loss: 4.7159 - val_mean_absolute_error: 4.7159\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4587 - mean_absolute_error: 4.4587 - val_loss: 4.4184 - val_mean_absolute_error: 4.4184\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4439 - mean_absolute_error: 4.4439 - val_loss: 4.7829 - val_mean_absolute_error: 4.7829\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3637 - mean_absolute_error: 4.3637 - val_loss: 4.6941 - val_mean_absolute_error: 4.6941\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4059 - mean_absolute_error: 4.4059 - val_loss: 4.3380 - val_mean_absolute_error: 4.3380\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3614 - mean_absolute_error: 4.3614 - val_loss: 4.4951 - val_mean_absolute_error: 4.4951\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4434 - mean_absolute_error: 4.4434 - val_loss: 4.2323 - val_mean_absolute_error: 4.2323\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2656 - mean_absolute_error: 4.2656 - val_loss: 5.3955 - val_mean_absolute_error: 5.3955\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5009 - mean_absolute_error: 4.5009 - val_loss: 4.9884 - val_mean_absolute_error: 4.9884\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2972 - mean_absolute_error: 4.2972 - val_loss: 4.4919 - val_mean_absolute_error: 4.4919\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2734 - mean_absolute_error: 4.2734 - val_loss: 4.4682 - val_mean_absolute_error: 4.4682\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2739 - mean_absolute_error: 4.2739 - val_loss: 4.5207 - val_mean_absolute_error: 4.5207\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3449 - mean_absolute_error: 4.3449 - val_loss: 4.6636 - val_mean_absolute_error: 4.6636\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2626 - mean_absolute_error: 4.2626 - val_loss: 5.0341 - val_mean_absolute_error: 5.0341\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2994 - mean_absolute_error: 4.2994 - val_loss: 4.3074 - val_mean_absolute_error: 4.3074\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_22 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,945\n",
            "Trainable params: 34,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 26ms/step - loss: 18.6298 - mean_absolute_error: 18.6298 - val_loss: 16.6874 - val_mean_absolute_error: 16.6874\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.9367 - mean_absolute_error: 14.9367 - val_loss: 14.3051 - val_mean_absolute_error: 14.3051\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.0077 - mean_absolute_error: 13.0077 - val_loss: 12.9625 - val_mean_absolute_error: 12.9625\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.8556 - mean_absolute_error: 11.8556 - val_loss: 12.0361 - val_mean_absolute_error: 12.0361\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.0255 - mean_absolute_error: 11.0255 - val_loss: 11.2668 - val_mean_absolute_error: 11.2668\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.3339 - mean_absolute_error: 10.3339 - val_loss: 10.5528 - val_mean_absolute_error: 10.5528\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7326 - mean_absolute_error: 9.7326 - val_loss: 9.9430 - val_mean_absolute_error: 9.9430\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.2377 - mean_absolute_error: 9.2377 - val_loss: 9.3916 - val_mean_absolute_error: 9.3916\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8064 - mean_absolute_error: 8.8064 - val_loss: 8.8863 - val_mean_absolute_error: 8.8863\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.4211 - mean_absolute_error: 8.4211 - val_loss: 8.4714 - val_mean_absolute_error: 8.4714\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0964 - mean_absolute_error: 8.0964 - val_loss: 8.0463 - val_mean_absolute_error: 8.0463\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7824 - mean_absolute_error: 7.7824 - val_loss: 7.6891 - val_mean_absolute_error: 7.6891\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.5200 - mean_absolute_error: 7.5200 - val_loss: 7.2824 - val_mean_absolute_error: 7.2824\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2483 - mean_absolute_error: 7.2483 - val_loss: 7.0058 - val_mean_absolute_error: 7.0058\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.0800 - mean_absolute_error: 7.0800 - val_loss: 6.7548 - val_mean_absolute_error: 6.7548\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9473 - mean_absolute_error: 6.9473 - val_loss: 6.5657 - val_mean_absolute_error: 6.5657\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8515 - mean_absolute_error: 6.8515 - val_loss: 6.3397 - val_mean_absolute_error: 6.3397\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.7277 - mean_absolute_error: 6.7277 - val_loss: 6.1393 - val_mean_absolute_error: 6.1393\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5626 - mean_absolute_error: 6.5626 - val_loss: 5.9650 - val_mean_absolute_error: 5.9650\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1938 - mean_absolute_error: 6.1938 - val_loss: 6.2552 - val_mean_absolute_error: 6.2552\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9600 - mean_absolute_error: 5.9600 - val_loss: 5.8274 - val_mean_absolute_error: 5.8274\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7682 - mean_absolute_error: 5.7682 - val_loss: 5.7162 - val_mean_absolute_error: 5.7162\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6143 - mean_absolute_error: 5.6143 - val_loss: 5.9728 - val_mean_absolute_error: 5.9728\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5434 - mean_absolute_error: 5.5434 - val_loss: 5.6017 - val_mean_absolute_error: 5.6017\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4246 - mean_absolute_error: 5.4246 - val_loss: 5.3674 - val_mean_absolute_error: 5.3674\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3700 - mean_absolute_error: 5.3700 - val_loss: 5.4316 - val_mean_absolute_error: 5.4316\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3045 - mean_absolute_error: 5.3045 - val_loss: 5.6807 - val_mean_absolute_error: 5.6807\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2472 - mean_absolute_error: 5.2472 - val_loss: 5.2869 - val_mean_absolute_error: 5.2869\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2445 - mean_absolute_error: 5.2445 - val_loss: 5.2143 - val_mean_absolute_error: 5.2143\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1959 - mean_absolute_error: 5.1959 - val_loss: 5.3413 - val_mean_absolute_error: 5.3413\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1420 - mean_absolute_error: 5.1420 - val_loss: 5.5742 - val_mean_absolute_error: 5.5742\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1422 - mean_absolute_error: 5.1422 - val_loss: 5.1888 - val_mean_absolute_error: 5.1888\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0847 - mean_absolute_error: 5.0847 - val_loss: 5.3159 - val_mean_absolute_error: 5.3159\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1002 - mean_absolute_error: 5.1002 - val_loss: 5.2043 - val_mean_absolute_error: 5.2043\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1073 - mean_absolute_error: 5.1073 - val_loss: 5.4950 - val_mean_absolute_error: 5.4950\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0839 - mean_absolute_error: 5.0839 - val_loss: 5.2367 - val_mean_absolute_error: 5.2367\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0431 - mean_absolute_error: 5.0431 - val_loss: 5.2028 - val_mean_absolute_error: 5.2028\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9917 - mean_absolute_error: 4.9917 - val_loss: 5.1516 - val_mean_absolute_error: 5.1516\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9871 - mean_absolute_error: 4.9871 - val_loss: 5.4074 - val_mean_absolute_error: 5.4074\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9234 - mean_absolute_error: 4.9234 - val_loss: 5.0593 - val_mean_absolute_error: 5.0593\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9121 - mean_absolute_error: 4.9121 - val_loss: 4.9453 - val_mean_absolute_error: 4.9453\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8855 - mean_absolute_error: 4.8855 - val_loss: 4.8716 - val_mean_absolute_error: 4.8716\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8878 - mean_absolute_error: 4.8878 - val_loss: 4.9167 - val_mean_absolute_error: 4.9167\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8114 - mean_absolute_error: 4.8114 - val_loss: 4.9404 - val_mean_absolute_error: 4.9404\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7961 - mean_absolute_error: 4.7961 - val_loss: 4.8160 - val_mean_absolute_error: 4.8160\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7807 - mean_absolute_error: 4.7807 - val_loss: 4.9529 - val_mean_absolute_error: 4.9529\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7700 - mean_absolute_error: 4.7700 - val_loss: 4.7610 - val_mean_absolute_error: 4.7610\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7281 - mean_absolute_error: 4.7281 - val_loss: 5.2220 - val_mean_absolute_error: 5.2220\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7449 - mean_absolute_error: 4.7449 - val_loss: 4.8304 - val_mean_absolute_error: 4.8304\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6989 - mean_absolute_error: 4.6989 - val_loss: 4.9140 - val_mean_absolute_error: 4.9140\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6790 - mean_absolute_error: 4.6790 - val_loss: 4.7791 - val_mean_absolute_error: 4.7791\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7241 - mean_absolute_error: 4.7241 - val_loss: 4.7866 - val_mean_absolute_error: 4.7866\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6804 - mean_absolute_error: 4.6804 - val_loss: 4.7461 - val_mean_absolute_error: 4.7461\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6508 - mean_absolute_error: 4.6508 - val_loss: 4.8676 - val_mean_absolute_error: 4.8676\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6417 - mean_absolute_error: 4.6417 - val_loss: 4.8010 - val_mean_absolute_error: 4.8010\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6516 - mean_absolute_error: 4.6516 - val_loss: 5.3674 - val_mean_absolute_error: 5.3674\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6927 - mean_absolute_error: 4.6927 - val_loss: 4.6630 - val_mean_absolute_error: 4.6630\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6634 - mean_absolute_error: 4.6634 - val_loss: 4.9106 - val_mean_absolute_error: 4.9106\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5433 - mean_absolute_error: 4.5433 - val_loss: 4.6303 - val_mean_absolute_error: 4.6303\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5510 - mean_absolute_error: 4.5510 - val_loss: 4.9811 - val_mean_absolute_error: 4.9811\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6333 - mean_absolute_error: 4.6333 - val_loss: 4.9628 - val_mean_absolute_error: 4.9628\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5245 - mean_absolute_error: 4.5245 - val_loss: 4.8548 - val_mean_absolute_error: 4.8548\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5770 - mean_absolute_error: 4.5770 - val_loss: 4.6092 - val_mean_absolute_error: 4.6092\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4968 - mean_absolute_error: 4.4968 - val_loss: 4.6717 - val_mean_absolute_error: 4.6717\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4634 - mean_absolute_error: 4.4634 - val_loss: 4.5622 - val_mean_absolute_error: 4.5622\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.4408 - mean_absolute_error: 4.4408 - val_loss: 5.6013 - val_mean_absolute_error: 5.6013\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5797 - mean_absolute_error: 4.5797 - val_loss: 5.0068 - val_mean_absolute_error: 5.0068\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5709 - mean_absolute_error: 4.5709 - val_loss: 4.4215 - val_mean_absolute_error: 4.4215\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3726 - mean_absolute_error: 4.3726 - val_loss: 4.5345 - val_mean_absolute_error: 4.5345\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3754 - mean_absolute_error: 4.3754 - val_loss: 4.5163 - val_mean_absolute_error: 4.5163\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3565 - mean_absolute_error: 4.3565 - val_loss: 5.9149 - val_mean_absolute_error: 5.9149\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5193 - mean_absolute_error: 4.5193 - val_loss: 4.4429 - val_mean_absolute_error: 4.4429\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3403 - mean_absolute_error: 4.3403 - val_loss: 4.4378 - val_mean_absolute_error: 4.4378\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4263 - mean_absolute_error: 4.4263 - val_loss: 4.3636 - val_mean_absolute_error: 4.3636\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2789 - mean_absolute_error: 4.2789 - val_loss: 4.4387 - val_mean_absolute_error: 4.4387\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2197 - mean_absolute_error: 4.2197 - val_loss: 4.6558 - val_mean_absolute_error: 4.6558\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3331 - mean_absolute_error: 4.3331 - val_loss: 4.4275 - val_mean_absolute_error: 4.4275\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1875 - mean_absolute_error: 4.1875 - val_loss: 4.3158 - val_mean_absolute_error: 4.3158\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2594 - mean_absolute_error: 4.2594 - val_loss: 4.4430 - val_mean_absolute_error: 4.4430\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.2242 - mean_absolute_error: 4.2242 - val_loss: 4.3092 - val_mean_absolute_error: 4.3092\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_23 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,457\n",
            "Trainable params: 51,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 24ms/step - loss: 19.2262 - mean_absolute_error: 19.2262 - val_loss: 17.2387 - val_mean_absolute_error: 17.2387\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.5275 - mean_absolute_error: 15.5275 - val_loss: 14.9787 - val_mean_absolute_error: 14.9787\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13.7313 - mean_absolute_error: 13.7313 - val_loss: 13.7701 - val_mean_absolute_error: 13.7701\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.6725 - mean_absolute_error: 12.6725 - val_loss: 12.8894 - val_mean_absolute_error: 12.8894\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11.8730 - mean_absolute_error: 11.8730 - val_loss: 12.1874 - val_mean_absolute_error: 12.1874\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.2159 - mean_absolute_error: 11.2159 - val_loss: 11.5464 - val_mean_absolute_error: 11.5464\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.6380 - mean_absolute_error: 10.6380 - val_loss: 11.0002 - val_mean_absolute_error: 11.0002\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.1404 - mean_absolute_error: 10.1404 - val_loss: 10.4207 - val_mean_absolute_error: 10.4207\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.6523 - mean_absolute_error: 9.6523 - val_loss: 9.9064 - val_mean_absolute_error: 9.9064\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.2361 - mean_absolute_error: 9.2361 - val_loss: 9.4317 - val_mean_absolute_error: 9.4317\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.8580 - mean_absolute_error: 8.8580 - val_loss: 9.0200 - val_mean_absolute_error: 9.0200\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.5284 - mean_absolute_error: 8.5284 - val_loss: 8.6109 - val_mean_absolute_error: 8.6109\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.2064 - mean_absolute_error: 8.2064 - val_loss: 8.1913 - val_mean_absolute_error: 8.1913\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8981 - mean_absolute_error: 7.8981 - val_loss: 7.7666 - val_mean_absolute_error: 7.7666\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.5981 - mean_absolute_error: 7.5981 - val_loss: 7.4781 - val_mean_absolute_error: 7.4781\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3938 - mean_absolute_error: 7.3938 - val_loss: 7.1356 - val_mean_absolute_error: 7.1356\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1749 - mean_absolute_error: 7.1749 - val_loss: 6.8544 - val_mean_absolute_error: 6.8544\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0009 - mean_absolute_error: 7.0009 - val_loss: 6.5839 - val_mean_absolute_error: 6.5839\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8667 - mean_absolute_error: 6.8667 - val_loss: 6.3080 - val_mean_absolute_error: 6.3080\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7354 - mean_absolute_error: 6.7354 - val_loss: 6.1330 - val_mean_absolute_error: 6.1330\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6849 - mean_absolute_error: 6.6849 - val_loss: 5.9826 - val_mean_absolute_error: 5.9826\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6470 - mean_absolute_error: 6.6470 - val_loss: 5.9370 - val_mean_absolute_error: 5.9370\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6405 - mean_absolute_error: 6.6405 - val_loss: 5.8986 - val_mean_absolute_error: 5.8986\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6278 - mean_absolute_error: 6.6278 - val_loss: 5.9172 - val_mean_absolute_error: 5.9172\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6318 - mean_absolute_error: 6.6318 - val_loss: 5.8920 - val_mean_absolute_error: 5.8920\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6288 - mean_absolute_error: 6.6288 - val_loss: 5.8725 - val_mean_absolute_error: 5.8725\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6110 - mean_absolute_error: 6.6110 - val_loss: 5.8431 - val_mean_absolute_error: 5.8431\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5396 - mean_absolute_error: 6.5396 - val_loss: 5.8805 - val_mean_absolute_error: 5.8805\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3146 - mean_absolute_error: 6.3146 - val_loss: 5.8910 - val_mean_absolute_error: 5.8910\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.0244 - mean_absolute_error: 6.0244 - val_loss: 5.5886 - val_mean_absolute_error: 5.5886\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7894 - mean_absolute_error: 5.7894 - val_loss: 5.5629 - val_mean_absolute_error: 5.5629\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5954 - mean_absolute_error: 5.5954 - val_loss: 5.8347 - val_mean_absolute_error: 5.8347\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4447 - mean_absolute_error: 5.4447 - val_loss: 5.4326 - val_mean_absolute_error: 5.4326\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3388 - mean_absolute_error: 5.3388 - val_loss: 5.3730 - val_mean_absolute_error: 5.3730\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2658 - mean_absolute_error: 5.2658 - val_loss: 5.2852 - val_mean_absolute_error: 5.2852\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2585 - mean_absolute_error: 5.2585 - val_loss: 5.1967 - val_mean_absolute_error: 5.1967\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1939 - mean_absolute_error: 5.1939 - val_loss: 5.6810 - val_mean_absolute_error: 5.6810\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2284 - mean_absolute_error: 5.2284 - val_loss: 5.2454 - val_mean_absolute_error: 5.2454\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0948 - mean_absolute_error: 5.0948 - val_loss: 5.1264 - val_mean_absolute_error: 5.1264\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0700 - mean_absolute_error: 5.0700 - val_loss: 5.3195 - val_mean_absolute_error: 5.3195\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0017 - mean_absolute_error: 5.0017 - val_loss: 5.3554 - val_mean_absolute_error: 5.3554\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0085 - mean_absolute_error: 5.0085 - val_loss: 5.0782 - val_mean_absolute_error: 5.0782\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0161 - mean_absolute_error: 5.0161 - val_loss: 5.9947 - val_mean_absolute_error: 5.9947\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1483 - mean_absolute_error: 5.1483 - val_loss: 5.4300 - val_mean_absolute_error: 5.4300\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9465 - mean_absolute_error: 4.9465 - val_loss: 5.2714 - val_mean_absolute_error: 5.2714\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8738 - mean_absolute_error: 4.8738 - val_loss: 5.7976 - val_mean_absolute_error: 5.7976\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0527 - mean_absolute_error: 5.0527 - val_loss: 4.9363 - val_mean_absolute_error: 4.9363\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8643 - mean_absolute_error: 4.8643 - val_loss: 5.1901 - val_mean_absolute_error: 5.1901\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8805 - mean_absolute_error: 4.8805 - val_loss: 4.9764 - val_mean_absolute_error: 4.9764\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.8792 - mean_absolute_error: 4.8792 - val_loss: 4.9918 - val_mean_absolute_error: 4.9918\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8607 - mean_absolute_error: 4.8607 - val_loss: 4.9045 - val_mean_absolute_error: 4.9045\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7702 - mean_absolute_error: 4.7702 - val_loss: 5.5999 - val_mean_absolute_error: 5.5999\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8209 - mean_absolute_error: 4.8209 - val_loss: 4.9013 - val_mean_absolute_error: 4.9013\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7350 - mean_absolute_error: 4.7350 - val_loss: 4.7484 - val_mean_absolute_error: 4.7484\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7258 - mean_absolute_error: 4.7258 - val_loss: 4.7706 - val_mean_absolute_error: 4.7706\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6867 - mean_absolute_error: 4.6867 - val_loss: 5.1656 - val_mean_absolute_error: 5.1656\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8853 - mean_absolute_error: 4.8853 - val_loss: 5.4996 - val_mean_absolute_error: 5.4996\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8058 - mean_absolute_error: 4.8058 - val_loss: 4.7631 - val_mean_absolute_error: 4.7631\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6696 - mean_absolute_error: 4.6696 - val_loss: 4.7193 - val_mean_absolute_error: 4.7193\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6689 - mean_absolute_error: 4.6689 - val_loss: 4.8173 - val_mean_absolute_error: 4.8173\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6640 - mean_absolute_error: 4.6640 - val_loss: 4.7147 - val_mean_absolute_error: 4.7147\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7115 - mean_absolute_error: 4.7115 - val_loss: 4.9638 - val_mean_absolute_error: 4.9638\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6850 - mean_absolute_error: 4.6850 - val_loss: 4.7084 - val_mean_absolute_error: 4.7084\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6098 - mean_absolute_error: 4.6098 - val_loss: 4.5926 - val_mean_absolute_error: 4.5926\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6305 - mean_absolute_error: 4.6305 - val_loss: 5.2720 - val_mean_absolute_error: 5.2720\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6220 - mean_absolute_error: 4.6220 - val_loss: 5.1320 - val_mean_absolute_error: 5.1320\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7514 - mean_absolute_error: 4.7514 - val_loss: 5.0051 - val_mean_absolute_error: 5.0051\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6095 - mean_absolute_error: 4.6095 - val_loss: 4.5133 - val_mean_absolute_error: 4.5133\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5545 - mean_absolute_error: 4.5545 - val_loss: 5.0047 - val_mean_absolute_error: 5.0047\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7072 - mean_absolute_error: 4.7072 - val_loss: 5.2924 - val_mean_absolute_error: 5.2924\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.5902 - mean_absolute_error: 4.5902 - val_loss: 5.4378 - val_mean_absolute_error: 5.4378\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6525 - mean_absolute_error: 4.6525 - val_loss: 4.8351 - val_mean_absolute_error: 4.8351\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4818 - mean_absolute_error: 4.4818 - val_loss: 4.8121 - val_mean_absolute_error: 4.8121\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.5321 - mean_absolute_error: 4.5321 - val_loss: 4.7499 - val_mean_absolute_error: 4.7499\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5412 - mean_absolute_error: 4.5412 - val_loss: 5.1537 - val_mean_absolute_error: 5.1537\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6912 - mean_absolute_error: 4.6912 - val_loss: 4.4813 - val_mean_absolute_error: 4.4813\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4624 - mean_absolute_error: 4.4624 - val_loss: 4.4159 - val_mean_absolute_error: 4.4159\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3047 - mean_absolute_error: 4.3047 - val_loss: 4.3794 - val_mean_absolute_error: 4.3794\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4734 - mean_absolute_error: 4.4734 - val_loss: 4.3398 - val_mean_absolute_error: 4.3398\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3638 - mean_absolute_error: 4.3638 - val_loss: 4.7219 - val_mean_absolute_error: 4.7219\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_24 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,969\n",
            "Trainable params: 67,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 26ms/step - loss: 19.8941 - mean_absolute_error: 19.8941 - val_loss: 17.9430 - val_mean_absolute_error: 17.9430\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16.3012 - mean_absolute_error: 16.3012 - val_loss: 15.8022 - val_mean_absolute_error: 15.8022\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14.6133 - mean_absolute_error: 14.6133 - val_loss: 14.7147 - val_mean_absolute_error: 14.7147\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 13.6202 - mean_absolute_error: 13.6202 - val_loss: 13.8446 - val_mean_absolute_error: 13.8446\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.8050 - mean_absolute_error: 12.8050 - val_loss: 13.0989 - val_mean_absolute_error: 13.0989\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.1026 - mean_absolute_error: 12.1026 - val_loss: 12.4472 - val_mean_absolute_error: 12.4472\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11.4801 - mean_absolute_error: 11.4801 - val_loss: 11.8717 - val_mean_absolute_error: 11.8717\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.9341 - mean_absolute_error: 10.9341 - val_loss: 11.2739 - val_mean_absolute_error: 11.2739\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.3850 - mean_absolute_error: 10.3850 - val_loss: 10.7099 - val_mean_absolute_error: 10.7099\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.8828 - mean_absolute_error: 9.8828 - val_loss: 10.1356 - val_mean_absolute_error: 10.1356\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9.4142 - mean_absolute_error: 9.4142 - val_loss: 9.6240 - val_mean_absolute_error: 9.6240\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.9984 - mean_absolute_error: 8.9984 - val_loss: 9.1670 - val_mean_absolute_error: 9.1670\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6289 - mean_absolute_error: 8.6289 - val_loss: 8.6787 - val_mean_absolute_error: 8.6787\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.2634 - mean_absolute_error: 8.2634 - val_loss: 8.2345 - val_mean_absolute_error: 8.2345\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.9359 - mean_absolute_error: 7.9359 - val_loss: 7.8219 - val_mean_absolute_error: 7.8219\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.6362 - mean_absolute_error: 7.6362 - val_loss: 7.4797 - val_mean_absolute_error: 7.4797\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.4006 - mean_absolute_error: 7.4006 - val_loss: 7.1601 - val_mean_absolute_error: 7.1601\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.1919 - mean_absolute_error: 7.1919 - val_loss: 6.8407 - val_mean_absolute_error: 6.8407\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.9998 - mean_absolute_error: 6.9998 - val_loss: 6.5024 - val_mean_absolute_error: 6.5024\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.8368 - mean_absolute_error: 6.8368 - val_loss: 6.3281 - val_mean_absolute_error: 6.3281\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7426 - mean_absolute_error: 6.7426 - val_loss: 6.1959 - val_mean_absolute_error: 6.1959\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.7005 - mean_absolute_error: 6.7005 - val_loss: 6.0603 - val_mean_absolute_error: 6.0603\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.6591 - mean_absolute_error: 6.6591 - val_loss: 5.8934 - val_mean_absolute_error: 5.8934\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6274 - mean_absolute_error: 6.6274 - val_loss: 5.8299 - val_mean_absolute_error: 5.8299\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6246 - mean_absolute_error: 6.6246 - val_loss: 5.8053 - val_mean_absolute_error: 5.8053\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6256 - mean_absolute_error: 6.6256 - val_loss: 5.8123 - val_mean_absolute_error: 5.8123\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6267 - mean_absolute_error: 6.6267 - val_loss: 5.8363 - val_mean_absolute_error: 5.8363\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6244 - mean_absolute_error: 6.6244 - val_loss: 5.8747 - val_mean_absolute_error: 5.8747\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.6227 - mean_absolute_error: 6.6227 - val_loss: 5.8418 - val_mean_absolute_error: 5.8418\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.6248 - mean_absolute_error: 6.6248 - val_loss: 5.7994 - val_mean_absolute_error: 5.7994\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.6190 - mean_absolute_error: 6.6190 - val_loss: 5.7782 - val_mean_absolute_error: 5.7782\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.6093 - mean_absolute_error: 6.6093 - val_loss: 5.8510 - val_mean_absolute_error: 5.8510\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.5936 - mean_absolute_error: 6.5936 - val_loss: 5.8801 - val_mean_absolute_error: 5.8801\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.5830 - mean_absolute_error: 6.5830 - val_loss: 5.8405 - val_mean_absolute_error: 5.8405\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.5593 - mean_absolute_error: 6.5593 - val_loss: 5.7939 - val_mean_absolute_error: 5.7939\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5234 - mean_absolute_error: 6.5234 - val_loss: 5.7390 - val_mean_absolute_error: 5.7390\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4900 - mean_absolute_error: 6.4900 - val_loss: 5.7756 - val_mean_absolute_error: 5.7756\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.4519 - mean_absolute_error: 6.4519 - val_loss: 5.6624 - val_mean_absolute_error: 5.6624\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.3961 - mean_absolute_error: 6.3961 - val_loss: 5.6683 - val_mean_absolute_error: 5.6683\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.3335 - mean_absolute_error: 6.3335 - val_loss: 5.5785 - val_mean_absolute_error: 5.5785\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.2685 - mean_absolute_error: 6.2685 - val_loss: 5.4802 - val_mean_absolute_error: 5.4802\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6.1925 - mean_absolute_error: 6.1925 - val_loss: 5.4249 - val_mean_absolute_error: 5.4249\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.1542 - mean_absolute_error: 6.1542 - val_loss: 5.3914 - val_mean_absolute_error: 5.3914\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0583 - mean_absolute_error: 6.0583 - val_loss: 5.3370 - val_mean_absolute_error: 5.3370\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9991 - mean_absolute_error: 5.9991 - val_loss: 5.3041 - val_mean_absolute_error: 5.3041\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.8925 - mean_absolute_error: 5.8925 - val_loss: 5.2345 - val_mean_absolute_error: 5.2345\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.7756 - mean_absolute_error: 5.7756 - val_loss: 5.2269 - val_mean_absolute_error: 5.2269\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5927 - mean_absolute_error: 5.5927 - val_loss: 5.3518 - val_mean_absolute_error: 5.3518\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.4118 - mean_absolute_error: 5.4118 - val_loss: 5.4355 - val_mean_absolute_error: 5.4355\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2624 - mean_absolute_error: 5.2624 - val_loss: 5.4399 - val_mean_absolute_error: 5.4399\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0834 - mean_absolute_error: 5.0834 - val_loss: 5.3954 - val_mean_absolute_error: 5.3954\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0776 - mean_absolute_error: 5.0776 - val_loss: 5.3069 - val_mean_absolute_error: 5.3069\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0449 - mean_absolute_error: 5.0449 - val_loss: 5.4056 - val_mean_absolute_error: 5.4056\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0726 - mean_absolute_error: 5.0726 - val_loss: 5.4278 - val_mean_absolute_error: 5.4278\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0173 - mean_absolute_error: 5.0173 - val_loss: 5.4560 - val_mean_absolute_error: 5.4560\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.0170 - mean_absolute_error: 5.0170 - val_loss: 5.3664 - val_mean_absolute_error: 5.3664\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9646 - mean_absolute_error: 4.9646 - val_loss: 5.3166 - val_mean_absolute_error: 5.3166\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.9385 - mean_absolute_error: 4.9385 - val_loss: 5.2475 - val_mean_absolute_error: 5.2475\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.9744 - mean_absolute_error: 4.9744 - val_loss: 5.1955 - val_mean_absolute_error: 5.1955\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9305 - mean_absolute_error: 4.9305 - val_loss: 5.1148 - val_mean_absolute_error: 5.1148\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8667 - mean_absolute_error: 4.8667 - val_loss: 5.0171 - val_mean_absolute_error: 5.0171\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.7628 - mean_absolute_error: 4.7628 - val_loss: 4.8832 - val_mean_absolute_error: 4.8832\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.7509 - mean_absolute_error: 4.7509 - val_loss: 4.8545 - val_mean_absolute_error: 4.8545\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.8200 - mean_absolute_error: 4.8200 - val_loss: 5.1119 - val_mean_absolute_error: 5.1119\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7264 - mean_absolute_error: 4.7264 - val_loss: 5.6238 - val_mean_absolute_error: 5.6238\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9104 - mean_absolute_error: 4.9104 - val_loss: 4.7799 - val_mean_absolute_error: 4.7799\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7096 - mean_absolute_error: 4.7096 - val_loss: 4.7782 - val_mean_absolute_error: 4.7782\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7233 - mean_absolute_error: 4.7233 - val_loss: 4.9155 - val_mean_absolute_error: 4.9155\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7406 - mean_absolute_error: 4.7406 - val_loss: 4.8475 - val_mean_absolute_error: 4.8475\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.6951 - mean_absolute_error: 4.6951 - val_loss: 4.9234 - val_mean_absolute_error: 4.9234\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7407 - mean_absolute_error: 4.7407 - val_loss: 5.1725 - val_mean_absolute_error: 5.1725\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.6978 - mean_absolute_error: 4.6978 - val_loss: 4.9759 - val_mean_absolute_error: 4.9759\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6890 - mean_absolute_error: 4.6890 - val_loss: 5.2944 - val_mean_absolute_error: 5.2944\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6440 - mean_absolute_error: 4.6440 - val_loss: 4.6412 - val_mean_absolute_error: 4.6412\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6469 - mean_absolute_error: 4.6469 - val_loss: 4.6399 - val_mean_absolute_error: 4.6399\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6221 - mean_absolute_error: 4.6221 - val_loss: 4.6577 - val_mean_absolute_error: 4.6577\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.6034 - mean_absolute_error: 4.6034 - val_loss: 4.8823 - val_mean_absolute_error: 4.8823\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5762 - mean_absolute_error: 4.5762 - val_loss: 4.8867 - val_mean_absolute_error: 4.8867\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.5445 - mean_absolute_error: 4.5445 - val_loss: 5.0702 - val_mean_absolute_error: 5.0702\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5678 - mean_absolute_error: 4.5678 - val_loss: 4.5224 - val_mean_absolute_error: 4.5224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi Hasil Pembentukan Model terhadap Kinerja pada Validation Data\n",
        "Label_Epochs = []\n",
        "for i in range(EPOCHS):\n",
        "  Label_Epochs.append(i+1)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12.0, 9.0)\n",
        "for idx in range(5) :\n",
        "  plt.plot(Label_Epochs, History_NumHiddenLayer_Training[idx].history['val_mean_absolute_error'])\n",
        "plt.title('Pencarian Jumlah Hidden Layer Terbaik - MAE')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['1 Hidden Layer', '2 Hidden Layer', '3 Hidden Layer', '4 Hidden Layer', '5 Hidden Layer'])\n",
        "plt.savefig('PencarianJumlahHiddenLayerTerbaik-MAE.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "4OMohNrpRmdd",
        "outputId": "aa68a7e0-431d-4b7f-de3c-3b8a81a345bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tahapan 5**.\n",
        "Percobaan ke-3 dilakukan untuk mencari jumlah hidden neuron terbaik dari setiap Hidden Layer (16, 32, 64, 128, 256) dalam regression model. Acuan yang digunakan adalah penggunaan jumlah hidden layer terbaik (dari percobaan ke-2) sebanyak 2-3 hidden layer. Sehingga pada percobaan ke-3 ini akan dilakukan terlebih dahulu eksplorasi kombinasi jumlah hidden neuron pada penggunaan 2 hidden layer dalam arsitektur ANN yang didefinisikan. Masing-masing hidden layer masih menggunakan fungsi aktifasi Sigmoid."
      ],
      "metadata": {
        "id": "fsevMDS75K_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Nilai Terbaik NumHiddenLayer = 2\n",
        "#Nilai Pencarian NumHiddenNeuronPerLayer = 16 | 32 | 64 | 128 | 256\n",
        "#Nilai Dasar ActivationFuncPerLayer = ['sigmoid', 'sigmoid', 'relu']\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 80\n",
        "opt = RMSprop(learning_rate=0.001)\n",
        "NumHiddenLayer = 2\n",
        "ActivationFuncPerLayer = ['sigmoid', 'sigmoid', 'relu']\n",
        "data_val_error = []\n",
        "\n",
        "Var_NumHiddenNeuron = [16, 32, 64, 128, 256]\n",
        "\n",
        "for NumNeuronLayer1 in Var_NumHiddenNeuron :\n",
        "  data_val_error_perlayer1 = []\n",
        "  for NumNeuronLayer2 in Var_NumHiddenNeuron :\n",
        "    NumHiddenNeuronPerLayer = [NumNeuronLayer1, NumNeuronLayer2]\n",
        "    model_percobaan3 = build_ann_model(NumHiddenLayer, NumHiddenNeuronPerLayer, ActivationFuncPerLayer)\n",
        "    model_percobaan3.build((None, 13))\n",
        "    model_percobaan3.compile(optimizer=opt, loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
        "    model_percobaan3.summary()\n",
        "    model_percobaan3.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "    loss_val, acc_val = model_percobaan3.evaluate(x_valid, y_valid)\n",
        "    data_val_error_perlayer1.append(loss_val)\n",
        "  \n",
        "  # Memasukkan data validation error (MAE) ke array penyimpanan error keseluruhan untuk setiap setting nilai pada Hidden Layer ke-1\n",
        "  data_val_error.append(data_val_error_perlayer1)\n",
        "\n",
        "dframe_val_error = pd.DataFrame(data_val_error, index =['16', '32', '64', '128', '256'], columns =['16', '32', '64', '128', '256'])\n",
        "print(dframe_val_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaKyLeS259jT",
        "outputId": "314e97ba-fcc9-42dd-f369-7602bbc1dc32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 13)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                224       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 21.0796 - mean_absolute_error: 21.0796\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.8236 - mean_absolute_error: 20.8236\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.6239 - mean_absolute_error: 20.6239\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.4371 - mean_absolute_error: 20.4371\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.2361 - mean_absolute_error: 20.2361\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.0494 - mean_absolute_error: 20.0494\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 19.8541 - mean_absolute_error: 19.8541\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 19.6551 - mean_absolute_error: 19.6551\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 19.4583 - mean_absolute_error: 19.4583\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 19.2622 - mean_absolute_error: 19.2622\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 19.0707 - mean_absolute_error: 19.0707\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.8757 - mean_absolute_error: 18.8757\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.6919 - mean_absolute_error: 18.6919\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.5047 - mean_absolute_error: 18.5047\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.3252 - mean_absolute_error: 18.3252\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.1598 - mean_absolute_error: 18.1598\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.9916 - mean_absolute_error: 17.9916\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.8251 - mean_absolute_error: 17.8251\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.6625 - mean_absolute_error: 17.6625\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.5057 - mean_absolute_error: 17.5057\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.3563 - mean_absolute_error: 17.3563\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.2103 - mean_absolute_error: 17.2103\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.0654 - mean_absolute_error: 17.0654\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.9226 - mean_absolute_error: 16.9226\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.7855 - mean_absolute_error: 16.7855\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.6518 - mean_absolute_error: 16.6518\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.5196 - mean_absolute_error: 16.5196\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.3917 - mean_absolute_error: 16.3917\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.2654 - mean_absolute_error: 16.2654\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.1393 - mean_absolute_error: 16.1393\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.0117 - mean_absolute_error: 16.0117\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.8849 - mean_absolute_error: 15.8849\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.7630 - mean_absolute_error: 15.7630\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.6418 - mean_absolute_error: 15.6418\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.5216 - mean_absolute_error: 15.5216\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.4014 - mean_absolute_error: 15.4014\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.2814 - mean_absolute_error: 15.2814\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.1625 - mean_absolute_error: 15.1625\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.0441 - mean_absolute_error: 15.0441\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.9262 - mean_absolute_error: 14.9262\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.8091 - mean_absolute_error: 14.8091\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.6921 - mean_absolute_error: 14.6921\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.5750 - mean_absolute_error: 14.5750\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.4579 - mean_absolute_error: 14.4579\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.3405 - mean_absolute_error: 14.3405\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.2232 - mean_absolute_error: 14.2232\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.1063 - mean_absolute_error: 14.1063\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.9920 - mean_absolute_error: 13.9920\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.8798 - mean_absolute_error: 13.8798\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.7673 - mean_absolute_error: 13.7673\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.6558 - mean_absolute_error: 13.6558\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.5451 - mean_absolute_error: 13.5451\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.4338 - mean_absolute_error: 13.4338\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.3218 - mean_absolute_error: 13.3218\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.2096 - mean_absolute_error: 13.2096\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.1020 - mean_absolute_error: 13.1020\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.9866 - mean_absolute_error: 12.9866\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.8724 - mean_absolute_error: 12.8724\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.7578 - mean_absolute_error: 12.7578\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6425 - mean_absolute_error: 12.6425\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.5269 - mean_absolute_error: 12.5269\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.4228 - mean_absolute_error: 12.4228\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.3048 - mean_absolute_error: 12.3048\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.1890 - mean_absolute_error: 12.1890\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.0738 - mean_absolute_error: 12.0738\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.9575 - mean_absolute_error: 11.9575\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.8406 - mean_absolute_error: 11.8406\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.7260 - mean_absolute_error: 11.7260\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.6186 - mean_absolute_error: 11.6186\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.5023 - mean_absolute_error: 11.5023\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.3852 - mean_absolute_error: 11.3852\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.2695 - mean_absolute_error: 11.2695\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.1535 - mean_absolute_error: 11.1535\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.0364 - mean_absolute_error: 11.0364\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 10.9339 - mean_absolute_error: 10.9339\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 10.8234 - mean_absolute_error: 10.8234\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.7065 - mean_absolute_error: 10.7065\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.5967 - mean_absolute_error: 10.5967\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 10.4807 - mean_absolute_error: 10.4807\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 10.3808 - mean_absolute_error: 10.3808\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 11.4635 - mean_absolute_error: 11.4635\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                224       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 801\n",
            "Trainable params: 801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 23.5842 - mean_absolute_error: 23.5842\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                224       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                1088      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,377\n",
            "Trainable params: 1,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 21.1388 - mean_absolute_error: 21.1388\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.2891 - mean_absolute_error: 20.2891\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 19.6862 - mean_absolute_error: 19.6862\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.1382 - mean_absolute_error: 19.1382\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.6090 - mean_absolute_error: 18.6090\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.0850 - mean_absolute_error: 18.0850\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.5653 - mean_absolute_error: 17.5653\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.0526 - mean_absolute_error: 17.0526\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.5489 - mean_absolute_error: 16.5489\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.0470 - mean_absolute_error: 16.0470\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.5507 - mean_absolute_error: 15.5507\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.0610 - mean_absolute_error: 15.0610\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.5762 - mean_absolute_error: 14.5762\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.0993 - mean_absolute_error: 14.0993\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.6326 - mean_absolute_error: 13.6326\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.1867 - mean_absolute_error: 13.1867\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7715 - mean_absolute_error: 12.7715\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.3295 - mean_absolute_error: 12.3295\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.9163 - mean_absolute_error: 11.9163\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.4895 - mean_absolute_error: 11.4895\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.0805 - mean_absolute_error: 11.0805\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.6881 - mean_absolute_error: 10.6881\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.3084 - mean_absolute_error: 10.3084\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.9379 - mean_absolute_error: 9.9379\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.5860 - mean_absolute_error: 9.5860\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.2595 - mean_absolute_error: 9.2595\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9676 - mean_absolute_error: 8.9676\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.7033 - mean_absolute_error: 8.7033\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.4231 - mean_absolute_error: 8.4231\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.1913 - mean_absolute_error: 8.1913\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.9552 - mean_absolute_error: 7.9552\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.7461 - mean_absolute_error: 7.7461\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5643 - mean_absolute_error: 7.5643\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3662 - mean_absolute_error: 7.3662\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.1972 - mean_absolute_error: 7.1972\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0587 - mean_absolute_error: 7.0587\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9162 - mean_absolute_error: 6.9162\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.7969 - mean_absolute_error: 6.7969\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7006 - mean_absolute_error: 6.7006\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.6386 - mean_absolute_error: 6.6386\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5676 - mean_absolute_error: 6.5676\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5409 - mean_absolute_error: 6.5409\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5111 - mean_absolute_error: 6.5111\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4831 - mean_absolute_error: 6.4831\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4370 - mean_absolute_error: 6.4370\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.3959 - mean_absolute_error: 6.3959\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.3621 - mean_absolute_error: 6.3621\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3472 - mean_absolute_error: 6.3472\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3210 - mean_absolute_error: 6.3210\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2986 - mean_absolute_error: 6.2986\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2738 - mean_absolute_error: 6.2738\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2533 - mean_absolute_error: 6.2533\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2279 - mean_absolute_error: 6.2279\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2021 - mean_absolute_error: 6.2021\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1832 - mean_absolute_error: 6.1832\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1583 - mean_absolute_error: 6.1583\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1340 - mean_absolute_error: 6.1340\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1048 - mean_absolute_error: 6.1048\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.0954 - mean_absolute_error: 6.0954\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.0572 - mean_absolute_error: 6.0572\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.0297 - mean_absolute_error: 6.0297\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0031 - mean_absolute_error: 6.0031\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9661 - mean_absolute_error: 5.9661\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9399 - mean_absolute_error: 5.9399\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9176 - mean_absolute_error: 5.9176\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8871 - mean_absolute_error: 5.8871\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8585 - mean_absolute_error: 5.8585\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8326 - mean_absolute_error: 5.8326\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7921 - mean_absolute_error: 5.7921\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7583 - mean_absolute_error: 5.7583\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7224 - mean_absolute_error: 5.7224\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6935 - mean_absolute_error: 5.6935\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6576 - mean_absolute_error: 5.6576\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6332 - mean_absolute_error: 5.6332\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5973 - mean_absolute_error: 5.5973\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.5921 - mean_absolute_error: 5.5921\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5407 - mean_absolute_error: 5.5407\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5185 - mean_absolute_error: 5.5185\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4932 - mean_absolute_error: 5.4932\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4474 - mean_absolute_error: 5.4474\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 5.6996 - mean_absolute_error: 5.6996\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                224       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               2176      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,529\n",
            "Trainable params: 2,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 21.5485 - mean_absolute_error: 21.5485\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.3567 - mean_absolute_error: 20.3567\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.3460 - mean_absolute_error: 19.3460\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.3601 - mean_absolute_error: 18.3601\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.3833 - mean_absolute_error: 17.3833\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.4191 - mean_absolute_error: 16.4191\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.4195 - mean_absolute_error: 15.4195\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.4429 - mean_absolute_error: 14.4429\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.5153 - mean_absolute_error: 13.5153\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6675 - mean_absolute_error: 12.6675\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.8308 - mean_absolute_error: 11.8308\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0589 - mean_absolute_error: 11.0589\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 10.2847 - mean_absolute_error: 10.2847\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.5715 - mean_absolute_error: 9.5715\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9469 - mean_absolute_error: 8.9469\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.4015 - mean_absolute_error: 8.4015\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.9548 - mean_absolute_error: 7.9548\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5019 - mean_absolute_error: 7.5019\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.1458 - mean_absolute_error: 7.1458\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8645 - mean_absolute_error: 6.8645\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6989 - mean_absolute_error: 6.6989\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5066 - mean_absolute_error: 6.5066\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4292 - mean_absolute_error: 6.4292\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.3777 - mean_absolute_error: 6.3777\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3643 - mean_absolute_error: 6.3643\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3327 - mean_absolute_error: 6.3327\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3115 - mean_absolute_error: 6.3115\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2978 - mean_absolute_error: 6.2978\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2722 - mean_absolute_error: 6.2722\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2489 - mean_absolute_error: 6.2489\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1980 - mean_absolute_error: 6.1980\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1609 - mean_absolute_error: 6.1609\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1085 - mean_absolute_error: 6.1085\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0602 - mean_absolute_error: 6.0602\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0281 - mean_absolute_error: 6.0281\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0044 - mean_absolute_error: 6.0044\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9782 - mean_absolute_error: 5.9782\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9396 - mean_absolute_error: 5.9396\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9113 - mean_absolute_error: 5.9113\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8870 - mean_absolute_error: 5.8870\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.8714 - mean_absolute_error: 5.8714\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8388 - mean_absolute_error: 5.8388\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8124 - mean_absolute_error: 5.8124\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7908 - mean_absolute_error: 5.7908\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7645 - mean_absolute_error: 5.7645\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7543 - mean_absolute_error: 5.7543\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7333 - mean_absolute_error: 5.7333\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7113 - mean_absolute_error: 5.7113\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7021 - mean_absolute_error: 5.7021\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6747 - mean_absolute_error: 5.6747\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6640 - mean_absolute_error: 5.6640\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6485 - mean_absolute_error: 5.6485\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6394 - mean_absolute_error: 5.6394\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6217 - mean_absolute_error: 5.6217\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6037 - mean_absolute_error: 5.6037\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6060 - mean_absolute_error: 5.6060\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.5876 - mean_absolute_error: 5.5876\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.5766 - mean_absolute_error: 5.5766\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5683 - mean_absolute_error: 5.5683\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5685 - mean_absolute_error: 5.5685\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5545 - mean_absolute_error: 5.5545\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5425 - mean_absolute_error: 5.5425\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5185 - mean_absolute_error: 5.5185\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5207 - mean_absolute_error: 5.5207\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5231 - mean_absolute_error: 5.5231\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4999 - mean_absolute_error: 5.4999\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4949 - mean_absolute_error: 5.4949\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4868 - mean_absolute_error: 5.4868\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4820 - mean_absolute_error: 5.4820\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4725 - mean_absolute_error: 5.4725\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4719 - mean_absolute_error: 5.4719\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4695 - mean_absolute_error: 5.4695\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4568 - mean_absolute_error: 5.4568\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4498 - mean_absolute_error: 5.4498\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4463 - mean_absolute_error: 5.4463\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4397 - mean_absolute_error: 5.4397\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4318 - mean_absolute_error: 5.4318\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4273 - mean_absolute_error: 5.4273\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4396 - mean_absolute_error: 5.4396\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4034 - mean_absolute_error: 5.4034\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 5.8282 - mean_absolute_error: 5.8282\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                224       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 256)               4352      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,833\n",
            "Trainable params: 4,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 20.1315 - mean_absolute_error: 20.1315\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.9984 - mean_absolute_error: 17.9984\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.2793 - mean_absolute_error: 16.2793\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6480 - mean_absolute_error: 14.6480\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.0723 - mean_absolute_error: 13.0723\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.5914 - mean_absolute_error: 11.5914\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.2986 - mean_absolute_error: 10.2986\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.1243 - mean_absolute_error: 9.1243\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.1469 - mean_absolute_error: 8.1469\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.4298 - mean_absolute_error: 7.4298\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9711 - mean_absolute_error: 6.9711\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5501 - mean_absolute_error: 6.5501\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3956 - mean_absolute_error: 6.3956\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3330 - mean_absolute_error: 6.3330\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3290 - mean_absolute_error: 6.3290\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3221 - mean_absolute_error: 6.3221\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2301 - mean_absolute_error: 6.2301\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2086 - mean_absolute_error: 6.2086\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1668 - mean_absolute_error: 6.1668\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0835 - mean_absolute_error: 6.0835\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0396 - mean_absolute_error: 6.0396\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9976 - mean_absolute_error: 5.9976\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9595 - mean_absolute_error: 5.9595\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9262 - mean_absolute_error: 5.9262\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8884 - mean_absolute_error: 5.8884\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8192 - mean_absolute_error: 5.8192\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7647 - mean_absolute_error: 5.7647\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7319 - mean_absolute_error: 5.7319\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7089 - mean_absolute_error: 5.7089\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6482 - mean_absolute_error: 5.6482\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5858 - mean_absolute_error: 5.5858\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5659 - mean_absolute_error: 5.5659\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5314 - mean_absolute_error: 5.5314\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5036 - mean_absolute_error: 5.5036\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4757 - mean_absolute_error: 5.4757\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4759 - mean_absolute_error: 5.4759\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4203 - mean_absolute_error: 5.4203\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3968 - mean_absolute_error: 5.3968\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3710 - mean_absolute_error: 5.3710\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3487 - mean_absolute_error: 5.3487\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3306 - mean_absolute_error: 5.3306\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3060 - mean_absolute_error: 5.3060\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3371 - mean_absolute_error: 5.3371\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2795 - mean_absolute_error: 5.2795\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2613 - mean_absolute_error: 5.2613\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2601 - mean_absolute_error: 5.2601\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2697 - mean_absolute_error: 5.2697\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2392 - mean_absolute_error: 5.2392\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2180 - mean_absolute_error: 5.2180\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2202 - mean_absolute_error: 5.2202\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2079 - mean_absolute_error: 5.2079\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2058 - mean_absolute_error: 5.2058\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1918 - mean_absolute_error: 5.1918\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1822 - mean_absolute_error: 5.1822\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1798 - mean_absolute_error: 5.1798\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2050 - mean_absolute_error: 5.2050\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1699 - mean_absolute_error: 5.1699\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1523 - mean_absolute_error: 5.1523\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1386 - mean_absolute_error: 5.1386\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1288 - mean_absolute_error: 5.1288\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1430 - mean_absolute_error: 5.1430\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1242 - mean_absolute_error: 5.1242\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1229 - mean_absolute_error: 5.1229\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1178 - mean_absolute_error: 5.1178\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1248 - mean_absolute_error: 5.1248\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1040 - mean_absolute_error: 5.1040\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1056 - mean_absolute_error: 5.1056\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0768 - mean_absolute_error: 5.0768\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1053 - mean_absolute_error: 5.1053\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0909 - mean_absolute_error: 5.0909\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1061 - mean_absolute_error: 5.1061\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0676 - mean_absolute_error: 5.0676\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0784 - mean_absolute_error: 5.0784\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0578 - mean_absolute_error: 5.0578\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0366 - mean_absolute_error: 5.0366\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0439 - mean_absolute_error: 5.0439\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0439 - mean_absolute_error: 5.0439\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0156 - mean_absolute_error: 5.0156\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0356 - mean_absolute_error: 5.0356\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9714 - mean_absolute_error: 4.9714\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f75ea2d1e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 5.4322 - mean_absolute_error: 5.4322\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 32)                448       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 993\n",
            "Trainable params: 993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3991 - mean_absolute_error: 22.3991\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f75ea138320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 23.5842 - mean_absolute_error: 23.5842\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 32)                448       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,537\n",
            "Trainable params: 1,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 21.6913 - mean_absolute_error: 21.6913\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 21.1317 - mean_absolute_error: 21.1317\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.6863 - mean_absolute_error: 20.6863\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.2922 - mean_absolute_error: 20.2922\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.8950 - mean_absolute_error: 19.8950\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.4825 - mean_absolute_error: 19.4825\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.0934 - mean_absolute_error: 19.0934\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.7217 - mean_absolute_error: 18.7217\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.3701 - mean_absolute_error: 18.3701\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.0266 - mean_absolute_error: 18.0266\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.6823 - mean_absolute_error: 17.6823\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.3487 - mean_absolute_error: 17.3487\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.0314 - mean_absolute_error: 17.0314\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.7219 - mean_absolute_error: 16.7219\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.4265 - mean_absolute_error: 16.4265\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.1483 - mean_absolute_error: 16.1483\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.8835 - mean_absolute_error: 15.8835\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.6258 - mean_absolute_error: 15.6258\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.3736 - mean_absolute_error: 15.3736\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.1256 - mean_absolute_error: 15.1256\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.8830 - mean_absolute_error: 14.8830\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6470 - mean_absolute_error: 14.6470\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.4153 - mean_absolute_error: 14.4153\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.1850 - mean_absolute_error: 14.1850\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.9741 - mean_absolute_error: 13.9741\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.7543 - mean_absolute_error: 13.7543\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.5415 - mean_absolute_error: 13.5415\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.3459 - mean_absolute_error: 13.3459\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.1385 - mean_absolute_error: 13.1385\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.9352 - mean_absolute_error: 12.9352\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7341 - mean_absolute_error: 12.7341\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.5320 - mean_absolute_error: 12.5320\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.3346 - mean_absolute_error: 12.3346\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.1400 - mean_absolute_error: 12.1400\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.9503 - mean_absolute_error: 11.9503\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.7723 - mean_absolute_error: 11.7723\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.5840 - mean_absolute_error: 11.5840\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.4081 - mean_absolute_error: 11.4081\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.2201 - mean_absolute_error: 11.2201\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0369 - mean_absolute_error: 11.0369\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.8589 - mean_absolute_error: 10.8589\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.6919 - mean_absolute_error: 10.6919\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.5123 - mean_absolute_error: 10.5123\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.3455 - mean_absolute_error: 10.3455\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.1684 - mean_absolute_error: 10.1684\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 10.0062 - mean_absolute_error: 10.0062\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.8533 - mean_absolute_error: 9.8533\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.6926 - mean_absolute_error: 9.6926\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.5403 - mean_absolute_error: 9.5403\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.3835 - mean_absolute_error: 9.3835\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.2386 - mean_absolute_error: 9.2386\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.1049 - mean_absolute_error: 9.1049\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9722 - mean_absolute_error: 8.9722\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.8321 - mean_absolute_error: 8.8321\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.6980 - mean_absolute_error: 8.6980\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.5722 - mean_absolute_error: 8.5722\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.4672 - mean_absolute_error: 8.4672\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.3383 - mean_absolute_error: 8.3383\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.2256 - mean_absolute_error: 8.2256\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.1113 - mean_absolute_error: 8.1113\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.9961 - mean_absolute_error: 7.9961\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.8964 - mean_absolute_error: 7.8964\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.7833 - mean_absolute_error: 7.7833\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.6837 - mean_absolute_error: 7.6837\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5757 - mean_absolute_error: 7.5757\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.4698 - mean_absolute_error: 7.4698\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.3838 - mean_absolute_error: 7.3838\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3201 - mean_absolute_error: 7.3201\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2328 - mean_absolute_error: 7.2328\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.1480 - mean_absolute_error: 7.1480\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0636 - mean_absolute_error: 7.0636\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9934 - mean_absolute_error: 6.9934\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9334 - mean_absolute_error: 6.9334\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8706 - mean_absolute_error: 6.8706\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8139 - mean_absolute_error: 6.8139\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.7642 - mean_absolute_error: 6.7642\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7140 - mean_absolute_error: 6.7140\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6779 - mean_absolute_error: 6.6779\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6382 - mean_absolute_error: 6.6382\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6070 - mean_absolute_error: 6.6070\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 6.7098 - mean_absolute_error: 6.7098\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 32)                448       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,625\n",
            "Trainable params: 2,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 21.3157 - mean_absolute_error: 21.3157\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 20.3430 - mean_absolute_error: 20.3430\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.5890 - mean_absolute_error: 19.5890\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.8764 - mean_absolute_error: 18.8764\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.1840 - mean_absolute_error: 18.1840\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.5224 - mean_absolute_error: 17.5224\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 16.8852 - mean_absolute_error: 16.8852\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.2839 - mean_absolute_error: 16.2839\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.7024 - mean_absolute_error: 15.7024\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.1447 - mean_absolute_error: 15.1447\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6040 - mean_absolute_error: 14.6040\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.0804 - mean_absolute_error: 14.0804\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.6004 - mean_absolute_error: 13.6004\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.1489 - mean_absolute_error: 13.1489\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7006 - mean_absolute_error: 12.7006\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.2663 - mean_absolute_error: 12.2663\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.8546 - mean_absolute_error: 11.8546\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.4613 - mean_absolute_error: 11.4613\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0803 - mean_absolute_error: 11.0803\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.7183 - mean_absolute_error: 10.7183\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.3716 - mean_absolute_error: 10.3716\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.0397 - mean_absolute_error: 10.0397\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.7378 - mean_absolute_error: 9.7378\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.4349 - mean_absolute_error: 9.4349\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.1813 - mean_absolute_error: 9.1813\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9135 - mean_absolute_error: 8.9135\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.6972 - mean_absolute_error: 8.6972\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.4701 - mean_absolute_error: 8.4701\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.2520 - mean_absolute_error: 8.2520\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.0408 - mean_absolute_error: 8.0408\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.8293 - mean_absolute_error: 7.8293\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.6939 - mean_absolute_error: 7.6939\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5355 - mean_absolute_error: 7.5355\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3807 - mean_absolute_error: 7.3807\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2124 - mean_absolute_error: 7.2124\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0809 - mean_absolute_error: 7.0809\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9554 - mean_absolute_error: 6.9554\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8571 - mean_absolute_error: 6.8571\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7825 - mean_absolute_error: 6.7825\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7270 - mean_absolute_error: 6.7270\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6757 - mean_absolute_error: 6.6757\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6453 - mean_absolute_error: 6.6453\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6268 - mean_absolute_error: 6.6268\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6023 - mean_absolute_error: 6.6023\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5933 - mean_absolute_error: 6.5933\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5842 - mean_absolute_error: 6.5842\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5809 - mean_absolute_error: 6.5809\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5715 - mean_absolute_error: 6.5715\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5585 - mean_absolute_error: 6.5585\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5502 - mean_absolute_error: 6.5502\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5436 - mean_absolute_error: 6.5436\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5347 - mean_absolute_error: 6.5347\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5161 - mean_absolute_error: 6.5161\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5001 - mean_absolute_error: 6.5001\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4762 - mean_absolute_error: 6.4762\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4593 - mean_absolute_error: 6.4593\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.4423 - mean_absolute_error: 6.4423\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.4073 - mean_absolute_error: 6.4073\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.3775 - mean_absolute_error: 6.3775\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3473 - mean_absolute_error: 6.3473\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.3144 - mean_absolute_error: 6.3144\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2682 - mean_absolute_error: 6.2682\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2239 - mean_absolute_error: 6.2239\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1882 - mean_absolute_error: 6.1882\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1411 - mean_absolute_error: 6.1411\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.1116 - mean_absolute_error: 6.1116\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0559 - mean_absolute_error: 6.0559\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.9847 - mean_absolute_error: 5.9847\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.9279 - mean_absolute_error: 5.9279\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8712 - mean_absolute_error: 5.8712\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8030 - mean_absolute_error: 5.8030\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.7520 - mean_absolute_error: 5.7520\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6883 - mean_absolute_error: 5.6883\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.6304 - mean_absolute_error: 5.6304\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5888 - mean_absolute_error: 5.5888\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5460 - mean_absolute_error: 5.5460\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5011 - mean_absolute_error: 5.5011\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4515 - mean_absolute_error: 5.4515\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4178 - mean_absolute_error: 5.4178\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3708 - mean_absolute_error: 5.3708\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 5.6496 - mean_absolute_error: 5.6496\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 32)                448       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,801\n",
            "Trainable params: 4,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 21.4258 - mean_absolute_error: 21.4258\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.8318 - mean_absolute_error: 19.8318\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.6843 - mean_absolute_error: 18.6843\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.6291 - mean_absolute_error: 17.6291\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.6152 - mean_absolute_error: 16.6152\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.6221 - mean_absolute_error: 15.6221\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6266 - mean_absolute_error: 14.6266\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.6674 - mean_absolute_error: 13.6674\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7265 - mean_absolute_error: 12.7265\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.8175 - mean_absolute_error: 11.8175\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.9866 - mean_absolute_error: 10.9866\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.2407 - mean_absolute_error: 10.2407\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.5268 - mean_absolute_error: 9.5268\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9494 - mean_absolute_error: 8.9494\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.4338 - mean_absolute_error: 8.4338\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.0126 - mean_absolute_error: 8.0126\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5981 - mean_absolute_error: 7.5981\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2687 - mean_absolute_error: 7.2687\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0031 - mean_absolute_error: 7.0031\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8176 - mean_absolute_error: 6.8176\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7207 - mean_absolute_error: 6.7207\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6430 - mean_absolute_error: 6.6430\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5845 - mean_absolute_error: 6.5845\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5743 - mean_absolute_error: 6.5743\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5550 - mean_absolute_error: 6.5550\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5461 - mean_absolute_error: 6.5461\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5282 - mean_absolute_error: 6.5282\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5106 - mean_absolute_error: 6.5106\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4916 - mean_absolute_error: 6.4916\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4791 - mean_absolute_error: 6.4791\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4536 - mean_absolute_error: 6.4536\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4370 - mean_absolute_error: 6.4370\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4238 - mean_absolute_error: 6.4238\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.3950 - mean_absolute_error: 6.3950\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3703 - mean_absolute_error: 6.3703\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.3490 - mean_absolute_error: 6.3490\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3283 - mean_absolute_error: 6.3283\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2998 - mean_absolute_error: 6.2998\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2740 - mean_absolute_error: 6.2740\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2355 - mean_absolute_error: 6.2355\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1975 - mean_absolute_error: 6.1975\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1592 - mean_absolute_error: 6.1592\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1241 - mean_absolute_error: 6.1241\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0755 - mean_absolute_error: 6.0755\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.0344 - mean_absolute_error: 6.0344\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9845 - mean_absolute_error: 5.9845\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9148 - mean_absolute_error: 5.9148\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8584 - mean_absolute_error: 5.8584\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.8242 - mean_absolute_error: 5.8242\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7668 - mean_absolute_error: 5.7668\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7219 - mean_absolute_error: 5.7219\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6756 - mean_absolute_error: 5.6756\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6283 - mean_absolute_error: 5.6283\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5976 - mean_absolute_error: 5.5976\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5657 - mean_absolute_error: 5.5657\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5236 - mean_absolute_error: 5.5236\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4925 - mean_absolute_error: 5.4925\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4581 - mean_absolute_error: 5.4581\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4647 - mean_absolute_error: 5.4647\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4312 - mean_absolute_error: 5.4312\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4025 - mean_absolute_error: 5.4025\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4078 - mean_absolute_error: 5.4078\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3779 - mean_absolute_error: 5.3779\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3621 - mean_absolute_error: 5.3621\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3547 - mean_absolute_error: 5.3547\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3513 - mean_absolute_error: 5.3513\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3081 - mean_absolute_error: 5.3081\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3216 - mean_absolute_error: 5.3216\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2985 - mean_absolute_error: 5.2985\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3037 - mean_absolute_error: 5.3037\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2890 - mean_absolute_error: 5.2890\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2788 - mean_absolute_error: 5.2788\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2583 - mean_absolute_error: 5.2583\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2587 - mean_absolute_error: 5.2587\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2586 - mean_absolute_error: 5.2586\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2421 - mean_absolute_error: 5.2421\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2476 - mean_absolute_error: 5.2476\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2169 - mean_absolute_error: 5.2169\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2217 - mean_absolute_error: 5.2217\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2194 - mean_absolute_error: 5.2194\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 5.6526 - mean_absolute_error: 5.6526\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 32)                448       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 256)               8448      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,153\n",
            "Trainable params: 9,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 20.1579 - mean_absolute_error: 20.1579\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.5859 - mean_absolute_error: 17.5859\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.5433 - mean_absolute_error: 15.5433\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.6564 - mean_absolute_error: 13.6564\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.9352 - mean_absolute_error: 11.9352\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.4020 - mean_absolute_error: 10.4020\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.1913 - mean_absolute_error: 9.1913\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.1634 - mean_absolute_error: 8.1634\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3498 - mean_absolute_error: 7.3498\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8257 - mean_absolute_error: 6.8257\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5667 - mean_absolute_error: 6.5667\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4575 - mean_absolute_error: 6.4575\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4207 - mean_absolute_error: 6.4207\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4107 - mean_absolute_error: 6.4107\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3743 - mean_absolute_error: 6.3743\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3361 - mean_absolute_error: 6.3361\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3167 - mean_absolute_error: 6.3167\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2469 - mean_absolute_error: 6.2469\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2013 - mean_absolute_error: 6.2013\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1719 - mean_absolute_error: 6.1719\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1359 - mean_absolute_error: 6.1359\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0823 - mean_absolute_error: 6.0823\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.0373 - mean_absolute_error: 6.0373\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0087 - mean_absolute_error: 6.0087\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9532 - mean_absolute_error: 5.9532\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9179 - mean_absolute_error: 5.9179\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.8766 - mean_absolute_error: 5.8766\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8392 - mean_absolute_error: 5.8392\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7944 - mean_absolute_error: 5.7944\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7666 - mean_absolute_error: 5.7666\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7269 - mean_absolute_error: 5.7269\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6733 - mean_absolute_error: 5.6733\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6647 - mean_absolute_error: 5.6647\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5945 - mean_absolute_error: 5.5945\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5647 - mean_absolute_error: 5.5647\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5170 - mean_absolute_error: 5.5170\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5022 - mean_absolute_error: 5.5022\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4520 - mean_absolute_error: 5.4520\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4251 - mean_absolute_error: 5.4251\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.4096 - mean_absolute_error: 5.4096\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3620 - mean_absolute_error: 5.3620\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3225 - mean_absolute_error: 5.3225\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3326 - mean_absolute_error: 5.3326\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3126 - mean_absolute_error: 5.3126\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3121 - mean_absolute_error: 5.3121\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2850 - mean_absolute_error: 5.2850\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2670 - mean_absolute_error: 5.2670\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2240 - mean_absolute_error: 5.2240\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2072 - mean_absolute_error: 5.2072\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2321 - mean_absolute_error: 5.2321\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2096 - mean_absolute_error: 5.2096\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2335 - mean_absolute_error: 5.2335\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1898 - mean_absolute_error: 5.1898\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2193 - mean_absolute_error: 5.2193\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1808 - mean_absolute_error: 5.1808\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1633 - mean_absolute_error: 5.1633\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1411 - mean_absolute_error: 5.1411\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1464 - mean_absolute_error: 5.1464\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1821 - mean_absolute_error: 5.1821\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1219 - mean_absolute_error: 5.1219\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1476 - mean_absolute_error: 5.1476\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1377 - mean_absolute_error: 5.1377\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1262 - mean_absolute_error: 5.1262\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0795 - mean_absolute_error: 5.0795\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1148 - mean_absolute_error: 5.1148\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1145 - mean_absolute_error: 5.1145\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1256 - mean_absolute_error: 5.1256\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0928 - mean_absolute_error: 5.0928\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1669 - mean_absolute_error: 5.1669\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0685 - mean_absolute_error: 5.0685\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1009 - mean_absolute_error: 5.1009\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0929 - mean_absolute_error: 5.0929\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1076 - mean_absolute_error: 5.1076\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1420 - mean_absolute_error: 5.1420\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0681 - mean_absolute_error: 5.0681\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0535 - mean_absolute_error: 5.0535\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1062 - mean_absolute_error: 5.1062\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0655 - mean_absolute_error: 5.0655\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0693 - mean_absolute_error: 5.0693\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0440 - mean_absolute_error: 5.0440\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 5.7933 - mean_absolute_error: 5.7933\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_10 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,953\n",
            "Trainable params: 1,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 4ms/step - loss: 21.4479 - mean_absolute_error: 21.4479\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.8340 - mean_absolute_error: 20.8340\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.3790 - mean_absolute_error: 20.3790\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 20.0035 - mean_absolute_error: 20.0035\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.6661 - mean_absolute_error: 19.6661\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 19.3750 - mean_absolute_error: 19.3750\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.1252 - mean_absolute_error: 19.1252\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.9134 - mean_absolute_error: 18.9134\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.7262 - mean_absolute_error: 18.7262\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.5642 - mean_absolute_error: 18.5642\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.4115 - mean_absolute_error: 18.4115\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.2750 - mean_absolute_error: 18.2750\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.1430 - mean_absolute_error: 18.1430\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.0211 - mean_absolute_error: 18.0211\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.9044 - mean_absolute_error: 17.9044\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.7926 - mean_absolute_error: 17.7926\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.6825 - mean_absolute_error: 17.6825\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.5729 - mean_absolute_error: 17.5729\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.4619 - mean_absolute_error: 17.4619\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.3494 - mean_absolute_error: 17.3494\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.2350 - mean_absolute_error: 17.2350\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.1170 - mean_absolute_error: 17.1170\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.9981 - mean_absolute_error: 16.9981\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.8803 - mean_absolute_error: 16.8803\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.7644 - mean_absolute_error: 16.7644\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.6497 - mean_absolute_error: 16.6497\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.5362 - mean_absolute_error: 16.5362\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.4255 - mean_absolute_error: 16.4255\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.3172 - mean_absolute_error: 16.3172\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.2100 - mean_absolute_error: 16.2100\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.1037 - mean_absolute_error: 16.1037\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.9990 - mean_absolute_error: 15.9990\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.8949 - mean_absolute_error: 15.8949\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.7912 - mean_absolute_error: 15.7912\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.6876 - mean_absolute_error: 15.6876\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 15.5843 - mean_absolute_error: 15.5843\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.4813 - mean_absolute_error: 15.4813\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.3784 - mean_absolute_error: 15.3784\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.2755 - mean_absolute_error: 15.2755\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.1732 - mean_absolute_error: 15.1732\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.0715 - mean_absolute_error: 15.0715\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.9697 - mean_absolute_error: 14.9697\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.8686 - mean_absolute_error: 14.8686\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.7675 - mean_absolute_error: 14.7675\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6665 - mean_absolute_error: 14.6665\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.5700 - mean_absolute_error: 14.5700\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.4671 - mean_absolute_error: 14.4671\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.3653 - mean_absolute_error: 14.3653\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.2638 - mean_absolute_error: 14.2638\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.1627 - mean_absolute_error: 14.1627\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.0632 - mean_absolute_error: 14.0632\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.9648 - mean_absolute_error: 13.9648\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.8679 - mean_absolute_error: 13.8679\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.7711 - mean_absolute_error: 13.7711\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.6739 - mean_absolute_error: 13.6739\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.5765 - mean_absolute_error: 13.5765\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.4771 - mean_absolute_error: 13.4771\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.3726 - mean_absolute_error: 13.3726\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.2605 - mean_absolute_error: 13.2605\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.1328 - mean_absolute_error: 13.1328\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.0030 - mean_absolute_error: 13.0030\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.8800 - mean_absolute_error: 12.8800\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7626 - mean_absolute_error: 12.7626\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6479 - mean_absolute_error: 12.6479\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.5378 - mean_absolute_error: 12.5378\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.4296 - mean_absolute_error: 12.4296\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.3284 - mean_absolute_error: 12.3284\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.2267 - mean_absolute_error: 12.2267\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.1207 - mean_absolute_error: 12.1207\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.0183 - mean_absolute_error: 12.0183\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.9170 - mean_absolute_error: 11.9170\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.8159 - mean_absolute_error: 11.8159\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.7216 - mean_absolute_error: 11.7216\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.6219 - mean_absolute_error: 11.6219\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.5285 - mean_absolute_error: 11.5285\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.4287 - mean_absolute_error: 11.4287\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.3358 - mean_absolute_error: 11.3358\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.2365 - mean_absolute_error: 11.2365\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.1397 - mean_absolute_error: 11.1397\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0442 - mean_absolute_error: 11.0442\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 12.1382 - mean_absolute_error: 12.1382\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,009\n",
            "Trainable params: 3,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3991 - mean_absolute_error: 22.3991\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 23.5842 - mean_absolute_error: 23.5842\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_12 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 4ms/step - loss: 20.4786 - mean_absolute_error: 20.4786\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 19.1857 - mean_absolute_error: 19.1857\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.1822 - mean_absolute_error: 18.1822\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.3421 - mean_absolute_error: 17.3421\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.5902 - mean_absolute_error: 16.5902\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.9063 - mean_absolute_error: 15.9063\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.3127 - mean_absolute_error: 15.3127\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.7827 - mean_absolute_error: 14.7827\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.2980 - mean_absolute_error: 14.2980\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.8473 - mean_absolute_error: 13.8473\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.4430 - mean_absolute_error: 13.4430\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.0618 - mean_absolute_error: 13.0618\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7094 - mean_absolute_error: 12.7094\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.3436 - mean_absolute_error: 12.3436\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.0111 - mean_absolute_error: 12.0111\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.7036 - mean_absolute_error: 11.7036\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.3656 - mean_absolute_error: 11.3656\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0421 - mean_absolute_error: 11.0421\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.7470 - mean_absolute_error: 10.7470\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 10.4382 - mean_absolute_error: 10.4382\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.1406 - mean_absolute_error: 10.1406\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.8522 - mean_absolute_error: 9.8522\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.5835 - mean_absolute_error: 9.5835\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.3304 - mean_absolute_error: 9.3304\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.0867 - mean_absolute_error: 9.0867\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.8655 - mean_absolute_error: 8.8655\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.6411 - mean_absolute_error: 8.6411\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.4085 - mean_absolute_error: 8.4085\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.1912 - mean_absolute_error: 8.1912\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.0154 - mean_absolute_error: 8.0154\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.8136 - mean_absolute_error: 7.8136\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.6205 - mean_absolute_error: 7.6205\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.4419 - mean_absolute_error: 7.4419\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2768 - mean_absolute_error: 7.2768\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.1143 - mean_absolute_error: 7.1143\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0166 - mean_absolute_error: 7.0166\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8922 - mean_absolute_error: 6.8922\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7767 - mean_absolute_error: 6.7767\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6784 - mean_absolute_error: 6.6784\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5699 - mean_absolute_error: 6.5699\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4956 - mean_absolute_error: 6.4956\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3995 - mean_absolute_error: 6.3995\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3103 - mean_absolute_error: 6.3103\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2158 - mean_absolute_error: 6.2158\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1037 - mean_absolute_error: 6.1037\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.0107 - mean_absolute_error: 6.0107\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9117 - mean_absolute_error: 5.9117\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7973 - mean_absolute_error: 5.7973\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7067 - mean_absolute_error: 5.7067\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6390 - mean_absolute_error: 5.6390\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5858 - mean_absolute_error: 5.5858\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5149 - mean_absolute_error: 5.5149\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4945 - mean_absolute_error: 5.4945\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4507 - mean_absolute_error: 5.4507\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4164 - mean_absolute_error: 5.4164\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3745 - mean_absolute_error: 5.3745\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.3522 - mean_absolute_error: 5.3522\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3255 - mean_absolute_error: 5.3255\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2845 - mean_absolute_error: 5.2845\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2597 - mean_absolute_error: 5.2597\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2483 - mean_absolute_error: 5.2483\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2136 - mean_absolute_error: 5.2136\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1890 - mean_absolute_error: 5.1890\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1621 - mean_absolute_error: 5.1621\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1518 - mean_absolute_error: 5.1518\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1287 - mean_absolute_error: 5.1287\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1292 - mean_absolute_error: 5.1292\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1171 - mean_absolute_error: 5.1171\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1118 - mean_absolute_error: 5.1118\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0758 - mean_absolute_error: 5.0758\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0597 - mean_absolute_error: 5.0597\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0834 - mean_absolute_error: 5.0834\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0366 - mean_absolute_error: 5.0366\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0589 - mean_absolute_error: 5.0589\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0270 - mean_absolute_error: 5.0270\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0270 - mean_absolute_error: 5.0270\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9803 - mean_absolute_error: 4.9803\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9935 - mean_absolute_error: 4.9935\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9927 - mean_absolute_error: 4.9927\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9548 - mean_absolute_error: 4.9548\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 5.2355 - mean_absolute_error: 5.2355\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_13 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,345\n",
            "Trainable params: 9,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 5ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 23.5842 - mean_absolute_error: 23.5842\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_14 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,793\n",
            "Trainable params: 17,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 20.1651 - mean_absolute_error: 20.1651\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.6162 - mean_absolute_error: 16.6162\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.9153 - mean_absolute_error: 13.9153\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.6355 - mean_absolute_error: 11.6355\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.8522 - mean_absolute_error: 9.8522\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.6085 - mean_absolute_error: 8.6085\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.7795 - mean_absolute_error: 7.7795\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0321 - mean_absolute_error: 7.0321\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6703 - mean_absolute_error: 6.6703\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4560 - mean_absolute_error: 6.4560\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3566 - mean_absolute_error: 6.3566\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2242 - mean_absolute_error: 6.2242\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1294 - mean_absolute_error: 6.1294\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0443 - mean_absolute_error: 6.0443\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9437 - mean_absolute_error: 5.9437\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.8587 - mean_absolute_error: 5.8587\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7322 - mean_absolute_error: 5.7322\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6311 - mean_absolute_error: 5.6311\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5210 - mean_absolute_error: 5.5210\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4422 - mean_absolute_error: 5.4422\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3942 - mean_absolute_error: 5.3942\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3459 - mean_absolute_error: 5.3459\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3286 - mean_absolute_error: 5.3286\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3152 - mean_absolute_error: 5.3152\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2936 - mean_absolute_error: 5.2936\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2926 - mean_absolute_error: 5.2926\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2713 - mean_absolute_error: 5.2713\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2370 - mean_absolute_error: 5.2370\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2170 - mean_absolute_error: 5.2170\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2951 - mean_absolute_error: 5.2951\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2224 - mean_absolute_error: 5.2224\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1848 - mean_absolute_error: 5.1848\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1973 - mean_absolute_error: 5.1973\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1798 - mean_absolute_error: 5.1798\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2198 - mean_absolute_error: 5.2198\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2174 - mean_absolute_error: 5.2174\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1333 - mean_absolute_error: 5.1333\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1621 - mean_absolute_error: 5.1621\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1247 - mean_absolute_error: 5.1247\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1751 - mean_absolute_error: 5.1751\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0860 - mean_absolute_error: 5.0860\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0785 - mean_absolute_error: 5.0785\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1304 - mean_absolute_error: 5.1304\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1954 - mean_absolute_error: 5.1954\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0516 - mean_absolute_error: 5.0516\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0684 - mean_absolute_error: 5.0684\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0189 - mean_absolute_error: 5.0189\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0565 - mean_absolute_error: 5.0565\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0243 - mean_absolute_error: 5.0243\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0202 - mean_absolute_error: 5.0202\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9927 - mean_absolute_error: 4.9927\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9957 - mean_absolute_error: 4.9957\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0577 - mean_absolute_error: 5.0577\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9795 - mean_absolute_error: 4.9795\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0065 - mean_absolute_error: 5.0065\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0013 - mean_absolute_error: 5.0013\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9572 - mean_absolute_error: 4.9572\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9432 - mean_absolute_error: 4.9432\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9667 - mean_absolute_error: 4.9667\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9836 - mean_absolute_error: 4.9836\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9338 - mean_absolute_error: 4.9338\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9448 - mean_absolute_error: 4.9448\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9572 - mean_absolute_error: 4.9572\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9249 - mean_absolute_error: 4.9249\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9585 - mean_absolute_error: 4.9585\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8905 - mean_absolute_error: 4.8905\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8929 - mean_absolute_error: 4.8929\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9389 - mean_absolute_error: 4.9389\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9832 - mean_absolute_error: 4.9832\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8887 - mean_absolute_error: 4.8887\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8894 - mean_absolute_error: 4.8894\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9253 - mean_absolute_error: 4.9253\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8835 - mean_absolute_error: 4.8835\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8755 - mean_absolute_error: 4.8755\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8524 - mean_absolute_error: 4.8524\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8977 - mean_absolute_error: 4.8977\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8538 - mean_absolute_error: 4.8538\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8336 - mean_absolute_error: 4.8336\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8370 - mean_absolute_error: 4.8370\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9221 - mean_absolute_error: 4.9221\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 5.1446 - mean_absolute_error: 5.1446\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_15 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 16)                2064      \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,873\n",
            "Trainable params: 3,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 21.3176 - mean_absolute_error: 21.3176\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.5359 - mean_absolute_error: 20.5359\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.2013 - mean_absolute_error: 20.2013\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.9974 - mean_absolute_error: 19.9974\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.8452 - mean_absolute_error: 19.8452\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.7190 - mean_absolute_error: 19.7190\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 19.6148 - mean_absolute_error: 19.6148\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.5203 - mean_absolute_error: 19.5203\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.4332 - mean_absolute_error: 19.4332\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.3512 - mean_absolute_error: 19.3512\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.2715 - mean_absolute_error: 19.2715\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.1941 - mean_absolute_error: 19.1941\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.1187 - mean_absolute_error: 19.1187\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.0443 - mean_absolute_error: 19.0443\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.9707 - mean_absolute_error: 18.9707\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.8975 - mean_absolute_error: 18.8975\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.8247 - mean_absolute_error: 18.8247\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.7521 - mean_absolute_error: 18.7521\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.6797 - mean_absolute_error: 18.6797\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.6073 - mean_absolute_error: 18.6073\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.5351 - mean_absolute_error: 18.5351\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.4630 - mean_absolute_error: 18.4630\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.3908 - mean_absolute_error: 18.3908\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.3187 - mean_absolute_error: 18.3187\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.2457 - mean_absolute_error: 18.2457\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.1641 - mean_absolute_error: 18.1641\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.0565 - mean_absolute_error: 18.0565\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.9569 - mean_absolute_error: 17.9569\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.8685 - mean_absolute_error: 17.8685\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.7841 - mean_absolute_error: 17.7841\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.7004 - mean_absolute_error: 17.7004\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.6111 - mean_absolute_error: 17.6111\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.5041 - mean_absolute_error: 17.5041\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.3826 - mean_absolute_error: 17.3826\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.2778 - mean_absolute_error: 17.2778\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.1804 - mean_absolute_error: 17.1804\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.0816 - mean_absolute_error: 17.0816\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.9661 - mean_absolute_error: 16.9661\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.8361 - mean_absolute_error: 16.8361\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.7237 - mean_absolute_error: 16.7237\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.6202 - mean_absolute_error: 16.6202\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.5204 - mean_absolute_error: 16.5204\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.4225 - mean_absolute_error: 16.4225\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.3256 - mean_absolute_error: 16.3256\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.2294 - mean_absolute_error: 16.2294\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.1338 - mean_absolute_error: 16.1338\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.0391 - mean_absolute_error: 16.0391\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.9443 - mean_absolute_error: 15.9443\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.8496 - mean_absolute_error: 15.8496\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.7551 - mean_absolute_error: 15.7551\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.6606 - mean_absolute_error: 15.6606\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.5662 - mean_absolute_error: 15.5662\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.4717 - mean_absolute_error: 15.4717\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.3773 - mean_absolute_error: 15.3773\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.2829 - mean_absolute_error: 15.2829\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.1888 - mean_absolute_error: 15.1888\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.0953 - mean_absolute_error: 15.0953\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.0016 - mean_absolute_error: 15.0016\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.9081 - mean_absolute_error: 14.9081\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.8152 - mean_absolute_error: 14.8152\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.7220 - mean_absolute_error: 14.7220\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6286 - mean_absolute_error: 14.6286\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.5352 - mean_absolute_error: 14.5352\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.4419 - mean_absolute_error: 14.4419\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.3487 - mean_absolute_error: 14.3487\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.2556 - mean_absolute_error: 14.2556\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.1626 - mean_absolute_error: 14.1626\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.0709 - mean_absolute_error: 14.0709\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.9803 - mean_absolute_error: 13.9803\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.8913 - mean_absolute_error: 13.8913\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.8021 - mean_absolute_error: 13.8021\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.7128 - mean_absolute_error: 13.7128\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.6251 - mean_absolute_error: 13.6251\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.5374 - mean_absolute_error: 13.5374\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.4495 - mean_absolute_error: 13.4495\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.3616 - mean_absolute_error: 13.3616\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.2773 - mean_absolute_error: 13.2773\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.1871 - mean_absolute_error: 13.1871\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.0983 - mean_absolute_error: 13.0983\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.0096 - mean_absolute_error: 13.0096\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 14.0992 - mean_absolute_error: 14.0992\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,953\n",
            "Trainable params: 5,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3991 - mean_absolute_error: 22.3991\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 23.5842 - mean_absolute_error: 23.5842\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3991 - mean_absolute_error: 22.3991\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 22.3992 - mean_absolute_error: 22.3992\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 23.5842 - mean_absolute_error: 23.5842\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,433\n",
            "Trainable params: 18,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 20.1571 - mean_absolute_error: 20.1571\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.9213 - mean_absolute_error: 16.9213\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.0091 - mean_absolute_error: 15.0091\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.7318 - mean_absolute_error: 13.7318\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7979 - mean_absolute_error: 12.7979\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.9962 - mean_absolute_error: 11.9962\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.2984 - mean_absolute_error: 11.2984\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.6767 - mean_absolute_error: 10.6767\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.1100 - mean_absolute_error: 10.1100\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.6263 - mean_absolute_error: 9.6263\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.1676 - mean_absolute_error: 9.1676\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.8089 - mean_absolute_error: 8.8089\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.4147 - mean_absolute_error: 8.4147\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.1160 - mean_absolute_error: 8.1160\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.8182 - mean_absolute_error: 7.8182\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.5485 - mean_absolute_error: 7.5485\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3397 - mean_absolute_error: 7.3397\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0946 - mean_absolute_error: 7.0946\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9272 - mean_absolute_error: 6.9272\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7401 - mean_absolute_error: 6.7401\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4822 - mean_absolute_error: 6.4822\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1912 - mean_absolute_error: 6.1912\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0063 - mean_absolute_error: 6.0063\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8586 - mean_absolute_error: 5.8586\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7506 - mean_absolute_error: 5.7506\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6445 - mean_absolute_error: 5.6445\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.5606 - mean_absolute_error: 5.5606\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5528 - mean_absolute_error: 5.5528\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4546 - mean_absolute_error: 5.4546\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4579 - mean_absolute_error: 5.4579\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4281 - mean_absolute_error: 5.4281\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3756 - mean_absolute_error: 5.3756\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3090 - mean_absolute_error: 5.3090\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2765 - mean_absolute_error: 5.2765\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2590 - mean_absolute_error: 5.2590\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2139 - mean_absolute_error: 5.2139\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2019 - mean_absolute_error: 5.2019\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2077 - mean_absolute_error: 5.2077\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2182 - mean_absolute_error: 5.2182\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1674 - mean_absolute_error: 5.1674\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1968 - mean_absolute_error: 5.1968\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1015 - mean_absolute_error: 5.1015\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1210 - mean_absolute_error: 5.1210\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1037 - mean_absolute_error: 5.1037\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0441 - mean_absolute_error: 5.0441\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0147 - mean_absolute_error: 5.0147\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9886 - mean_absolute_error: 4.9886\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9708 - mean_absolute_error: 4.9708\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9585 - mean_absolute_error: 4.9585\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9734 - mean_absolute_error: 4.9734\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8949 - mean_absolute_error: 4.8949\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9098 - mean_absolute_error: 4.9098\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9004 - mean_absolute_error: 4.9004\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8711 - mean_absolute_error: 4.8711\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8300 - mean_absolute_error: 4.8300\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8816 - mean_absolute_error: 4.8816\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8377 - mean_absolute_error: 4.8377\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7964 - mean_absolute_error: 4.7964\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7998 - mean_absolute_error: 4.7998\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7268 - mean_absolute_error: 4.7268\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7425 - mean_absolute_error: 4.7425\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7680 - mean_absolute_error: 4.7680\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6906 - mean_absolute_error: 4.6906\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7221 - mean_absolute_error: 4.7221\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6239 - mean_absolute_error: 4.6239\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5965 - mean_absolute_error: 4.5965\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6276 - mean_absolute_error: 4.6276\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5817 - mean_absolute_error: 4.5817\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5451 - mean_absolute_error: 4.5451\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5032 - mean_absolute_error: 4.5032\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5231 - mean_absolute_error: 4.5231\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5024 - mean_absolute_error: 4.5024\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4971 - mean_absolute_error: 4.4971\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4562 - mean_absolute_error: 4.4562\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3833 - mean_absolute_error: 4.3833\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4069 - mean_absolute_error: 4.4069\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4022 - mean_absolute_error: 4.4022\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.3106 - mean_absolute_error: 4.3106\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.3214 - mean_absolute_error: 4.3214\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2637 - mean_absolute_error: 4.2637\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.6558 - mean_absolute_error: 4.6558\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,073\n",
            "Trainable params: 35,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 4ms/step - loss: 18.1787 - mean_absolute_error: 18.1787\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.1165 - mean_absolute_error: 13.1165\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.2917 - mean_absolute_error: 10.2917\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.7724 - mean_absolute_error: 8.7724\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.9853 - mean_absolute_error: 7.9853\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2574 - mean_absolute_error: 7.2574\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7997 - mean_absolute_error: 6.7997\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5622 - mean_absolute_error: 6.5622\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.4483 - mean_absolute_error: 6.4483\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3072 - mean_absolute_error: 6.3072\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1003 - mean_absolute_error: 6.1003\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.8732 - mean_absolute_error: 5.8732\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6979 - mean_absolute_error: 5.6979\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5355 - mean_absolute_error: 5.5355\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4300 - mean_absolute_error: 5.4300\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4241 - mean_absolute_error: 5.4241\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3742 - mean_absolute_error: 5.3742\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2994 - mean_absolute_error: 5.2994\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3188 - mean_absolute_error: 5.3188\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2305 - mean_absolute_error: 5.2305\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2241 - mean_absolute_error: 5.2241\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2143 - mean_absolute_error: 5.2143\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1805 - mean_absolute_error: 5.1805\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1608 - mean_absolute_error: 5.1608\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1254 - mean_absolute_error: 5.1254\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1130 - mean_absolute_error: 5.1130\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0416 - mean_absolute_error: 5.0416\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0805 - mean_absolute_error: 5.0805\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0107 - mean_absolute_error: 5.0107\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9954 - mean_absolute_error: 4.9954\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1219 - mean_absolute_error: 5.1219\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9665 - mean_absolute_error: 4.9665\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0017 - mean_absolute_error: 5.0017\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9858 - mean_absolute_error: 4.9858\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9425 - mean_absolute_error: 4.9425\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9017 - mean_absolute_error: 4.9017\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9133 - mean_absolute_error: 4.9133\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8132 - mean_absolute_error: 4.8132\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7914 - mean_absolute_error: 4.7914\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7928 - mean_absolute_error: 4.7928\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7668 - mean_absolute_error: 4.7668\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7146 - mean_absolute_error: 4.7146\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7381 - mean_absolute_error: 4.7381\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6598 - mean_absolute_error: 4.6598\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6365 - mean_absolute_error: 4.6365\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8540 - mean_absolute_error: 4.8540\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6019 - mean_absolute_error: 4.6019\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6433 - mean_absolute_error: 4.6433\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5781 - mean_absolute_error: 4.5781\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5470 - mean_absolute_error: 4.5470\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5772 - mean_absolute_error: 4.5772\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4918 - mean_absolute_error: 4.4918\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5011 - mean_absolute_error: 4.5011\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4897 - mean_absolute_error: 4.4897\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4960 - mean_absolute_error: 4.4960\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5022 - mean_absolute_error: 4.5022\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4924 - mean_absolute_error: 4.4924\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4692 - mean_absolute_error: 4.4692\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.3509 - mean_absolute_error: 4.3509\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4776 - mean_absolute_error: 4.4776\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3814 - mean_absolute_error: 4.3814\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3036 - mean_absolute_error: 4.3036\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3369 - mean_absolute_error: 4.3369\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2530 - mean_absolute_error: 4.2530\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2890 - mean_absolute_error: 4.2890\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.1736 - mean_absolute_error: 4.1736\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4358 - mean_absolute_error: 4.4358\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2717 - mean_absolute_error: 4.2717\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1389 - mean_absolute_error: 4.1389\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2144 - mean_absolute_error: 4.2144\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1524 - mean_absolute_error: 4.1524\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0666 - mean_absolute_error: 4.0666\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2090 - mean_absolute_error: 4.2090\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2335 - mean_absolute_error: 4.2335\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0517 - mean_absolute_error: 4.0517\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8936 - mean_absolute_error: 3.8936\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.1538 - mean_absolute_error: 4.1538\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8520 - mean_absolute_error: 3.8520\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9504 - mean_absolute_error: 3.9504\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.9440 - mean_absolute_error: 3.9440\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.9765 - mean_absolute_error: 3.9765\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_20 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 256)               3584      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 16)                4112      \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,713\n",
            "Trainable params: 7,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 20.5895 - mean_absolute_error: 20.5895\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.0443 - mean_absolute_error: 19.0443\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.6129 - mean_absolute_error: 18.6129\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.4025 - mean_absolute_error: 18.4025\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.2471 - mean_absolute_error: 18.2471\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.1167 - mean_absolute_error: 18.1167\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.9970 - mean_absolute_error: 17.9970\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.8836 - mean_absolute_error: 17.8836\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.7733 - mean_absolute_error: 17.7733\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.6652 - mean_absolute_error: 17.6652\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.5583 - mean_absolute_error: 17.5583\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.4526 - mean_absolute_error: 17.4526\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.3484 - mean_absolute_error: 17.3484\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.2452 - mean_absolute_error: 17.2452\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.1420 - mean_absolute_error: 17.1420\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.0390 - mean_absolute_error: 17.0390\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.9360 - mean_absolute_error: 16.9360\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.8330 - mean_absolute_error: 16.8330\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.7302 - mean_absolute_error: 16.7302\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.6272 - mean_absolute_error: 16.6272\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.5244 - mean_absolute_error: 16.5244\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 16.4216 - mean_absolute_error: 16.4216\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.3187 - mean_absolute_error: 16.3187\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.2158 - mean_absolute_error: 16.2158\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.1130 - mean_absolute_error: 16.1130\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.0110 - mean_absolute_error: 16.0110\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.9090 - mean_absolute_error: 15.9090\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.8069 - mean_absolute_error: 15.8069\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.7048 - mean_absolute_error: 15.7048\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.6024 - mean_absolute_error: 15.6024\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.5002 - mean_absolute_error: 15.5002\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.4027 - mean_absolute_error: 15.4027\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.2989 - mean_absolute_error: 15.2989\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.1964 - mean_absolute_error: 15.1964\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.0948 - mean_absolute_error: 15.0948\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.9932 - mean_absolute_error: 14.9932\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.8918 - mean_absolute_error: 14.8918\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.7912 - mean_absolute_error: 14.7912\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6904 - mean_absolute_error: 14.6904\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.5894 - mean_absolute_error: 14.5894\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.4885 - mean_absolute_error: 14.4885\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.3875 - mean_absolute_error: 14.3875\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.2865 - mean_absolute_error: 14.2865\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.1856 - mean_absolute_error: 14.1856\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.0858 - mean_absolute_error: 14.0858\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.9876 - mean_absolute_error: 13.9876\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.8909 - mean_absolute_error: 13.8909\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.7942 - mean_absolute_error: 13.7942\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.6977 - mean_absolute_error: 13.6977\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.6031 - mean_absolute_error: 13.6031\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.5079 - mean_absolute_error: 13.5079\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.4120 - mean_absolute_error: 13.4120\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.3166 - mean_absolute_error: 13.3166\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.2214 - mean_absolute_error: 13.2214\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.1299 - mean_absolute_error: 13.1299\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.0325 - mean_absolute_error: 13.0325\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.9368 - mean_absolute_error: 12.9368\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.8418 - mean_absolute_error: 12.8418\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.7468 - mean_absolute_error: 12.7468\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.6520 - mean_absolute_error: 12.6520\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.5568 - mean_absolute_error: 12.5568\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.4616 - mean_absolute_error: 12.4616\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.3671 - mean_absolute_error: 12.3671\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.2733 - mean_absolute_error: 12.2733\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.1794 - mean_absolute_error: 12.1794\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.0867 - mean_absolute_error: 12.0867\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.9946 - mean_absolute_error: 11.9946\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.9021 - mean_absolute_error: 11.9021\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.8103 - mean_absolute_error: 11.8103\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.7195 - mean_absolute_error: 11.7195\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.6301 - mean_absolute_error: 11.6301\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.5402 - mean_absolute_error: 11.5402\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.4499 - mean_absolute_error: 11.4499\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.3604 - mean_absolute_error: 11.3604\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.2714 - mean_absolute_error: 11.2714\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.1828 - mean_absolute_error: 11.1828\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0938 - mean_absolute_error: 11.0938\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0060 - mean_absolute_error: 11.0060\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.9197 - mean_absolute_error: 10.9197\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.8384 - mean_absolute_error: 10.8384\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 11.9363 - mean_absolute_error: 11.9363\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_21 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 256)               3584      \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 32)                8224      \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,841\n",
            "Trainable params: 11,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 20.7696 - mean_absolute_error: 20.7696\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 18.8679 - mean_absolute_error: 18.8679\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.2774 - mean_absolute_error: 18.2774\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.9648 - mean_absolute_error: 17.9648\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.7344 - mean_absolute_error: 17.7344\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.5384 - mean_absolute_error: 17.5384\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.3574 - mean_absolute_error: 17.3574\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.1876 - mean_absolute_error: 17.1876\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.0224 - mean_absolute_error: 17.0224\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.8580 - mean_absolute_error: 16.8580\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.6779 - mean_absolute_error: 16.6779\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.4918 - mean_absolute_error: 16.4918\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.3003 - mean_absolute_error: 16.3003\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.1093 - mean_absolute_error: 16.1093\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.9307 - mean_absolute_error: 15.9307\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.7552 - mean_absolute_error: 15.7552\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.5759 - mean_absolute_error: 15.5759\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.3662 - mean_absolute_error: 15.3662\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.1790 - mean_absolute_error: 15.1790\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.9924 - mean_absolute_error: 14.9924\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.8107 - mean_absolute_error: 14.8107\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6310 - mean_absolute_error: 14.6310\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.4521 - mean_absolute_error: 14.4521\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.2731 - mean_absolute_error: 14.2731\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.0953 - mean_absolute_error: 14.0953\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.9230 - mean_absolute_error: 13.9230\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.7524 - mean_absolute_error: 13.7524\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.5636 - mean_absolute_error: 13.5636\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.3644 - mean_absolute_error: 13.3644\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.1765 - mean_absolute_error: 13.1765\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.9973 - mean_absolute_error: 12.9973\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.8220 - mean_absolute_error: 12.8220\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6533 - mean_absolute_error: 12.6533\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.4736 - mean_absolute_error: 12.4736\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.2981 - mean_absolute_error: 12.2981\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.1249 - mean_absolute_error: 12.1249\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.9559 - mean_absolute_error: 11.9559\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.7948 - mean_absolute_error: 11.7948\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.6253 - mean_absolute_error: 11.6253\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.4668 - mean_absolute_error: 11.4668\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.2980 - mean_absolute_error: 11.2980\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.1327 - mean_absolute_error: 11.1327\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.9711 - mean_absolute_error: 10.9711\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.8214 - mean_absolute_error: 10.8214\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.6615 - mean_absolute_error: 10.6615\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.5036 - mean_absolute_error: 10.5036\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.3492 - mean_absolute_error: 10.3492\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.2058 - mean_absolute_error: 10.2058\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.0618 - mean_absolute_error: 10.0618\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.9132 - mean_absolute_error: 9.9132\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.7620 - mean_absolute_error: 9.7620\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.6218 - mean_absolute_error: 9.6218\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.4892 - mean_absolute_error: 9.4892\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.3593 - mean_absolute_error: 9.3593\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.2342 - mean_absolute_error: 9.2342\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.1106 - mean_absolute_error: 9.1106\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9968 - mean_absolute_error: 8.9968\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.8892 - mean_absolute_error: 8.8892\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.7669 - mean_absolute_error: 8.7669\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.6568 - mean_absolute_error: 8.6568\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.5470 - mean_absolute_error: 8.5470\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.4497 - mean_absolute_error: 8.4497\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.3438 - mean_absolute_error: 8.3438\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.2484 - mean_absolute_error: 8.2484\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.1419 - mean_absolute_error: 8.1419\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.0473 - mean_absolute_error: 8.0473\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.9440 - mean_absolute_error: 7.9440\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.8593 - mean_absolute_error: 7.8593\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.7581 - mean_absolute_error: 7.7581\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.6697 - mean_absolute_error: 7.6697\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5891 - mean_absolute_error: 7.5891\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.4967 - mean_absolute_error: 7.4967\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.4008 - mean_absolute_error: 7.4008\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2903 - mean_absolute_error: 7.2903\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.1459 - mean_absolute_error: 7.1459\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9851 - mean_absolute_error: 6.9851\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8485 - mean_absolute_error: 6.8485\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7404 - mean_absolute_error: 6.7404\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6361 - mean_absolute_error: 6.6361\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5395 - mean_absolute_error: 6.5395\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 7.2240 - mean_absolute_error: 7.2240\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_22 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 256)               3584      \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,097\n",
            "Trainable params: 20,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 20.3113 - mean_absolute_error: 20.3113\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.1049 - mean_absolute_error: 18.1049\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.3621 - mean_absolute_error: 17.3621\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.9362 - mean_absolute_error: 16.9362\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.6030 - mean_absolute_error: 16.6030\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.2976 - mean_absolute_error: 16.2976\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 16.0074 - mean_absolute_error: 16.0074\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.7121 - mean_absolute_error: 15.7121\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.4137 - mean_absolute_error: 15.4137\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.1157 - mean_absolute_error: 15.1157\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.8230 - mean_absolute_error: 14.8230\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.5433 - mean_absolute_error: 14.5433\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.2667 - mean_absolute_error: 14.2667\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.9962 - mean_absolute_error: 13.9962\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.7177 - mean_absolute_error: 13.7177\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.4412 - mean_absolute_error: 13.4412\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.1868 - mean_absolute_error: 13.1868\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.8903 - mean_absolute_error: 12.8903\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.5792 - mean_absolute_error: 12.5792\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.2788 - mean_absolute_error: 12.2788\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.9711 - mean_absolute_error: 11.9711\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.6660 - mean_absolute_error: 11.6660\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.3673 - mean_absolute_error: 11.3673\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.0872 - mean_absolute_error: 11.0872\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.8336 - mean_absolute_error: 10.8336\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.5670 - mean_absolute_error: 10.5670\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.3140 - mean_absolute_error: 10.3140\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.0148 - mean_absolute_error: 10.0148\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.7205 - mean_absolute_error: 9.7205\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.4586 - mean_absolute_error: 9.4586\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.2188 - mean_absolute_error: 9.2188\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9894 - mean_absolute_error: 8.9894\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.7799 - mean_absolute_error: 8.7799\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.5914 - mean_absolute_error: 8.5914\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.4245 - mean_absolute_error: 8.4245\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.2459 - mean_absolute_error: 8.2459\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.0597 - mean_absolute_error: 8.0597\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.8902 - mean_absolute_error: 7.8902\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.7146 - mean_absolute_error: 7.7146\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5331 - mean_absolute_error: 7.5331\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3128 - mean_absolute_error: 7.3128\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.0908 - mean_absolute_error: 7.0908\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8884 - mean_absolute_error: 6.8884\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.7194 - mean_absolute_error: 6.7194\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5281 - mean_absolute_error: 6.5281\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3713 - mean_absolute_error: 6.3713\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2245 - mean_absolute_error: 6.2245\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1009 - mean_absolute_error: 6.1009\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9817 - mean_absolute_error: 5.9817\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8521 - mean_absolute_error: 5.8521\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7444 - mean_absolute_error: 5.7444\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6715 - mean_absolute_error: 5.6715\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5935 - mean_absolute_error: 5.5935\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5088 - mean_absolute_error: 5.5088\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4292 - mean_absolute_error: 5.4292\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3505 - mean_absolute_error: 5.3505\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2972 - mean_absolute_error: 5.2972\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2419 - mean_absolute_error: 5.2419\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1408 - mean_absolute_error: 5.1408\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1080 - mean_absolute_error: 5.1080\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0482 - mean_absolute_error: 5.0482\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0527 - mean_absolute_error: 5.0527\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0132 - mean_absolute_error: 5.0132\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9872 - mean_absolute_error: 4.9872\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9927 - mean_absolute_error: 4.9927\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9004 - mean_absolute_error: 4.9004\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8567 - mean_absolute_error: 4.8567\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9185 - mean_absolute_error: 4.9185\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9097 - mean_absolute_error: 4.9097\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7770 - mean_absolute_error: 4.7770\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8313 - mean_absolute_error: 4.8313\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8077 - mean_absolute_error: 4.8077\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7755 - mean_absolute_error: 4.7755\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7913 - mean_absolute_error: 4.7913\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7543 - mean_absolute_error: 4.7543\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6857 - mean_absolute_error: 4.6857\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7558 - mean_absolute_error: 4.7558\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7141 - mean_absolute_error: 4.7141\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6358 - mean_absolute_error: 4.6358\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7456 - mean_absolute_error: 4.7456\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 5.0763 - mean_absolute_error: 5.0763\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_23 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 256)               3584      \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,609\n",
            "Trainable params: 36,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 5ms/step - loss: 17.6673 - mean_absolute_error: 17.6673\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.8713 - mean_absolute_error: 13.8713\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5744 - mean_absolute_error: 12.5744\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.7006 - mean_absolute_error: 11.7006\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.0186 - mean_absolute_error: 11.0186\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.4180 - mean_absolute_error: 10.4180\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.9194 - mean_absolute_error: 9.9194\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.4550 - mean_absolute_error: 9.4550\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.9958 - mean_absolute_error: 8.9958\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.5964 - mean_absolute_error: 8.5964\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.2956 - mean_absolute_error: 8.2956\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.9585 - mean_absolute_error: 7.9585\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.6832 - mean_absolute_error: 7.6832\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.2939 - mean_absolute_error: 7.2939\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.8731 - mean_absolute_error: 6.8731\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.5321 - mean_absolute_error: 6.5321\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2772 - mean_absolute_error: 6.2772\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1068 - mean_absolute_error: 6.1068\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.9417 - mean_absolute_error: 5.9417\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7539 - mean_absolute_error: 5.7539\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6823 - mean_absolute_error: 5.6823\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.5374 - mean_absolute_error: 5.5374\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4914 - mean_absolute_error: 5.4914\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4160 - mean_absolute_error: 5.4160\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3440 - mean_absolute_error: 5.3440\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3769 - mean_absolute_error: 5.3769\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2647 - mean_absolute_error: 5.2647\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2209 - mean_absolute_error: 5.2209\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1678 - mean_absolute_error: 5.1678\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1426 - mean_absolute_error: 5.1426\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1442 - mean_absolute_error: 5.1442\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0795 - mean_absolute_error: 5.0795\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1069 - mean_absolute_error: 5.1069\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0660 - mean_absolute_error: 5.0660\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0376 - mean_absolute_error: 5.0376\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0587 - mean_absolute_error: 5.0587\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0047 - mean_absolute_error: 5.0047\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9520 - mean_absolute_error: 4.9520\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9248 - mean_absolute_error: 4.9248\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9368 - mean_absolute_error: 4.9368\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8441 - mean_absolute_error: 4.8441\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8683 - mean_absolute_error: 4.8683\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8212 - mean_absolute_error: 4.8212\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0005 - mean_absolute_error: 5.0005\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8505 - mean_absolute_error: 4.8505\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7509 - mean_absolute_error: 4.7509\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7574 - mean_absolute_error: 4.7574\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7209 - mean_absolute_error: 4.7209\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7448 - mean_absolute_error: 4.7448\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6886 - mean_absolute_error: 4.6886\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6363 - mean_absolute_error: 4.6363\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6786 - mean_absolute_error: 4.6786\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6778 - mean_absolute_error: 4.6778\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6030 - mean_absolute_error: 4.6030\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6267 - mean_absolute_error: 4.6267\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5526 - mean_absolute_error: 4.5526\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5222 - mean_absolute_error: 4.5222\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7601 - mean_absolute_error: 4.7601\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4679 - mean_absolute_error: 4.4679\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5721 - mean_absolute_error: 4.5721\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4645 - mean_absolute_error: 4.4645\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3802 - mean_absolute_error: 4.3802\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4271 - mean_absolute_error: 4.4271\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4401 - mean_absolute_error: 4.4401\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4774 - mean_absolute_error: 4.4774\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3109 - mean_absolute_error: 4.3109\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4366 - mean_absolute_error: 4.4366\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.2417 - mean_absolute_error: 4.2417\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4177 - mean_absolute_error: 4.4177\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2856 - mean_absolute_error: 4.2856\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2902 - mean_absolute_error: 4.2902\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2845 - mean_absolute_error: 4.2845\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1023 - mean_absolute_error: 4.1023\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.2076 - mean_absolute_error: 4.2076\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3422 - mean_absolute_error: 4.3422\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.1403 - mean_absolute_error: 4.1403\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1445 - mean_absolute_error: 4.1445\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0888 - mean_absolute_error: 4.0888\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.2533 - mean_absolute_error: 4.2533\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.0470 - mean_absolute_error: 4.0470\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4304 - mean_absolute_error: 4.4304\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_24 (Flatten)        (None, 13)                0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 256)               3584      \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,633\n",
            "Trainable params: 69,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "8/8 [==============================] - 1s 6ms/step - loss: 17.5931 - mean_absolute_error: 17.5931\n",
            "Epoch 2/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.1772 - mean_absolute_error: 12.1772\n",
            "Epoch 3/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.1888 - mean_absolute_error: 10.1888\n",
            "Epoch 4/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.1012 - mean_absolute_error: 9.1012\n",
            "Epoch 5/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.3552 - mean_absolute_error: 8.3552\n",
            "Epoch 6/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8881 - mean_absolute_error: 7.8881\n",
            "Epoch 7/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.3671 - mean_absolute_error: 7.3671\n",
            "Epoch 8/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9912 - mean_absolute_error: 6.9912\n",
            "Epoch 9/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5470 - mean_absolute_error: 6.5470\n",
            "Epoch 10/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1140 - mean_absolute_error: 6.1140\n",
            "Epoch 11/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8803 - mean_absolute_error: 5.8803\n",
            "Epoch 12/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6935 - mean_absolute_error: 5.6935\n",
            "Epoch 13/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5480 - mean_absolute_error: 5.5480\n",
            "Epoch 14/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4474 - mean_absolute_error: 5.4474\n",
            "Epoch 15/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3974 - mean_absolute_error: 5.3974\n",
            "Epoch 16/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3667 - mean_absolute_error: 5.3667\n",
            "Epoch 17/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2948 - mean_absolute_error: 5.2948\n",
            "Epoch 18/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2838 - mean_absolute_error: 5.2838\n",
            "Epoch 19/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2323 - mean_absolute_error: 5.2323\n",
            "Epoch 20/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2863 - mean_absolute_error: 5.2863\n",
            "Epoch 21/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1437 - mean_absolute_error: 5.1437\n",
            "Epoch 22/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1342 - mean_absolute_error: 5.1342\n",
            "Epoch 23/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0737 - mean_absolute_error: 5.0737\n",
            "Epoch 24/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0354 - mean_absolute_error: 5.0354\n",
            "Epoch 25/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0382 - mean_absolute_error: 5.0382\n",
            "Epoch 26/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0362 - mean_absolute_error: 5.0362\n",
            "Epoch 27/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0896 - mean_absolute_error: 5.0896\n",
            "Epoch 28/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0074 - mean_absolute_error: 5.0074\n",
            "Epoch 29/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9723 - mean_absolute_error: 4.9723\n",
            "Epoch 30/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9275 - mean_absolute_error: 4.9275\n",
            "Epoch 31/80\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.9279 - mean_absolute_error: 4.9279\n",
            "Epoch 32/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7904 - mean_absolute_error: 4.7904\n",
            "Epoch 33/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9026 - mean_absolute_error: 4.9026\n",
            "Epoch 34/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9027 - mean_absolute_error: 4.9027\n",
            "Epoch 35/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7489 - mean_absolute_error: 4.7489\n",
            "Epoch 36/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7708 - mean_absolute_error: 4.7708\n",
            "Epoch 37/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7052 - mean_absolute_error: 4.7052\n",
            "Epoch 38/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6532 - mean_absolute_error: 4.6532\n",
            "Epoch 39/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7100 - mean_absolute_error: 4.7100\n",
            "Epoch 40/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7692 - mean_absolute_error: 4.7692\n",
            "Epoch 41/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6039 - mean_absolute_error: 4.6039\n",
            "Epoch 42/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4858 - mean_absolute_error: 4.4858\n",
            "Epoch 43/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5363 - mean_absolute_error: 4.5363\n",
            "Epoch 44/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5226 - mean_absolute_error: 4.5226\n",
            "Epoch 45/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7682 - mean_absolute_error: 4.7682\n",
            "Epoch 46/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4704 - mean_absolute_error: 4.4704\n",
            "Epoch 47/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4313 - mean_absolute_error: 4.4313\n",
            "Epoch 48/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4914 - mean_absolute_error: 4.4914\n",
            "Epoch 49/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3815 - mean_absolute_error: 4.3815\n",
            "Epoch 50/80\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4411 - mean_absolute_error: 4.4411\n",
            "Epoch 51/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3947 - mean_absolute_error: 4.3947\n",
            "Epoch 52/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3005 - mean_absolute_error: 4.3005\n",
            "Epoch 53/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4367 - mean_absolute_error: 4.4367\n",
            "Epoch 54/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1991 - mean_absolute_error: 4.1991\n",
            "Epoch 55/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3139 - mean_absolute_error: 4.3139\n",
            "Epoch 56/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2475 - mean_absolute_error: 4.2475\n",
            "Epoch 57/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1675 - mean_absolute_error: 4.1675\n",
            "Epoch 58/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1368 - mean_absolute_error: 4.1368\n",
            "Epoch 59/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4450 - mean_absolute_error: 4.4450\n",
            "Epoch 60/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1991 - mean_absolute_error: 4.1991\n",
            "Epoch 61/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4241 - mean_absolute_error: 4.4241\n",
            "Epoch 62/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1128 - mean_absolute_error: 4.1128\n",
            "Epoch 63/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0857 - mean_absolute_error: 4.0857\n",
            "Epoch 64/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2890 - mean_absolute_error: 4.2890\n",
            "Epoch 65/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0350 - mean_absolute_error: 4.0350\n",
            "Epoch 66/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1783 - mean_absolute_error: 4.1783\n",
            "Epoch 67/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0154 - mean_absolute_error: 4.0154\n",
            "Epoch 68/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0455 - mean_absolute_error: 4.0455\n",
            "Epoch 69/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0030 - mean_absolute_error: 4.0030\n",
            "Epoch 70/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8855 - mean_absolute_error: 3.8855\n",
            "Epoch 71/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1031 - mean_absolute_error: 4.1031\n",
            "Epoch 72/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7900 - mean_absolute_error: 3.7900\n",
            "Epoch 73/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0580 - mean_absolute_error: 4.0580\n",
            "Epoch 74/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9243 - mean_absolute_error: 3.9243\n",
            "Epoch 75/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8624 - mean_absolute_error: 3.8624\n",
            "Epoch 76/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0037 - mean_absolute_error: 4.0037\n",
            "Epoch 77/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8212 - mean_absolute_error: 3.8212\n",
            "Epoch 78/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9330 - mean_absolute_error: 3.9330\n",
            "Epoch 79/80\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9439 - mean_absolute_error: 3.9439\n",
            "Epoch 80/80\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0210 - mean_absolute_error: 4.0210\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 5.2074 - mean_absolute_error: 5.2074\n",
            "            16         32         64        128       256\n",
            "16   11.463501  23.584209   5.699639   5.828223  5.432215\n",
            "32   23.584209   6.709786   5.649563   5.652644  5.793319\n",
            "64   12.138196  23.584209   5.235470  23.584209  5.144598\n",
            "128  14.099161  23.584209  23.584209   4.655785  3.976454\n",
            "256  11.936255   7.223952   5.076314   4.430404  5.207352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan ploting nilai MAE dari beberapa kombinasi jumlah neuron hidden pada 2 hidden layer di Heatmap\n",
        "plt.style.use(\"seaborn\") \n",
        "plt.figure(figsize=(10,10))\n",
        "warna_heatmap = LinearSegmentedColormap.from_list('gr',[\"g\", \"w\", \"r\"], N=256)\n",
        "heat_map = sns.heatmap(dframe_val_error, linewidth = 1 , annot = True, fmt='.5g', cmap=warna_heatmap)\n",
        "heat_map.set(xlabel='HiddenLayer2', ylabel='HiddenLayer1')\n",
        "plt.title( \"Nilai MAE dari Kombinasi 2 Hidden Layer\" )\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "Eqtvwouz60-D",
        "outputId": "8ebab1f3-f1f2-4f1b-d97b-257c0c734f05"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAJbCAYAAAAPPCVGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3RU1drH8e+kEyCQSu+9KgiXJr2EItWLSAmIXKXIpSgdpPeiIoIg0qQoTXoghE4EghSRIhCQGgmQXgikvn+MjsZACL6k3JnfZ62sNbPP3mfvfWbIPPPsfYIhOTk5GREREREzZ5XVAxARERHJDAp6RERExCIo6BERERGLoKBHRERELIKCHhEREbEICnpERETEIijokQxVrlw5xowZk6LM398fLy8vANasWcNnn30GQJMmTTh16lSa5/tr/b+fs1y5cqxZsybVsRYtWpj6+0N4eDh169Zl3Lhxqc5TuXJlWrZsmerneYKCgihXrtxz6/3dvHnz+Pbbb1OVf//997zzzjum54mJifTt25fJkye/cB/PUq5cOYKCglKV+/r6Mnr06JfWzx9+/vln+vTp89Rj+/fvp3379rRq1YquXbty9erVp9Z72vvE39+f5s2bA2mP/Z133uH7779PVf5PX7tnWbBgAWPHjn1p5xORl8Mmqwcg5u/HH3/k0qVLVKxYMdWxHj16vNC50qpfoEABdu7cmaLOzz//TFxcXKq6O3fuxMvLi02bNvHkyRPs7e1TnGfPnj0vNK7/j48++ihd9SZOnIi9vX2qQC0jNG/e3BREvExVq1Zl2bJlqcrv37/PqFGj+PbbbyldujRr165l/PjxfPfddy/cR0aNXUT+9ynTIxnuww8/ZPr06U899qxvxBs3bqRVq1a0aNGC7t27ExgYmGZ9gCJFihAeHs7du3dNZd7e3tSrVy9V3a1bt/LGG29Qr1499u/f/0+mBcCmTZto3Lgxbdu2Zfv27abypKQkJk2ahKenJ02aNGH48OHEx8cDMGrUKGbMmEHbtm3ZvXs3o0aNYtGiRWn2s3DhQm7evMncuXOxsjL+s33y5Anjx4/H09OTVq1aMXPmTBITEwFjNmT16tV07NiRunXrsnfvXiZNmkSzZs146623iIiIMJ17586dtG3blkaNGrF27VogZZZp1KhRfP755/Tu3ZvGjRvTu3dvYmNjATh79iydOnWiZcuWtG7dmmPHjgGQkJDA2LFj8fT0pHnz5gwcOJDo6OgUGZm/srGxYd68eZQuXRqA1157jWvXrr3w6/H3sd+5c4fOnTvTrFkzPvroI9P1gWe/dsnJyXzxxRd4enrSuHFjpk6damrn5eXFihUr6Nq1K/Xr1+fDDz/kRf++6/79+2nbti2enp506tSJX375hcTEROrVq8f58+dN9dasWcOAAQMAWL9+PS1btqRJkyZ8+OGHPH78GEj9XhKRtCnokQzXqlUrkpOT0509CQkJYfLkyaxYsYK9e/dStGjR5wYFf2jZsiW7du0CjB9e+/fvp3HjxinqBAQEYGtrS5EiRWjXrh1bt259sQn9LiIigmnTpvH111+zY8cOHjx4YDrm6+vLqVOn2LlzJ7t37+bixYt4e3ubjh8/fpxNmzbRqlWr5/azZcsW9uzZw6JFi7CzszOVr1q1iqCgIHbt2sWWLVtM/f11nlu2bGHAgAGMGDGCli1b4uvrS1JSEnv37jXV++2339ixYwfLli1j1qxZhIaGphrDnj17+PTTT/H19SU0NBRfX18Axo8fT58+fdizZw/vv/8+EyZMAMDPz4+7d++yZ88e9u7dS+nSpTl79uwz5+jq6kqDBg1Mz48cOcIrr7zy3GvzPHPnzqVOnTrs27ePXr16cebMGSDt127btm3s2bOHTZs24evry507d1IsPx44cIAVK1bg4+PDiRMnTOdMj4SEBEaNGsWUKVPw8fGhSZMmzJo1C2tra1q1apXi9fP19aVNmzacOnWK+fPns2rVKg4cOECuXLmYP3++qd6LvJdELJ2CHskUY8aMYe7cuTx58uS5dV1dXTl9+jT58+cHoEaNGty5cydd/bRp08b0wXHq1CnKlClD7ty5U9TZsmUL7dq1A4wZhZs3bxIcHGw6fu/evVT7eWbOnJmqr3PnzlGsWDFKlSoFQIcOHUzHPD092bx5M7a2ttjb21OlSpUUc6hTp06KJbVnuXbtGgsXLiQyMjLVMt2hQ4d46623sLGxwcHBgbZt2/LDDz+Yjjdt2hSAsmXLYm9vT61atTAYDJQpUybFh/wf4y5VqhQlS5bkwoULqcbRsGFD8ubNi42NDWXLluXevXuAMWP2x4fta6+9Zpqji4sL169fx9fXl9jYWIYMGUL9+vWfO18wfoivWrUqzT1Fw4cPT/H6jBw58qn1Tp06RevWrQHj0lrJkiWBtF+7gwcP8uabb5I7d25sbGzo3LlziiCxZcuWODg44OjoSPHixU3XIj1sbGw4duwYr776KpDyvd2mTRu8vb1JSkoiPDycCxcu0LhxYw4cOEDr1q3Jly8fAF27dk0xnvS+l0REe3okk1SqVImaNWuyYsUKqlWrlmbdxMREPv/8cw4cOEBiYiIxMTGUKFEiXf2UKVMGgKtXr7Jr1y7TB95fz71jxw4ePXrEvHnzAOMy0Y4dO+jduzeQ/j09ERERKQKqPHnymB6HhoYyZcoULl26hMFgIDg4mF69ej21blpy5szJxo0b+fLLLxk6dCgrVqzA2tra1Mdfz5MnTx5CQkJStAWwsrIyPf7jeVJSkum5s7Oz6XHu3LmJjIxMNY6/ztPa2tq03LNjxw6++eYbYmJiSEpKMi31VK1alXHjxrF69WpGjhxJkyZNTFmgtOzbt48pU6awePFi01LX08yZM4caNWqYnvv7+z91r1NERAS5cuUyPXdycjKVP+u1i4qKYtmyZaxfvx4wvmdcXFxMx/96vr9ei/RavXo1W7ZsIS4ujri4OAwGAwDVqlXD1taWkydPEhQUxOuvv46joyNRUVH4+vri5+cHGDOYfyyV/n3sIpI2BT2SaYYOHUqnTp0oXLhwmvW8vb05cOAAa9aswcXFhQ0bNrBjx45099OmTRt2797NkSNHGDFiRIp9En5+fpQtWzbFZtpLly4xevRoU9CTXk5OTkRFRZme/3VZ6NNPP8XGxoYdO3ZgZ2eX7s3Kf1egQAGcnJz46KOP6NGjB3PnzjVlNdzc3AgPDzfVDQ8Px83N7YX7iIiIoEiRIqbHefLk4eHDh89td//+fcaNG8fGjRupUKECN2/exNPT03T8jyxMeHg4Y8aMYdmyZdStW/eZ5zt27BjTpk1j+fLlpgzM/5eTkxPR0dGm53+8Rmm9dh4eHjRp0uSFN9mnx5kzZ1i6dCkbN26kcOHC/PDDD3z88cem423atGHPnj0EBQXRsWNH03g6duz4zGyWiKSflrck03h4eNC9e3cWLFiQZr2QkBAKFSqEi4sLYWFh7N69m5iYmHT306ZNGzZs2ECVKlVwdHRMcWzLli00a9YsRVnFihWJioriypUr6Z8MUKVKFW7cuMHNmzdN5/7rHMqWLYudnR2XL1/m7NmzPHr06IXO/1c2NjZ89tlnbN26FR8fHwAaNWrEpk2bSExM5NGjR2zbto2GDRu+8Ln/WA68fv06t2/fpkqVKulqFxoaiqOjIyVLliQhIcGUGYmJiWHz5s0sXLgQgLx585qWlZ4lNjaW0aNHs2DBgpcW8AC8+uqrpv1HZ86c4fbt20Dar13Tpk3Ztm2babP2d999l+L4/0doaCiurq4ULFiQ2NhYtmzZwqNHj0wZsjfeeIN9+/Zx9uxZ02vZpEkT9u7dawrM9u3bx1dfffVSxiNiaZTpkUz17rvvsnHjxjTrvPHGG+zatYvmzZtTpEgRhgwZQv/+/Zk5c2aKZZpnKVKkCIUKFUq1tBUZGcnBgwdT/d0gMH7Qbd26lUaNGpn29Pzd7NmzqVq1qum5i4sLI0eOpHfv3uTMmZPOnTunmOfIkSP5/vvvqVGjBiNHjmTs2LEp2r+o/PnzM3v2bIYOHUrp0qXx8vLizp07tGnTBoPBQMuWLf/RZtZChQrRvn17IiMjGTt2LHnz5k1Xu/Lly9OgQQM8PT1xdXVl1KhRnDlzBi8vL5YvX86YMWNo0aIF1tbWFCtWjJkzZz4zsNy/fz+hoaEMGzYsRfmaNWv+UfbqD8OHD+ejjz5i27ZtvPLKK6ZMU1qvXbNmzQgICDBlWooWLcq0adNeuG8fHx9Onz5tel6hQgVmzpzJunXraNasGfny5WPMmDGcO3eOQYMGsWDBAsqVK0fevHkpV64cDg4OgHFpuF+/fnh5eZGUlISrqyuTJk36x9dExJIZkl/0fksREckw7733Hj169PhHWTsRSZuWt0REsonTp08TGBiY7jvdROTFaHlLRCQbGD16NGfOnGHOnDmmP0ApIi+XlrdERETEIujrhIiIiFgELW+JiIhYqt//OGamyAYLS9k66Dl6+2hWD8Fs1S/6+0bJzHzDW6Lf/5FX+TJ9f/tGXtz5/sY/PlltSdp/6Vv+ubN9jf9vWrkvymXxSMzblYEv9rfC5MVpeUtEREQsQrbO9IiIiEgGsrA7BS1rtiIiImKxlOkRERGxVMr0iIiIiJgfZXpEREQslTI9IiIiIuZHmR4RERFLpUyPiIiIiPlRpkdERMRSKdMjIiIiYn6U6REREbFUyvSIiIiImB8FPSIiImIRtLwlIiJiqbS8JSIiImJ+lOkRERGxVMr0iIiIiJgfZXpEREQslTI9IiIiIuZHmR4RERFLpUyPiIiIiPlRpkdERMRSKdMjIiIiYn6U6REREbFUFpbpUdAjIiIiWW727NmcPn2ahIQE+vbtS5UqVRg9ejQJCQnY2NgwZ84c3N3dTfX9/f0ZPHgwZcqUAaBs2bJ8/PHHafahoEdERMRSZZNMz4kTJwgICGD9+vWEhYXRsWNHatWqxVtvvUXr1q1Zu3YtK1asYMSIESna/etf/+Lzzz9Pdz8KekRERCRL1axZk6pVqwLg5OREbGwsEyZMwN7eHgBnZ2cuXrz4/+4ne4R4IiIikvmsrDLvJw3W1tY4OjoCsGnTJho0aICjoyPW1tYkJiaybt062rZtm6rdtWvX6NevH127duWHH3547nSV6REREZFsYd++fWzatInly5cDkJiYyIgRI6hduzZ16tRJUbd48eIMHDiQVq1acefOHXr27MnevXuxs7N75vmV6REREZEsd/ToURYvXszSpUvJnTs3AKNHj6ZYsWIMHDgwVf18+fLRunVrDAYDRYsWxc3Njfv376fZhzI9IiIiliqbbGSOiopi9uzZrFy5krx58wKwfft2bG1tGTRo0FPbbN++nYcPH9KnTx8ePnxISEgI+fLlS7MfBT0iIiKSpby9vQkLC2PIkCGmst9++w0nJye8vLwAKFWqFBMnTmTo0KHMmDGDJk2aMGzYMPbv3098fDwTJ05Mc2kLFPSIiIhYrmyS6enSpQtdunRJV91PP/3U9Hjx4sUv1E/2mK2IiIhIBlOmR0RExFJlk0xPZrGs2YqIiIjFUqZHRETEUinTIyIiImJ+lOkRERGxVMr0iIiIiJgfZXpEREQslTI9IiIiIuZHmR4RERFLpUyPiIiIiPlRpkdERMRSKdMjIiIiYn4U9IiIiIhF0PKWiIiIpbKw5S0FPU8ReCOQLyZ8QfNOzWnSoQkA+7bsY+OSjczfMh+HHA5PbRf3JI4J703gje5vUM+zHgkJCSyfvZwHvz3AIYcD/cf3J2funKb6X037ChtbG94d8W6mzCtbmTUL6tcHGxuYMQPu3YM5cyA+Hp48AS8vCA7+s37DhrBxI1y8aHx+/jwMGmQ8x/TpxnYxMcZ24eF/tvPzA19fmDQpc+eXxWoUrMG8FvO4HnodgIDQAGb4zTAdz5czH7Obz8bWypZfgn9hypEpGDAwvuF4SruUJj4xnilHpnAj/AYl8pZgQsMJJJPMzfCbTD0ylcTkRMq6lmVyo8kAHLx5kCWnl2TJXLPSawVeY07zOVwPM17na6HXmPXDLNPxtyq9RZsybUhMSuRS8CXmHpuLtcGaCQ0nUNipMNZW1nx64lN+CvqJpiWa0vOVnsQnxvMg5gHjD40nISmBwbUGU71AdawN1iz/aTkHbhzIqulmiX8V+hfzW84nIDQAgKshV5l6ZGqqeh/W+ZBX879Kzy09cbBxYGbTmbg6umJvbc+iU4s4dPMQ+XPlZ0bTGdhY2ZCQlMBw3+EEPwqmVelWvFvtXZKSkzh+9zifnfgss6cpmSRDgp6oqChOnTpF48aNiYyMZPHixVy/fp0SJUrw/vvv4+LikhHdvhRPYp+wbuE6KlSrYCo75nuMyLBI8rjmSbPtzrU7UwQ1R72PkjtPbt4f8z6Hdx0m4HwAr9Z9FYCLpy/y4N4DChYtmDETyc4aNYLKlaFuXXBxgbNnwd8fevaEGzdg/Hh47z1jMPRXhw9D584pyz75BLp3h6tXYfRo6NvXGFAB/Oc/YGeXKVPKjk79doqP9n701GPD6w5n1blVHLhxgLH1x5I/V34qulckl10uvLZ4UdipMKPqjWLg7oEMrT2Ur89+jd9tP/q+1hfP0p54B3gzoeEEJh2exOXgy8xsNhMHGwceJzzO5FlmvdP3TjPcd3iq8py2Oen1Si/afduOxOREFrVeRBWPKpRwLkFsQizvbn+Xks4lmdRoEl5bvBhRbwRvbniT6LhoxjUYR9MSTQmJDaG0S2l6be1FHvs8fPvmtxYX9ACcDDzJ4D2Dn3m8lHMpahasSXxSPACNizfmwoMLfH32awrmLsjy9ss5dPMQQ2oPYcPFDey+tptuVbrR+9XeLDi5gGF1h9Hu23bExMew4d8b2OG8wxTImj0Ly/RkyGwHDRpE8O/f0idNmkTu3LkZOHAgxYsXZ+TIkRnR5UtjY2fD4GmDUwQ41etVp9O7nTAYDM9sd+/2Pe7dvkeVWlVMZedOnKNW01oANGzT0BTwxMfFs2vtLt7o9kYGzSKbO3Lkz+AlPBxy5oS33zYGPACFCsHdu+k7V3AwuLoaHzs7/5kdcnWFbt1gieVlH57HgIHqBapz6OYhAKYdnUZQdBDF8hTj/IPzANyNvEvB3AWxMlhRNE9Rzt83lv9w5wfqFq6Law5XHG0d+SX4F5JJZuS+kRYZ8KQlPime+MR4ctjmwNpgjYONAxFPIvAO8Gbe8XkAhMWGkcfe+Lsm4nEEue1yA5DbLjfhj8M5c++MKaCKiosih20OrAyW9SGVHqNeH8WnJz41Pd99bTdfn/0agAK5CnA/+j4Akw5Nwue6D2C89nkd8vI44bEp4AEIfxxOXoe8mTwDySwZ8q8nOjqazr9/qD148ID+/ftTpUoV3n77bWJiYjKiy5fG2toaO/uU2QEHx6cvZ/3VhiUbeKvvWynKgoOCufDjBWZ/NJsl05YQHRkNgPd33jRq2wiHnM8/r1lKSoJHj4yP+/QBb29jmacnXLkC+fLBmjWp21WsCNu2wdGj0KyZsWzoUNi6FS5fNi51rVxpLJ89G8aOhYSETJlSdlTKuRSft/qcVR1WUadwHVO5Sw4XYuJjGFF3BKs6rGJwLeM36IDQAOoVqYeVwYrieYtTyKkQzg7OBIQG0KBYAwDqFamHq6MrBXMXJOJJBFMbT+WbDt/Qo2qPLJljdlDSuSSfeX7G8nbLqVWolqk8LjGOJaeXsLPrTry7e3PhwQVuR9wmISmBuMQ4ALpX7c6ea3sAmPXDLL5981t2dN2BtcEa/0B/kpKTTMFkh/Id8LvtR1JyUuZPMouVdinNl22+ZF2nddQtUjfFsY7lO3Iy8CSBkYGp2n375rfMbTGX6UenAxCbEEtSchJWBiu6VenGjqs7AEwBT1nXshRyKsS5++cyeEbZiJVV5v1kAxkyiqJFizJ9+nTOnz9PrVq12L17N8HBwXz//fe4u7tnRJdZ6pjvMUpVLIV7gdRzy184PyPmjaBQ8ULs/m439+/e59bVW/yr8b+yYKTZTLt2xqBn4EDjcx8fKFfOGMCMGpWybkCAcV9O+/bQqxcsWwa2trBgAXTsCOXLG/fvDBhgDH4SE+H48cyfUzZxO+I2X576kkG7BzH2wFgmNZqEjdWfq9keOT1Yc34Nvbf1prxbeeoXrY/fbT8uPLjAyvYr6VG1BzfCjJm3ucfm4lnKk6/bfW3KdhoMBgrnLsycY3N4f+f7dCjXgVLOpbJkrlnpdsRtlpxewhCfIYw/NJ4JDSeYrnNO25z0qdaHDus70GZdGyp7VKasS1lT27cqvUV5t/J8deYrDBgYUW8EPbb0oO23bUlMTqRhsYamuo2KNaJDuQ4p9gtZipvhN/ni5Bf039WfkftGMq3JNGytbAHIY5+HThU6seKnFU9t23VzV/rv6s+c5nNMZVYGK2Y3n82Juyc4cfeEqbxYnmLMbTGXj/Z+REKS5X5ZMncZsqdn1qxZbNiwgc8//5zAwECSk5Nxc3OjQYMGjBs3LiO6zFI/+/9M8L1gfj7xM2HBYdjY2uDs7oxTXifKVjX+kqtUoxLbVm3j55M/E/IghOn/nU7so1iiIqLYvX43rbq0yuJZZLIWLYyZmJYtITISOnQwZmwANm+GiRNT1v/tN9iwwfj4118hKMi4DFa1Khw7Ziz39TXu7ylWDGrUMAY97u5gbw/Xrz89e2SmHsQ8MKXx70beJfhRMPly5iMwKpDwx+Hci7rH3UjjEqJ/oD+lXUpz9PZRFpxcYDqHdzdvQmNDSSaZgbuNgWndInVxd3Qn5FEI10KvEfEkAoCzQWcp7VLacvZB/O7ho4fsvb4XMF7nkNgQPHJ68FvUb5RwLsHdqLuEPzZurD8bdJYK7hW4GnqVDuU60KBYAz70+ZCEpARccrhgwGB6TU4GnqSie0UO3zpMncJ16FO9Dx94f0B0XHSWzTWrPIh5wO5ruwG4E3nH9F6+G3WX2oVr45LDhbWd1mJnbUfRPEUZ/fpotl/ZTkhsCEHRQVwOvoy1lTUuOVwIjQ1lRtMZ3Aq/xcIfF5r6yJczHwtbL2TEvhFcDr6cVVPNGtkkA5NZMiTosbGxoVu3bnTr1i3VsZ49e/LNN99kRLdZpt+4fqbH277Zhls+NypWr8jNqze58OMFXm/5Oreu3iJ/kfw079Sc5p2aA3D53GWO+RyzvIDHycl4p1azZhAWZiybONG4p+fcOahVy7jM9VfdukGBAjBvnnH5K18+CAw0Bj8VKsAvv0DNmsaM0NS/3NnRqxcUL25RAQ9AmzJtcHN0Y9W5VbjmcMXV0ZX7McZ9DYnJidyNvEvRPEW5HXGbim4V2X1tN2Vdy9KjSg/GHxpPvSL1TPt1BtQcwPn75zl6+ygdynVgx9UdBEYFktMuJ072TkQ9iaKcazk2XtqYxbPOfK1Kt8LN0Y3VP682XuccrjyIeQBgDHzylsDe2p4niU+o6F4Rv9t+FMpdiH9X/Df/2fEf0zJX+ONwnOydcHZwJuxxGJXcK3H63mly2eViSO0h9NvZj8gnkVk51SzTtmxb3HO6s/zsctwc3XDN8ed72ee6jym4L5S7EDOazWCG3wx6vdKLQrkLMd1vumn/WVhsGG3LtiU+MT5FcA8wrek0Jh6eyKWHlzJ9fpK5MiToWbt27TOP3b9/PyO6fGluXr3JhiUbCLkfgrW1NaeOnqJi9YpcOnOJiNAI5o+ZT8mKJen8XmeWTFtC72G9U+0B+kPTDk1ZPns5fnv8sM9hb5m3pj9Nly7g5vZn5gbgv/+FRYuMe3BiY423ngN8+y307g3bt8O6dcblLTs76N/feJt6v36wdKnxcWgovKtrDMZbyGc1m0XjEo2xtbJl6pGptCnThqi4KA7cOMCsH2YxtclUrAxWBIQEmDY1WxmsWNdpHXGJcYzcZ7zpwDvAm+lNpjOg5gDO3DvD0dtHAZj9w2y+bPMlySTzw+0fuBpyNaumm2UO3zrM9KbTaVS8EbZWtkw/Op1WpVsRHRfNwZsH+ebcN3zV9isSkxI5d/8cZ4POMvBfA8njkIcFrf784O2/qz8z/WbyWcvPiE+MJzAqEJ/rPrQr1w5nB2dmN59tqvvxwY8Jig7KiulmiQM3DjC3xVyalmiKrZUtEw9P5I2ybxAVF8W+X/c9tc13F75jWtNprO20FgcbByYfnkwyyXSr0g17a3u+6Wj84n099Dqrzq2iRoEaDKo1yNR+5dmVHLhpIXfJWVimx5CcnJz8sk/avHlz6tSpg4eHR6pjW7ZsYf/+/ek6zx+/XOXlq1+0vvFBGnekyUvw+z+vKl9WeU5F+afO9zfeWVZtSbUsHon5Otv3LADlviiXxSMxb1cGXnl+pZetVq3n13lZ/P0zr69nyJBMz8KFC5k6dSrjxo3D7m9/J8U/G0xaREREsLhMT4bMtmzZsixZsgQbm9Qx1ai/35UjIiIikgky7L+hyJEjx1PLK1WqlFFdioiIyItQpkdERETE/Og/HBUREbFUyvSIiIiImB8FPSIiImIRtLwlIiJiqbS8JSIiImJ+lOkRERGxVMr0iIiIiJgfZXpEREQslTI9IiIiIuZHmR4RERFLpUyPiIiIiPlRpkdERMRSKdMjIiIiYn6U6REREbFUyvSIiIiImB9lekRERCyVMj0iIiIi5keZHhEREUulTI+IiIiI+VHQIyIiIhZBy1siIiKWSstbIiIiIuZHmR4RERFLpUyPiIiIiPlRpkdERMRSKdMjIiIiYn6U6REREbFUyvSIiIiImB9lekRERCyVMj0iIiIi5keZHhEREUulTI+IiIiI+VGmR0RExFJZWKZHQY+IiIhkudmzZ3P69GkSEhLo27cvVapUYcSIESQmJuLu7s6cOXOws7NL0Wb69OmcO3cOg8HAmDFjqFq1app9KOgRERGxVNkk03PixAkCAgJYv349YWFhdOzYkTp16tCtWzdatWrFJ598wqZNm+jWrZupzcmTJ7l16xbr16/n+vXrjBkzhvXr16fZT/aYrYiIiFismjVrMn/+fACcnJyIjY3F39+fpk2bAtC4cWOOHz+eos3x48dp1qwZAKVKlSIiIoLo6Og0+1HQIyIiYqmsrDLvJw3W1jfofHoAACAASURBVNY4OjoCsGnTJho0aEBsbKxpOcvV1ZWHDx+maBMcHIyzs7PpuYuLS6o6qab7T66RiIiIyMu2b98+Nm3axPjx41OUJycnP7dteuoo6BEREZEsd/ToURYvXszSpUvJnTs3jo6OPH78GID79+/j4eGRor6HhwfBwcGm5w8ePMDd3T3NPhT0iIiIWKpssrwVFRXF7NmzWbJkCXnz5gWgbt26+Pj4ALB3717q16+fok29evVMxy9evIiHhwe5cuVKsx/dvSUiIiJZytvbm7CwMIYMGWIqmzlzJuPGjWP9+vUULFiQDh06ADB06FBmzJhB9erVqVSpEm+//TYGg4EJEyY8tx8FPSIiIpYqm9yy3qVLF7p06ZKqfMWKFanKPv30U9PjYcOGvVA/2WO2IiIiIhlMmR4RERFLlU0yPZnFkJyee7xERETE/Lz3Xub1tXRp5vX1DMr0iIiIWCoLy/Rk76DHYMjqEZiv3xN8nms8s3gg5s2nh/F2ykqLKmXxSMzXxQEXAV3jjPTHNX5l8StZPBLzdq7fuawegtnL3kGPiIiIZBwLy/RY1mxFRETEYinTIyIiYqmU6RERERExP8r0iIiIWCplekRERETMjzI9IiIilkqZHhERERHzo6BHRERELIKWt0RERCyVlrdEREREzI8yPSIiIpZKmR4RERER86NMj4iIiKVSpkdERETE/CjTIyIiYqmU6RERERExP8r0iIiIWCplekRERETMjzI9IiIilkqZHhERERHzo0yPiIiIpVKmR0RERMT8KNMjIiJiqZTpERERETE/CnpERETEImh5S0RExFJpeUtERETE/CjTIyIiYqmU6RERERExP8r0iIiIWCplekRERETMjzI9IiIilkqZHhERERHzo0yPiIiIpVKmR0RERMT8KNMjIiJiqZTpERERETE/yvSIiIhYKmV6RERERMyPMj0iIiKWSpkeEREREfOjoEdEREQsgpa3RERELJWWt0RERETMjzI9IiIilkqZHhERERHzo0yPiIiIpbKwTI+CnqeZNQvq1wcbG5gxA+7dgzlzID4enjwBLy8IDv6zfsOGsHEjXLxofH7+PAwaZDzH9OnGdjExxnbh4X+28/MDX1+YNClz55cNNC7emLcqvUViUiLf/PwNJwNPAuCaw5WRr4801SuQqwDLzy7nyK0jDKs7DI+cHiQlJzHv+DyCooOo6FaR9197n4SkBC4+vMiKn1ZgZbBiUK1BFM5dGBsrG3Zc3cH+G/uzaqpZombBmnzi+QnXQq8BEBASwHS/6abj+XPlZ07zOdha2XIp+BKTD082HbO3tmfr21tZcmoJW69spUTeEkxsNJHk5GRuRdxi8uHJJCYnUs61HJMbG9sdvHGQxacXZ+4ks4F/cp2f1SZ/rvxMbTwVGysbEpISGLVvFMGxwRZ/nWsUrMGc5nO4HnYdgGsh15j5w0wAPHJ6ML3pn9e7cO7CzPefz6Gbh5jSeAqujq7Exsfy8cGPCYkNoWGxhvSp1of4pHhCY0MZe2As8YnxjK4/mrIuZbGxsmHzL5vZcnlLlsxVMp6Cnr9r1AgqV4a6dcHFBc6eBX9/6NkTbtyA8ePhvfeMwdBfHT4MnTunLPvkE+jeHa5ehdGjoW9fY0AF8J//gJ1dpkwpu8ltl5seVXsw0HsgOWxz4FXVyxT0hMSGMMJ3BABWBivmNJ/D8bvHaVyiMdFx0cz6YRbVC1Tn3VffZbrfdP5b67/M8JvB7YjbDK09lIpuFcltnxsHGweG+Q7DztqOle1XcuDGAZJJzsppZ7pTv51iqM/Qpx4bXnc4K39ayf4b+xlXfxwFchXgXvQ9APrW6Evkk0hT3Q/rfMjSM0vxu+1Hv9f60bJ0S3YF7GJio4lMPDSRy8GXmd18Ng42DjxOeJwpc8tOXvQ6P6vNoH8NYuOljfhc96Fr5a70erUX847P03UGTv92mmG+w1KVP4h5wH+2/wcAa4M1y9ot49DNQ7xZ8U3uRt5lmO8wquWvxoCaA5hyZArdq3RngPcAouOimdxoMk1LNCUoOoiEpATe2fYOOWxy4N3dm62Xt1rO7wsLy/RkyGxDQkKYM2cO48aN48SJEymOTZ48+RmtsokjR/4MXsLDIWdOePttY8ADUKgQ3L2bvnMFB4Orq/Gxs/Of2SFXV+jWDZYseblj/x9RvUB1zt47S2xCLKGxocz3n//Uei1KtcDvth+PEx5TLX81jt05BsDZe2ep6F4RAJccLtyOuA0YfzFWL1idiCcR5LLNhQEDOWxy8CjhkeX8AksHAwZeK/AaB28eBGDq0ammgKdE3hKUci7F4VuHTfWL5SnG+fvnAfjhzg/ULVIX1xyuONo68kvwLySTzHDf4Rb3Qfw8aV3np5lyZAq+v/oCEBobSh6HPLrOL6BduXbsu7GP2IRYiuYpyvkHxvfs2aCzVMtfDYD3d75PdFw01gZrXB1deRDzgLNBZ5n9w2zA+Psk4nGEfl+YsQwJeoYPH07BggWpV68eCxcuZOHChaZj165dy4guX56kJHj0yPi4Tx/w9jaWeXrClSuQLx+sWZO6XcWKsG0bHD0KzZoZy4YOha1b4fJl41LXypXG8tmzYexYSEjIlCllN/ly5sPexp6JjSYyr8U8Xs3/6lPrtSzVEp/rPgA4OzgT8TgCwPQLycbKhqDoICp7VAaMwZSzgzOXgy/z4NEDVnVYxbJ2y1h+dnkmzCr7KeVcii9afcHqjqupU7iOqdwlhwsx8TGMrDeS1R1XM6T2ENOx4fWGmz4A/nA19CoNizcEoF6RerjmcKVg7oJEPI5gWpNprOm4Bq+qXpkzqWzon1znp7WJTYglKTkJK4MVXSt3ZdfVXbrOvyvpXJL5Leezsv1Kaheu/dQ6nSp0YssvxmWpgJAA6hetD8BrBV6jYO6CpnrtyrVjV7dd3I28y+l7p03lc5rPYVWHVSmWJy2ClVXm/WQDGTKK+Ph4unfvTqtWrVi1ahW//vorX3zxBQDJyf8jEXS7dsagZ+BA43MfHyhXzhjAjBqVsm5AgHFfTvv20KsXLFsGtrawYAF07Ajlyxv37wwYYAx+EhPh+PHMn1N2YQAneycmH57M3GNz+ajOR6mqVHCrwJ3IOzyKf5TmqT45/gk9qvRgepPpRMVFYcBAZffKuDu68862d+i7sy/vVnsXGyvLWsm9FXGLRacWMXD3QMbsH8OUxlOwtbIFjBkIj5werPl5Db229qKCWwUaFGtAu3LtOBd0jsCowBTnmntsLp6lPFnebjkGg8H0U8ipELN/mM1/dvyHjuU7Usq5VFZMNUv9k+ucVhsrgxUzm87EP9Af/0B/XWfgdsRtlpxewuA9gxl3cBwTG05M9e+5ar6q3Ai/QUx8DABbLm8hPimele1XUqdIHUJjQ011t1/ZTpt1bchtn5tWpVuZyof7DsdrixdjXh+Do61j5kxOMl2GfBLY2NiwZ88ePD09sbKyYs6cOYwePZpx48YRExOTEV2+XC1aGDMxLVtCZCR06GDM2ABs3gwTJ6as/9tvsGGD8fGvv0JQkHEZrGpVOGZcksHX17i/p1gxqFHDGPS4u4O9PVy//vTskZkKjw3n0sNLJCUncS/6HrHxseSxz0PEkwhTnVqFanE26KzpeUhsCM45nCHcuHZvMBhISErgVsQtRu03BqGty7Qml10uKrpX5Kegn0hKTiIkNoSoJ1G4OboRFB2U6XPNKg9iHrDn2h4A7kTeIfhRMB45PQiMCiTscRj3ou5xJ/IOACfunqC0c2kqelSkiFMRGhZrSL5c+YhLjCMoJogTd0/wgfcHgDHT457TnZBHIVwPvW56zc7cO0Npl9KmzaaW4p9c5yO3jjyzzdQmU7kVcYsvT30JoOuM8Rr/kfG9G3mXkNgQ8uXMlyI4b1CsAf53/U3PE5ISmHZ0GgA5bHLQuHhj7KztqFGwBsfuHCMxOZFDNw9Ro2ANfgn+BQMGboTf4F70Pe5G3aWkc0kuPLiQuRPNKtkkA5NZMmS2M2bM4PDhwzx58sTYiZUVI0eOpFatWthl9827Tk7GO7XeeAPCwoxlEyfCK68YH9eqZVzm+qtu3eCj37MV+fIZfwIDjcFPhQrG8po1jRmhYcOgenWoUwemTIGvv7aogAfg9L3TvJr/VQwYyG1n3HT8142zAGVdy/Jr2K+m52funaF+MWO6unbh2py7fw6AD2t/SIm8JbAyWNG0RFP87/rzW9RvlHMtB4CjrSNujm4pvulZgjZl2vDOq+8A4JbDzbR/ASAxOZE7kXcomqcoABXdK3Ij/AbD9g6jy6YudPu+G5t/2cySU0uMAU/ND2hQrAEAHcp34NDNQwRGBeJo50ge+zwYMFDerTw3w29mxVSz1D+5zs9q06ZMG+IT41n445/bAXSdjV9mer7SEzDe3emSw4X7MfdT1KnsXpkrIX/+Xn696Ot8UNMYqL9R9g38bvuRmJTIhIYTcHd0B6CKRxVuht+kZN6SDKo1CAAHGweK5ylOYGTKbKeYjwzJ9Fy+fJkzZ87Qr18/xowZw7Bhw0hKSuLRo0eMHz8+I7p8ebp0ATe3PzM3AP/9LyxaZNyDExtrvPUc4NtvoXdv2L4d1q0zLm/Z2UH//sbb1Pv1g6VLjY9DQ+Hdd7NmTtlMSGwIR28fZX5L4wbmRacW0axkM2LiY0yblV1yuBD++M/b+w/fOkz1AtWZ12Ie8YnxzDs+D4A91/fwUV1jwHnoxiFuRdzidsRtqhc01rUyWPH1ma+JS4zL5FlmrYM3DzKn+RyaFG+CrbUtkw9Ppk2ZNkTFRbH/xn5m+c1iWtNpGAwGAkICOHTz0DPPtStgFzObzuSDmh9w+rfTHLl1BIBZfrNY/MZikpOT8bvjl+JDx1L8k+ucwzZHqjbxSfF0rdIVe2t7VrRfAcCvYb8y5cgUi7/Oh24eYmbTmTQu3hhbK1umHZ1G6zKtiX4SzYGbBwBSfbH5MfBHulTqwuqOq4l4EsGofaNITE5k8uHJfNbyM+IS4wh5FMLCHxfyOOEx/yr0L1Z1WIWdtR3Lf1pO2OOwrJpu5stGmZ6rV68yYMAA3nnnHXr06MGgQYMI+z35EB4ezquvvsqUKVNM9b///nvmz59P0aLGLxZ169alf//+afZhSM6ATTZdunTh008/5bfffmPEiBEsWrSI8uXLExwcTL9+/di0aVP6TmQwvOyhyR9+f9k913hm8UDMm08PY1q+0qJKWTwS83VxgPHvY+kaZ5w/rvEri1/J4pGYt3P9zmV+p8uWZV5fffo889CjR4/o27cvxYsXp1y5cvTo0SPF8dGjR9O1a1eqVq1qKvv+++8JCAhg5MiRfz/dM2VIiGdnZ0fBggWpUaMGHh4elC9fHgA3Nzfs7e0zoksRERF5Udnk7i07OzuWLl2Kh4dHqmO//vorUVFRKQKefzzd//cZnsLV1ZVlv0eP3333HQBBQUFMnz6d/PnzZ0SXIiIi8j/KxsYGBweHpx775ptvUmV+/nDy5En69OlDr169uHTp0vP7+X+N8hlmzpzJgQMHUpSFhIRQsGBBPvoo9e3JIiIiIn8XFxfH6dOnmfj3u6aBV155BRcXFxo1asTZs2cZOXIkO3bsSPN8GRL0ODg40Lp16xRllSpVolIlrbmLiIhkG9loI/PT/Pjjj89c1ipVqhSlShn/blW1atUIDQ0lMTERa2vrZ54ve89WRERELNb58+dN+4L/bunSpezcuRMw3vnl4uKSZsAD+g9HRURELFc2yfRcuHCBWbNmERgYiI2NDT4+PixYsICHDx+abkn/Q//+/fnyyy9p27Ytw4cP57vvviMhIYFp06Y9tx8FPSIiIpKlKleuzOrVq1OVf/zxx6nKvvzS+BfL8+fP/9Q2aVHQIyIiYqmySaYns1jWbEVERMRiKdMjIiJiqZTpERERETE/yvSIiIhYKmV6RERERMyPMj0iIiKWSpkeEREREfOjTI+IiIilUqZHRERExPwo0yMiImKplOkRERERMT8KekRERMQiaHlLRETEUml5S0RERMT8KNMjIiJiqZTpERERETE/yvSIiIhYKmV6RERERMyPMj0iIiKWSpkeEREREfOjTI+IiIilUqZHRERExPwo0yMiImKplOkRERERMT/K9IiIiFgqZXpEREREzI8yPSIiIpZKmR4RERER86OgR0RERCyClrdEREQslZa3RERERMyPMj0iIiKWSpkeEREREfOjTI+IiIilUqZHRERExPwo0yMiImKplOkRERERMT/K9IiIiFgqZXpEREREzI8yPSIiIpZKmR4RERER82NITk5OzupBiIiISBY4fTrz+nrttczr6xmU6RERERGLkK339Fx8eDGrh2C2KrlXMj4wGLJ2IObu90Rqifklsngg5uvG4BvGB3ovZ5zf38fFPiuWxQMxb7eG3Mr8TrWnR0RERMT8KOgRERERi5Ctl7dEREQkA2l5S0RERMT8KNMjIiJiqZTpERERETE/yvSIiIhYKmV6RERERMyPMj0iIiKWSpkeEREREfOjTI+IiIilUqZHRERExPwo0yMiImKplOkRERERMT/K9IiIiFgqZXpEREREMtfVq1dp1qwZa9asAWDUqFG0bdsWLy8vvLy8OHToUKo206dPp0uXLrz99tv8/PPPz+1DmR4RERFLlU0yPY8ePWLKlCnUqVMnRfmHH35I48aNn9rm5MmT3Lp1i/Xr13P9+nXGjBnD+vXr0+wne8xWRERELJadnR1Lly7Fw8Mj3W2OHz9Os2bNAChVqhQRERFER0en2UZBj4iIiGQpGxsbHBwcUpWvWbOGnj17MnToUEJDQ1McCw4OxtnZ2fTcxcWFhw8fpt3PyxmuiIiI/M/JJstbT9O+fXvy5s1LhQoV+Oqrr/jiiy8YP378M+snJyc/95z/eLZhYWH/tKmIiIhImurUqUOFChUAaNKkCVevXk1x3MPDg+DgYNPzBw8e4O7unuY5/3HQM3jw4H/aVERERLIDK6vM+3lB//3vf7lz5w4A/v7+lClTJsXxevXq4ePjA8DFixfx8PAgV65caZ4zzeWt48ePP/NYZGRkugYtIiIikpYLFy4wa9YsAgMDsbGxwcfHhx49ejBkyBBy5MiBo6MjM2bMAGDo0KHMmDGD6tWrU6lSJd5++20MBgMTJkx4bj+G5DQWwapVq0b58uWxsUkdG125coWTJ0/+P6b4fBcfXszQ81uySu6VjA8MhqwdiLn7/Z9Xifklsngg5uvG4BvGB3ovZ5zf38fFPiuWxQMxb7eG3Mr8TgMDM6+vQoUyr69nSDPT8/HHH3Pp0iXGjRuX6piXl1eGDUpERETkZUsz6OnUqRPW1tbExMSQM2fOFMdq166doQMTERGRDJaN797KCM+dbfv27bl1K3XK7YMPPsiQAYmIiIhkhHSFeDNnzszocYiIiEhmy8Z3b2WEdP1xwoIFC+Ll5cUrr7yCra2tqVy3rYuIiMj/inQFPYULF6Zw4cIZPRYRERHJTNkkA5NZ0hX0DBw4kLCwMO7evUuVKlVISkrCysIulIiIiPxvS1fQs2vXLubPn4+dnR07d+5kypQpVKpUiX//+98ZPT4RERHJKBaWwEjXbJcvX862bdtM/5vpyJEjWb9+fYYOTERERORlSlemJ3fu3OTIkcP03MHBIcWGZhEREfkfZGGZnnQFPc7OzmzZsoUnT55w8eJFvL29cXFxyeixiYiIiLw06QrxJk2axPnz54mJiWHcuHE8efKEqVOnZvTYRERERF6adG9k/vDDD5/7X7aLiIjI/xALW95K12yvXLlC+/btGTlyJKdOncroMYmIiIi8dOnK9EycOJGkpCT8/f3Zvn07c+fOpWnTprz11lvkyZMno8coIiIiGUGZnmdUtLKiaNGi5M+fn7i4OC5evEj37t3Zt29fRo5PRERE5KVIV6Zn69atbN68mfDwcDp37syKFSvIkycPkZGR9OjRg2bNmmX0OEVERORls7BMT7qCHj8/PwYPHkyNGjVMZVFRUTg5OdGrV68MG5yIiIjIy5KuoGfu3Llcu3aNH3/8EYC4uDimTp3K7t27efPNNzN0gCIiIpJBlOlJbdq0afj5+REcHEzRokW5c+cO7777bkaPTUREROSlSVeI9/PPP7N7927Kly/P5s2bWb58ObGxsRk9NhEREclIVlaZ95MNpGsUdnZ2AMTHx5OcnEzlypU5c+ZMhg5MRERE5GVK1/JWiRIlWLt2LTVq1KB3796UKFGCqKiojB6biIiIZKRskoHJLOkKeiZNmkRERAROTk7s2rWLkJAQ+vbtm9FjExEREXlp0hX0GAwG8ubNC0Dbtm0BWLlyJe+8806GDSwr3fr1FjNHzaRtl7a0frM1wfeD+WL6FyQkJmBjbcPg8YNxdnVOsw3AlQtXWLVwFTY2NtjY2jD448Hkcc7D2iVrufDTBZKTkqnVoBYdu3fMimlmrVmzoH59sLGBGTPg3j2YMwfi4+HJE/DyguDgP+s3bAgbN8LFi8bn58/DoEHGc0yfbmwXE2NsFx7+Zzs/P/D1hUmTMnd+WaxWoVosbL2QgNAAAK4EX2Hi4Ymm47UL12ZE3REkJifya9ivjNo3Cnsbe+Y2n4uboxv2NvYsOLmAAzcOMKf5HCp7VCb8sfG6fnX6Kw7ePMjVgVc5fe+06Zzdv+9OUnJSps4zW9B7OUPVLlybRa0XcTX0KmB8L084NMF03N7anulNp1PWtSxtv22boq29tT2+Xr58fvJzNl3aZCpvUKwBqzuupthnxQCo4FaB2c1nA+B73VjfYijTkz4HDhwwy6Dncexjln26jKqvVTWVrVu6jubtmlOvaT12b97NjvU76DmgZ5ptALZ/t51B4waRv1B+1i9fj+8OX2q+XpMLZy8wY/EMkpKSGOw1mEYtG6UKosxao0ZQuTLUrQsuLnD2LPj7Q8+ecOMGjB8P771n/AD5q8OHoXPnlGWffALdu8PVqzB6NPTta/wQAvjPf+D3/WiW6GTgSQZ4D3jqselNp9NtczeCooNY2HohDYs3JKdtTs4/OM+S00solLsQqzuu5sCNAwDMOTbH9PgPUXFRdN3cNcPnka3pvZwp/AP96b+r/1OPjak/hksPL1HWtWyqY4NqDTIF63+wt7ZnQM0B3I++byqb0WwGo/eN5uLDi8xvNR8HGwceJzx+uZOQbOEfh3jJyckvVN/Ly+ufdpWpbG1tGTt3LM5ufwYh73/0PrUb1QbAKa8TURFRz20DMHzqcPIXyk9ycjKhD0NxdXclZ86cxMXFER8XT3xcPFYGK+wd7DN+YtnJkSN//sIPD4ecOeHtt40fEgCFCsHdu+k7V3AwuLoaHzs7//mN2tUVunWDJUte7tjNRLtv2xEUHQRASGwIzg7O7ArYxZLTxutVIHcB7kXfy8oh/m/QeznLzf5hNj7XfVKVl3IuRWmX0hy4mTJY/6DmB3xz7hvikuIAcHN0I6dtTi48vEAyyQzaPciyAh7dvZU+BoPhmcfKly9PgwYNaNq0KU2aNKFJkyb89NNPNGnShKZNm/7TLjOFtY019vYpgxCHHA5YW1uTmJjI7i27qd+8/nPb/OHMiTMM7DqQ8LBwGno2xC2fG3Ub16Xvv/vS9999adGhBY45HTNsPtlSUhI8emR83KcPeHsbyzw94coVyJcP1qxJ3a5iRdi2DY4ehT/+65OhQ2HrVrh82bg8sHKlsXz2bBg7FhISMmVK2VFpl9IsbbuUDZ038HrR11Mci46LBsDd0Z36Retz8OZB07FNnTfxWcvPmHJkiqmsZ9WerO20ls9bfo6zgzG4t7e257OWn7Gx80b6VOuTCTPKhvRezhRlXMrwdduv2dR5U6r3ckx8zFPbjGswjqlHpqYoK5G3BBXcK+Ad4G0qK+xUmPDH4cxtMZfNb23m3Wr6G3TmLM3lrW7duj01uElOTiYgIOCZ7ZYuXcpXX31Fjx498PT0BKBLly6sX7/+/zncrJOYmMjnUz6nSvUqVK1R9fkNfle9dnWqfVuN1V+u5vs13/N609fxP+LPlxu+JCEhgTH9xlCvaT3yOufNwNFnU+3aGT8oWrQwPvfxgXLlYOZMGDUq5ZJAQIBxL8OGDVCyJBw8CKVLw4IF0LEjHDtm3EcxYAD89BMkJsLx41A2dcrbEtwMv8l8//nsCthF0TxFWffmOhqvbEx8UrypjmsOV75u9zXjD45PsQTw743/poJbBT71/JRWa1ux5fIWwmLD+CX4F/rV6MeQ2kOYcGgC0/2ms/XyVpKTk1n/7/WcDDzJ+Qfns2K6WU/v5QxzI+wGn/l/xs6rOymapyjfvfkdDVc2TPFe/rtOFTpx5t4Z7kTeSVE+vuH4FPuBAAwYKOJUhPd2vMfjhMds6bKFo7eOmvbDmbvkZ+cvXrpM7OqZ0gx6hgwZ8o9OWr9+fWrVqsXixYvZvn07o0aNSjMz9L/gi+lfUKBIAbq82yXdbU4cPkHthrUxGAzUaVSH9cvXk79QfspULIO9gz322FOsVDHu/HqHvK9ZWNDTooXx22vLlhAZCR06GL/lAmzeDBMnpqz/22/GDwmAX3+FoCDj0kHVqsYPCTBu8uzeHYoVgxo1jB8U7u5gbw/Xrz/9G7eZuh9zn10BuwC4HXGb4Jhg8uXKx91I41JLLrtcrGi/grnH53L09lEAKntUJuRRCPei7/FL8C9YG6xxzeHKsTvHTOfd9+s+pjY2fnted36dqfzYnWOUcytnmUGP3ssZ6n7MfXZe3QkY38sPHz0kf678qQKa/2vvzuOirvY/jr+GXQQFZNEUFXfTNDW33NEsKc0WlQzM2/JzI80ruS8UpqlZuV73JZfUNMubaa5XTY3qZqaW4oqgiKxuICIzvz+mpggz6zoMzryfj0ePO/P9fmfOOXNH5jPvc77z/a3QkFAqlqpIaEgo5bzKcSP/BiaTiaq+VZn22DQAAj0DPb8OZQAAIABJREFUWf3saqK3RBOfEW8p/L89/y01ytRwmKLH0dy26GnSpInl9pUrV8jKyrrN0QW5ubkxcOBAzpw5w/jx40n77dkL95hdW3bh4upC+Evhf+lxqxetJui+IEKqhxD/Yzz3VbyPcuXL8dmazzAajRiNRhJOJRB0X5CVel5MlSpl/ibboQNkZpq3xcSY10EcPAhNm5qnBn6rZ08oVw6mTjVPGQQFwblz5g+M2rXhp5+gcWPzt+jxv4m0X3gBKld2qA8JgCdrPklgyUDmfzcff09//D39CyzcHNVqFIsOLGJ3wm7Ltiblm1Deuzyxu2Px9/TH082TjJwMZj8+m4l7JpJ4OZFmFZoRnx5PFZ8qDGw2kNc2v4azwZlG9zVi04lNthiqbem9bHVda3YlsGQg876bR4BnAP6e/pb1aH8k6vMoy+3Xmr1G0uUk1v20jnU/rbNs//LFL+mx1vwl1svVi9Lupbmce5n7A+4vUNCLfbmjs7fGjx/PunXr8PPzsyxgNhgMbN++/ZbH79q1i+3bt/Pmm2+SnJxMfHw8Tk5OhIaGMnbsWNq2bXvXBnC3nTx6kiUzl3DxwkVcXFzYv3M/l7Iu4ermypioMQBUqFyBPtF9mDpuKlEjo0g6nVToMUMnDGXAiAHMmzoPZ2dn3NzdGDhmID6+PjzY5EFG9R8FQIfOHQgsF2jLIRe9Hj3A3//Xb7sAr74Ks2eb1y3k5JhP1wX48EP4xz9gwwZYuRKefNJ8Fku/fuZTe/v2hfnzzbczMkDXhAPMicy0x6bxSJVHcHV2ZfTO0XSp2YUrN66wO2E3T9V6iso+lelR1/xHf8OxDaz4YQWTHpnEmmfX4O7izrid4zBh4oODHzAjbAbX865zLe8aQ7cOJT0nneQryXwSbp7e2nZqGwdTDtp41Dag97LVbT21lemdpvNI1Z/fyztG82StJ7mSe4UvTn7B7LDZlPMuRxXfKqx6dhUfHvqQT499+pfaeHP3myx9aikmk4ldCbv4Ke0nK42m+CnKn5lwNjgXWVt/xGC6g9OwOnfuzNq1a/9wse7vPfPMM8ydOxd/f38iIiKYOHEiwcHBZGZm0qdPH9b89g/EbRxJPXJHx8lfVyegjvnGPT7tWOz9/M8rZFqIjTtiv04P+vlMKb2Xrefn9/Evv2sj1pHwWkKRt5lvyi+ytopD0XNHSU+lSpXuuOABuHnzJiVLlgTA29ub8uXLA+Dj4/OXT3UXERER63C0pOeOip6yZcvy/PPP06hRI5ydf+30oEGDbnn8Sy+9RNeuXWnRogU+Pj4MGDCABg0aEBcXR7ff/yCXiIiISBG4o6LHx8eH5s2b3/GTdunShdatW7Nv3z7OnTuHyWTC39+fCRMmEBTkYIt2RUREiilHu3TMHRU9UVFRZGZmkpSUxAMPPIDRaMTpT35d0cfHh7CwsLvSSREREZH/1R0VPRs3bmTatGm4ubnx2WefERsbS506dXj22Wet3T8RERGxEkdLeu7oMhSLFi3i008/xdfX/PPzw4YNu6d/XVlEREQczx0lPd7e3pQoUcJy38PDA1dXV6t1SkRERKzP0ZKeOyp6fH19Wb9+Pbm5uRw5coTPP/8cPz8/a/dNRERE5K65o+mtN954g0OHDnHt2jVGjx5Nbm4u48eP//MHioiISLFlNBmL7L/i4I6SnlKlSjF27Fhr90VERETEam5b9ISGht726uh/dO0tERERKf6KSwJTVG5b9CxZsgSA1atXExAQQLNmzcjPz2fv3r1kZ2cXRf9ERERE7orbFj0VK1YE4Mcff2Tx4sWW7XXq1KFPnz7W7ZmIiIhYlaMlPXe0kDk9PZ0vv/yS7Oxsrl+/zv79+zl//ry1+yYiIiJy19zRQuaYmBgmT55MfHw8JpOJ6tWrM2bMGGv3TUREROSuuaOip2HDhqxatcrafREREZEi5GjTW7cteiIjI2979tYHH3xw1zskIiIiYg23LXr69+8PwLZt2zAYDDRr1gyj0ci+ffsKXJZCRERE7j1Go5Iei+bNmwOwcOFCFixYYNnesWNH+vXrZ92eiYiIiNxFd7Sm58KFC5w+fZqQkBAAzp49S2JiolU7JiIiItalNT238Nprr9G7d29yc3MxGAw4OzszcuRIa/dNRERE5K65o6KnQ4cOdOjQgaysLEwmE76+vtbul4iIiFiZESU9FnPnzqVPnz68/vrrtzyLa/LkyVbrmIiIiMjddNuip1atWhiNRpo0aXLbU9dFRETk3qM1Pb/Rp08fDAYDJpMJoNDtZ5991vo9FBEREbkLblv0HD16tMD9yMhIli1bZtUOiYiISNFwtKTnji44+gtNcYmIiMi96o7O3vrFL1NbIiIicu8rTklPfHw8/fv3p3fv3kRERJCcnMyIESO4efMmLi4uTJkyhYCAAMvxcXFxDBo0iOrVqwNQo0aNP70Y+l8qepT0iIiIyN2WnZ1NbGys5UoQAO+//z7du3cnLCyMFStWsHjxYoYOHVrgcU2aNGH69Ol33M5ti542bdoUKHTS09Np27YtJpMJg8HAf/7znztuSERERIqX4pL0uLm5MX/+fObPn2/ZNm7cONzd3QHw9fXlyJEj/3M7ty16Vq5c+T83ICIiInI7Li4uuLgULEk8PT0ByM/PZ+XKlQwYMKDQ406cOEHfvn25dOkSUVFRtGjR4vbt3G5n+fLl/2q/RURERO6K/Px8hg4dSrNmzQpMfQFUrlyZqKgoOnXqRGJiIr169WLLli24ubn94fP9pTU9IiIiYj+Ky/TWHxkxYgSVKlUiKiqq0L6goCDCwsIAqFixIv7+/qSkpBAcHPyHz/eXTlkXERERKQobNmzA1dWVgQMH/uH+hQsXApCamkp6ejpBQUG3fU4lPSIiIg6quCQ9hw8fZtKkSZw7dw4XFxe++OIL0tPTcXd3JzIyEoCqVasSExPD4MGDmThxIqGhoURHR7N9+3by8vKIiYm57dQWqOgRERERG6tbt+4dX/Hhvffes9yeM2fOX2pHRY+IiIiDKi5JT1HRmh4RERFxCEp6REREHJSSHhERERE7pKRHRETEQSnpEREREbFDSnpEREQclJIeERERETukpEdERMRBKekRERERsUNKekRERByUkh4RERERO2QwmUwmW3dCREREit6BCweKrK0GZRsUWVt/RNNbIiIiDsrRpreKd9GTk2PrHtivEiXM/2sw2LYf9u6XIFWvs/X8/Br7TvK1cUfsV+awTAAMb+h9bE2mcZp4sbbiXfSIiIiI1RiNjpX0aCGziIiIOAQlPSIiIg7K0db0KOkRERERh6CkR0RExEEZUdIjIiIiYneU9IiIiDgorekRERERsUNKekRERByUkh4RERERO6SkR0RExEEp6RERERGxQ0p6REREHJSSHhERERE7pKJHREREHIKmt0RERByUprdERERE7JCSHhEREQelpEdERETEDinpERERcVBKekRERETskJIeERERB6WkR0RERMQOKekRERFxUEp6REREROyQkh4REREHpaRHRERExA4p6REREXFQSnpERERE7JCSHhEREQelpEdERETEDqnoEREREYeg6S0REREHpektERERETukpEdERMRBGY1KekRERETsjpIeERERB6U1PSIiIiJ2SEmPiIiIgzKipEdERETE7ijpERERcVBa0yMiIiJih5T0iIiIOCglPSIiIiJ2SEmPiIiIg1LSIyIiImKHVPSIiIg4KKPJWGT//Zn4+Hg6dOjA8uXLAUhOTiYyMpKePXsyaNAgbty4UegxEyZMoEePHoSHh/PDDz/8aRtWK3rS09O5du0aABkZGcTFxXH+/HlrNSciIiL3qOzsbGJjY2nevLll2/Tp0+nZsycrV66kUqVKrF27tsBjvv76axISEli9ejVvvfUWb7311p+2Y5WiZ8GCBURGRhIeHs6KFSvo1asXa9asoU+fPixbtswaTYqIiMg9ys3Njfnz5xMYGGjZFhcXR/v27QFo164d+/fvL/CY/fv306FDBwCqVq3KpUuXuHr16m3bscpC5m3btrFx40auX79O+/bt2bJlC15eXuTl5dGrVy8iIyOt0exdE3/iBP1fe43eERFEhIdbtu/Zt4+X+/fn2PffF3rMhClTOHjoEAZg5NCh1Ktbl5OnTzM2NhaDwUDlihWJGTUKFxcXVq1dy0cff4yrqyv/iIzk0Z//T3MokyZBq1bg4gITJ0JyMkyZAnl5kJsLkZGQlvbr8W3awEcfwZEj5vuHDsHAgebnmDDB/Lhr18yPy8r69XFffglbt8IbbxTt+IoLvc5FwsPFg30v7mPKvil8ePhDy/by3uVZ0GUBrk6u/JDyA//c8k9aBLdgSdclHE07CsCPqT8ybNswZoXN4sGyD5KRkwHAjLgZbDm1hdGtRtOyYksMBgMb4zcy/evpNhmjrZRwKcGSrksIKhmEh4sHsbtj2Xh8o2V/l5pdGN1qNLn5uaw6vIpZ38zixQYvElnv18+Zh+57CO+J3pRyL8WqZ1bhV8KPc1fO8dy65yjnVY5D/Q7x3+T/ApB6LZXua7sX+ThtpbgsZHZxccHFpWBJkpOTg5ubGwBlypQhNTW1wP60tDTq1Kljue/n50dqaipeXl5/3M5d7LOFwWDAYDDg7OyMk5OTpdOurq6YTCZrNHnXZOfkEPv22zRv0qTA9tzcXOYtXEhAQEChx3z97bcknD3L6g8+4OSpU4yMiWH1Bx/wzrRp/N+LL9KmZUtmzZvHpi1beLhZMxYtXcq/f47pXnjlFdq0bImHh0eRjK9YaNsW6taFhx8GPz84cADi4qBXLzh9GsaOhVdeMX9I/9auXdCtW8Ft774Lzz8P8fEwYgT06WP+oAd4+WX4+b3nkPQ6F5no5tFkXs8stD02NJaZX89k4/GNTHlkChW8KwCwN3EvvT/pXej4N3e9yRcnv7Dcr+1fm1aVWvHo8kcxYGD/y/tZdWQVF69dtNpYipvONTvz7flvmbJvChVLV2Rr5FZL0WPAwMxOM2k4ryHp2elsen4Tnxz9hEUHFrHowCIAWldqTfc65iJmVKtRbDm1hfe/ep8xrcdQP6g+F69d5Fj6MdotbWezMcqfu5Pa4U6Oscr0VpMmTQgPDyc8PJxevXoRERHB+PHjCQ8Pp0WLFtZo8q5xc3Vl/syZBP6uuJmzcCE9e/TAzaVwnbj/66/p0M78D6ZqlSpcunyZq1evknD2LPXq1gWgVfPm7N2/n3PnzlElJAR3d3fc3d2pVbMmBw8dsv7AipPdu3/9UM3KgpIlITzc/EEMUL48JCXd2XOlpUGZMubbvr6/phZlykDPnjB37t3t+71Er3ORqO5XnZr+NdlyckuB7QYMNK/QnE0nNgHw+tbXSbpyh6/3zy7nXsbd2R03Zzc8XDwwmozk5OXctb7fC9YcWcOUfVMACC4VTNLlX19Df09/sq5nkZadhgkT209vp0OVgsn52NZjid0VC0DnGp1Z8cMKAGJ3x/LN+W+KaBTFV3FayPx7np6eXL9+HYCUlJQCU18AgYGBpP0mqb548eItg4nfskrRM3jwYGJjY5k9ezb/93//x9SpU2nYsCFjxozh1VdftUaTd42Li0uh1OV0QgJH4+Pp1LHjLR+TlpaGr6+v5b6fry+p6enUqFaNXXv2ALBn/37SMjKoWLEi8cePk5GZybXsbA4cPEh6Rob1BlQcGY2QnW2+/dJL8Pnn5m2PPgrHjkFQEPy8er+A+++HTz+FPXvglynBwYPhk0/g6FHzFMySJebtkyfDqFFw82aRDKlY0utcJMaHjmfUjlGFtvt7+nP1xlUmhE5g0/ObGNt6rGVfzTI1Wfn0SjY9v4m2ldtatr/c8GU+Df+UhV0WWqZgPj32KT/0/YEf+v3A4gOLuXLjSlEMq9jZ++JeVj6zktc2v2bZlpqdire7N9X8quHi5EK7yu0I8gqy7H/ovodIvJxIyrUUAMp6laXvQ33Z3Xs3c56Yg5uzm2X7R90+Yu+Le+n5QM+iHZj8oYcffpgvvjAnn1u2bKFVq1YF9rdo0cKy/8iRIwQGBt52agusVPSkp6fzySefMHPmTOLi4ggODiYsLIw6derw5ptvWqNJq5o4ZQojhgy54+N/idiG/fOfbNqyhV6vvILJaMRkMuFTujSvDx5M/0GDGD5mDNWqVi32U35W06WL+cM4Ksp8/4svoGZN8wfr8OEFjz1+3Lxe5Mkn4YUXYOFCcHWFGTPgqaegVi3zupL+/c0fyvn58LtFbw5Lr7PV9KjTg6/Pfc3ZS2cL7TMYDJTzKsec/87h8ZWP80DQA3Ss0pFTmaeYvHcyPT/uSb+N/ZjRaQauTq6sPrKaN3a9wZOrnuRQyiGGtxhOpdKVeLz64zSY24BGcxvxjwb/wN/T3wYjtb0Wi1rQ5cMuLH+6YKH+wicvsKjLItb3WM/prNMYMFj2vdzwZZZ8v8Ry38PFg62nttJ6SWucDE683PBl0nPSGbNzDM+te44uH3Yhtl0sZb3KFtWwbK64JD2HDx8mMjKS9evX88EHHxAZGUlUVBSffPIJPXv2JCsri65duwLmYOX69es0bNiQOnXqEB4ezvjx4xk3btyfjtcqa3pef/112rdvT926dZk5cybffvstAwYMAODEiRPWaNJqUlJSOHXmDNEjRwJwMS2NiJdeYvnChZZjAgMCSEtPt9y/mJpKgL8/XiVLMnfGDMC8CPrizzFcp44dLanRP4cPp/x99xXVcIqPjh3NCcFjj8Hly9C1qzlJAFi3DmJiCh5//jysWWO+feoUXLhgnp6pVw/27TNv37rVvO6kUiV46CHzh3FAALi7w8mTt0417J1eZ6vqWLUjlX0q82i1R7nP+z5u3LzB+Svn2ZWwi/TsdBIvJ3Im6wwAuxN2U8u/FltObWH90fUAnMk6Q8rVFMp5l2N3wm7L8246sYmpHafSsFxD/pv8X3Ju5pBDDj9e/JHa/rXZc3aPLYZrEw3LNeTitYskXU7iYMpBXJxcCPAMIDXbvKh1d8JuWi9pDcCE9hMsrzdA20ptefXzX2cXEi8n8lXSVwBsObmFdpXbcfXGVUthlJ6Tzrfnv6WWfy0uXL1QNAMUAOrWrXvLs7sXL15caNt7771nuR0dHf2X2rFK0pOXl8fzzz9Pp06dWLp0KadOnWLmzJnAnS00Kk6CgoLY9tlnrFm2jDXLlhHo71+g4AFo0bw5X2zdCsCRn34iMCAAr5IlmT57Nv/Zbf5D9vGnnxLaujU3b94k8qWXyM3NJTUtjZ+OHaPu/fcX+bhsqlQp8xlETzwBmT8v/oyJgfr1zbebNjVPv/xWz57wS9oWFGT+79w584dy7drm7Y0bm5OK6Gho2BCaN4fYWFiwwKE+iC30OlvdSxteov0H7em4rCPLDi5jyr4p7ErYBUC+KZ+ErASq+FYB4MGyD3I84zjd7u9GVBNz6hZYMpDAkoEkX0lmadelVCpdCYCWFVvyU9pPnMo8xYNlH8SAARcnF+4PuL/Ah7ojaF2pNUOam9+TgSUD8XLzIi3713Ucn/f8nADPADxdPelcozPbTm0DoJxXOa7euEqeMc9y7I7TOyzTiY3KNeJY+jHaVm7L1I5TAfB09eTBsg8Snx5fRKOzveKS9BQVqyQ9Li4ufPHFF3Ts2BEnJyemTJnCiBEjGDNmjOUHC4urwz/+yKSpUzl3/rx5HFu3MuPdd/EpXbrQsYOHDWPiG2/Q8MEHqXP//YT36oXByYlxI0YA8ERYGENHjWLGnDk81LAhbVubv4089sgj9OjVC4PBwNjhwwudpmf3evQAf/9fEwWAV1+F2bPNa0NycsynRAN8+CH84x+wYQOsXGmednFzg379zKdP9+0L8+ebb2dkwIsv2mZMxZFeZ5t4ru5zXM69zMbjGxmxfQSzH5+Nk8GJH1N/ZPOJzZR0K8n8zvMJqxaGq7MrQ7YMIc+Yx/zv5rPoyUXk5OVwLe8aAz4fQFp2GjvP7GRzxGYAPvjhAxIvJ9p4hEVrzrdzWNhlIbt776aEawkGfD6AXvV7cSn3Ep8c/YT5381nS+QWTCYTE7+cSHqOOXUv512u0FluY3aOYcXTK3iz7ZukXEshdncsuTdzeaH+C+x7cR/OTs5M/HIi56/oh3TtlcFkheglOTmZadOmERMTU2BR8IYNG5g3bx6fffbZnT1RjmOdpVCkSpQw/6/BcPvj5H/zyz8vvc7W8/Nr7DvJ908OlL8rc5g5KTS8ofexNZnGFf1MyKxvZhVZWwMaDyiytv6IVaa3ypUrx9tvv13oLKguXbrg5+dnjSZFREREbssq8yorVqz4w30pKSnWaFJERET+ouKy1qaoWKXoWbJkCc2bNy/0Q0IANx349zxERETEdqxS9MyaNYvx48czevRoyyUofhEXF2eNJkVEROQvcrSkxypremrUqMHcuXNveVbS8N//GJqIiIhIEbDaudIlfjk76Hd+e0VUERERsR0lPSIiIiJ2SEWPiIiIOAQH+ylgERER+YWmt0RERETskJIeERERB2U0KukRERERsTtKekRERByU1vSIiIiI2CElPSIiIg7KiJIeEREREbujpEdERMRBaU2PiIiIiB1S0iMiIuKglPSIiIiI2CElPSIiIg5KSY+IiIiIHVLSIyIi4qCU9IiIiIjYIRU9IiIi4hA0vSUiIuKgNL0lIiIiYoeU9IiIiDgoJT0iIiIidkhJj4iIiINS0iMiIiJih5T0iIiIOCglPSIiIiJ2SEmPiIiIg1LSIyIiImKHlPSIiIg4KCU9IiIiInZISY+IiIiDUtIjIiIiYoeU9IiIiDgoJT0iIiIidkhFj4iIiDgETW+JiIg4KE1viYiIiNghJT0iIiIOymhU0iMiIiJid5T0iIiIOCit6RERERGxQ8U76SlRwtY9sH8mk6174Bj0Oltd5rBMW3fB7pnG6X1sb4wo6RERERGxO8U66Tlw4YCtu2C3GpRtAEC3j7rZuCf27aNuHwEQ/F6wjXtivxIHJwJQckJJG/fEfl0beQ2AkGkhNu6JfTs96HSRt6k1PSIiIiJ2qFgnPSIiImI9SnpERERE7JCSHhEREQelpEdERETEDinpERERcVCOlvSo6BERERGb+uijj9iwYYPl/uHDhzlw4NefralTpw4NGza03F+yZAnOzs5/uR0VPSIiIg6quCQ93bp1o1s38+/Gff3112zatKnAfi8vL5YtW/Y/t6M1PSIiIlJszJo1i/79+1vluVX0iIiISLHwww8/UK5cOQICAgpsv3HjBkOGDCE8PJzFixf/7efX9JaIiIiDKi7TW79Yu3YtTz31VKHtQ4cOpUuXLhgMBiIiInjooYd44IEH/vLzK+kRERGRYiEuLo4GDRoU2v7cc89RsmRJPD09adasGfHx8X/r+VX0iIiIOCijyVhk//2ZlJQUSpYsiZubW4Htp06dYsiQIZhMJm7evMl3331H9erV/9Z4Nb0lIiIiNpeamoqfn5/l/rx582jcuDENGjSgbNmyPPvsszg5OREaGkq9evX+VhsqekRERBxUcVrTU7duXRYsWGC5/3//93+W26+//vpdaUPTWyIiIuIQlPSIiIg4qOKU9BQFJT0iIiLiEJT0iIiIOCglPSIiIiJ2SEmPiIiIg1LSIyIiImKHlPSIiIg4KCU9IiIiInZISY+IiIiDUtIjIiIiYodU9IiIiIhD0PSWiIiIgzIaNb0lIiIiYneU9IiIiDgoLWQWERERsUNKekRERByUESU9IiIiInZHSY+IiIiD0poeERERETukpEdERMRBKekRERERsUNKekRERByUkh4RERERO6SkR0RExEEp6RERERGxQ0p6REREHJSSHhERERE7pKJHREREHIKmt0RERByUprdERERE7JCSHhEREQelpOcuyc3Ntdw+efIkmzdv5tixY9ZqTkREROS2rJL0zJ49m5MnTzJ16lSWLl3Kxx9/TKNGjVi6dCktWrQgKirKGs3eNYmnEpkyagph3cJ47OnHANi0dhPLZy9n4WcL8fD0KHC80WhkwdQFJJ5OxMXVhZf/+TLlK5Un/nA8K+aswNnZGVc3VwaMGkApn1IknEhg7uS5ADRq0YhnXnimyMdYXIRWDqV1pdaW+1X9qhK5PtJy/+EKD9O5ZmeMJiOHLx7mw8Mf4mRwot9D/SjrVRYngxPLDi7jaPpRy2M6VOnAU7WeYsDnA4p0LMVJswrNmPP4HOLT4wE4mnaUsf8Za9nfsmJLhrUYRr4xn51ndjItbho96vTgmdq/vhfrBdWj1qxaeLt5MytsFj4ePly4eoGoTVHk5ecxPnQ8tfxr4erkyopDK1h9ZHWRj7M48HDx4JtXvmHSl5NYfmh5of1vtH2DJuWb0GlFJ0q4lGBu57kElgzEw9mDt/e+zeYTmynvXZ4FXRbg7OTMhasXeHnDy9zIv2F5jiVPLiE3P5c+n/UpyqEVC03LN2VW2CyOZxwH4FjaMWJ2xVj2N6vQjKEPDyXflM+pzFMM3zYcEyZGtx5Ng7INMJlMvLn7TX5I+YFZYbPwK+EHgI+HDweSDzByx0jLc33U7SO+PPsl0+KmFekYbcnRkh6rFD07duxg7dq1AHzxxResXr0aDw8PjEYjPXv2LNZFz/Wc6yyetpi6Detatu3evJtLmZfw9fe95WO+/fJbsq9lEzs7lgvnLrB0xlKGvT2MjWs20n9kf4LuC2LtkrVs//d2nop8innvzOOV6FeoVK0SM2Nnkns9F3cP96IaYrGy48wOdpzZAcD9/vfTPLi5ZZ+bsxvP13ueIVuGcP3mdSaETmCP9x6qlalG7s1cxuwcQ4VSFRjQeAAjto8AoJR7KZqWb2qTsRQ3X537ir6f9b3lvjfavkHExxFcuHqBtd3X8vnxz1l9ZLWlcGlWvhlP1HgCgFebvsruhN0sOLCAQU0Hcb///bg6u5JnzOOZNc/g6erJ3hf3suaJDLYVAAAYFUlEQVTIGkyYimx8xcWwFsPIzMm85b5a/rVoEdyCPGMeAGHVwziQfID3vnqP4FLB/Pu5f7P5xGbGtB7DvP/OY/3R9cS0iaFX/V4s+G4BYP5iEOIbwtG0o7dswxF8fe5r+n/e/5b7JrSfQM91Pblw9QKzwmbRpnIbcvJyqOxTmWfWPENV36pMfmQyz6x5psAXoUkdJhUo1MPrhOPq7Gr1sYhtWWV6y2QycfSo+R9opUqVuHHD/I3l6tWrGI3Fu6p0dXVl+OThBQqcxq0bE/5KOBhu/ZgLSReoVrsaAGXLlyXtQhrGfCOD3xxM0H1BmEwmMlIzKBNQhqyMLHJzcgmpEYKTkxMDxw102ILn9569/1nW/bjOcv9G/g1LwQNw5cYVvNy92JOwh6UHlwJwOfcyXm5elsdE1ot02MThTlUsXZGs61kkX03GhIkdp3fQomKLAscMajbI8m23Q0gH1h9dD8C0uGl8n/I935z/hpj/xADg7+lP1vUshyx4apSpQS3/Wmw+ufmW+ye2n8gbu96w3F/30zre++o9ACqUqsD5K+cBaFWpFRuPbwTg8xOf065yO8Bc+A9tOZRJeydZcxj3tC4fduHC1QsApOek4+vhy8PBD7P15FYATmaepLR76QJ/J6r4VKGUeykOphwEwNfDly41u/DhoQ+LfgA2ZjQZi+y/4sAqRc9bb73F2LFj6dy5M2fPnqVLly68/PLL9OnTh9GjR1ujybvG2cUZN3e3AttKeJa47WOCqwRz8OuDGPONnD97novJF7l86TIA38d9z+CIwVzKvETLji1JvZBKSe+SzJ44m7EDxvL5R59bbSz3kqq+VUnPSScrN6vA9l8KnoqlKhJYMpDj6cfJN+Vbvjk/Xv1xvjz7JQD3B9zPjfwbnMg4UbSdL6aq+1VnUZdFrOu+jlYVW1m2B3gGkJGTYbmflp1GUMkgy/36QfVJvpJManaq+fiSAUTUi2Bd93VMbD8RN+df/3386/F/8XGPjxm9o3j/u7aWie0nMnzb8Fvui3gggi/PfknCpYRC+7b32s7iJxczdOtQAEq6lrRMZ6VeS6WsV1kAoh+OZsF3C7iSe8VKI7g3VPOrxvzO81nTbQ0tK7YssO/qjauA+X3dqmIrdp7ZWeg9npGTQYBngOV+7wa9LV+cAIa3HM47+9/hpvGmlUcitmaV6a1atWqxZs0a0tPTOXfuHCaTCX9/f8qXL2+N5myuQbMGxB+OJ2ZgDBWrVKR8pfL88qX3waYP8t7y91g5dyWfrviUug3rknohlei3onFzd2NM/zE88NADBIcE23YQNtY+pD07z+y85b6yXmXNycNX08g35Vu2P1r1Uar4VuHtL9/GxeBCjzo9mLx3clF1uVg7k3mG9796n3/H/5tKpSux+tnVtFrcylIs/pbBUDDCDK8bzpof11jue7h4sOfsHqbFTWNSh0k8V/c5ywdGv439KO9dnuVPL+eJlU9wLe+adQdWjPSs25O4c3G3LGp8PXyJqB/BEyuf4D7v+wrtb/9Be+oF1mPhkwtpuqDgdOwv/39U9a1Kw7INmbBnQoGi1dGcyTrDtLhpbDy+kYqlK7LymZW0W9KuwHu5TIkyLOiygLE7x5J1Pavwk/zmLe7q5Erj+xozdqd5jVuT+5pgNBn5Lvk7QnxCrD2cYqe4JDBFxSpFz65du2jTpg1lypTB2dmZGTNmEB8fT40aNRgwYAB+fn7WaNamerzcw3J74HMDKeVbiq93f02T1k0wGAw0bdOUtYvX0qJDCypUroB3aW8Aaj1Qi6TTSQ5f9NQJrMOiA4sKbfcr4cfQh4cy4+sZnLl0xrI9tHIoD933EJP3TibflE81v2r4ePgwspV5UaKvhy+vNX2N9+PeL6ohFCsXrl3g3/H/BiDhUgKp2eb0IPFyIinXUgp86y3rVdYyPQDQvEJzywcCwPkr5/ku+TsAdifs5uHgh6nqWxWDwcCJjBOcu3KOs5fOUt2vOt+nfF9EI7S9R6s9SohPCJ2qdaK8d3ly83M5d+UcO8/spE3lNvh7+rM1civuzu6E+IYwqcMkPjz8IanXUjl35Rw/XPwBZydnAjwDuHrjKh4uHly/eZ37vO8j+Woyj1V7jODSwex8YSfe7t74e/ozuNlgy/SYo0i5lmKZ+jt76Sxp19II8goi6XISAF5uXix+cjHv7H+HPWf3WB7j7+lveY6gkkFcvHYRgKYVmnLwwkHLvkeqPsIDgQ/wcfeP8Svhh5uzG2cvnbVM6Yp9scr01sKFCy23Y2NjCQoKIiYmhipVqjBy5MjbPPLelHAigTlvzwHM01kh1c3rddYuWcuZ42cAOPHjCcpVLEdguUBysnO4etm8vunMiTPcV7HwN0FH4uvhy/Wb17lpKhwt93uoH/O/m8/prNOWbYElA3mk6iNM2TfF8m3vRMYJBm0exKgdoxi1YxSZ1zMdtuAB6FqrK30amc/0CfAMwN/T31LYJF1OwsvdiwqlKuBscKZDSAd2J+wGzB8O1/KuFfgWvTdxL80rmBeYPxD0ACczT1LdrzrDWgwDzElQVd+qnL18tiiHaHMvfPICrZe0pt3Sdiw5uIRJX06ypJWfHP2Eh+Y9RLul7QhfF873F75n2LZhtAxuyaCmgwDz+9jL1Yu07DR2ntlJ15pdAXiy5pNsPbmVWd/MoumCprRb2o7BmwfzxYkvHK7gAfPr8UrDVwDz+jF/T39SrqZY9o9qNYpFBxZZ3sMAe87uIax6GAB1AuqQci3FkkLWC6rHT2k/WY59a89bPPHhEzy95mlmfD2D1UdWO1TB42hreqz+44RpaWlMnToVgKpVq7J5860X/BUXp46dYtnsZaReSMXF2YW4XXHUe6geP3z7A5cyLjFx6ERq1KnB8/2eZ9ob0+g3vB/BVYIxmoyM6jMKVzdXosaYz07rM7QPC99biLOzeZ3QgFHmMwd6RfVi4tCJGAwG6jepT6VqlWw5ZJvz9fDl0vVLlvtda3blx9QfuXLjCrX9a9Ojzq8p2mfxn1G9THW83bwZ2fLXAnr87vG3LJoc1daTW5kRNoOOVTvi6uTKyO0j6VqrK1dyr7D55GZGbR/FzE4zAfh3/L8tRWVgyUDSs9MLPNc7+95hRqcZRD8cTWp2KtO+mkbOzRweDn6Y9T3W4+bsxqxvZhVYQ+GoIh6I4FLuJUvK9nsLDizgX4//iy2RWyjhUoLBXwzGhIm3dr/F/C7zebHhiyReSmTFoRVF3PPia9upbUx7bBqPVHkEV2dXRu8cTZeaXbhy4wq7E3bzVK2nqOxTmR51zX8nNhzbwIeHP+TQxUOs7bYWI0bG7Rxneb5Az0C+yfrGVsMRGzOYTKa7fspF586diY6OxmQysXz5cqKjo6lVqxaJiYkMHjzYcjr7nzlw4cDd7pr8rEHZBgB0+6ibjXti3z7q9hEAwe859vSlNSUOTgSg5ISSNu6J/bo20pyShExzvDUvRen0oNN/ftBdVn9O/SJr62Dfg39+kJVZJempW7cumzdvxmg0EhAQQFaWeWHZlClTiIiIsEaTIiIiIrdllTU9oaGhfPXVV/znP//BaDRSt675h/6mT5/Oxx9/bI0mRURE5C9ytDU9Vil65s2bx/r169m/fz8NGzbkpZde4soV8+9MWGE2TURERORPWaXocXZ2xsfHBycnJ3r06MErr7zCSy+9REZGRqHfBBEREREpClZZ09OwYUP69OnDtGnT8PDwoEOHDri7u9O7d2/L+h4RERGxreIy7VRUrFL0DB06lLi4ONzdf72mVKtWrWjQoAGff67LLoiIiEjRs9rv9DRtWvhK115eXnTv3t1aTYqIiMhfUNwvAn63WWVNj4iIiEhxY/VfZBYREZHiyYiSHhERERG7o6RHRETEQTna2VtKekRERMQhKOkRERFxUEp6REREROyQkh4REREHpaRHRERExA4p6REREXFQSnpERERE7JCSHhEREQdVXJKeuLg4Bg0aRPXq1QGoUaMGY8aMsezft28f7777Ls7OzrRu3ZoBAwb8rXZU9IiIiIjNNWnShOnTp99y3/jx41m4cCFBQUFERETw6KOPUq1atb/chqa3REREpNhKTEykdOnSlCtXDicnJ9q0acP+/fv/1nMp6REREXFQxWV6C+DEiRP07duXS5cuERUVRYsWLQBITU3Fz8/Pcpyfnx+JiYl/qw0VPSIiImJTlStXJioqik6dOpGYmEivXr3YsmULbm5ud7UdFT0iIiIOqrgkPUFBQYSFhQFQsWJF/P39SUlJITg4mMDAQNLS0izHpqSkEBgY+Lfa0ZoeERERsakNGzawcOFCwDydlZ6eTlBQEAAVKlTg6tWrJCUlcfPmTXbu3GmZ+vqrlPSIiIg4qOKS9ISGhhIdHc327dvJy8sjJiaGzz77DG9vbx555BFiYmIYMmQIAGFhYYSEhPytdlT0iIiIiE15eXkxZ86cP9zfuHFjVq9e/T+3o6JHRETEQRWXpKeoaE2PiIiIOAQlPSIiIg5KSY+IiIiIHVLSIyIi4qCU9IiIiIjYISU9IiIiDkpJj4iIiIgdUtIjIiLioJT0iIiIiNghFT0iIiLiEDS9JSIi4qA0vSUiIiJih5T0iIiIOCglPSIiIiJ2SEmPiIiIg1LSIyIiImKHlPSIiIg4KCU9IiIiInZISY+IiIiDUtIjIiIiYoeU9IiIiDgoR0t6DCaTyWTrToiIiEjRM7xhKLK2TONsX26o6BERERGHoDU9IiIi4hBU9IiIiIhDUNEjIiIiDkFFj4iIiDgEFT0iIiLiEFT0iIiIiENQ0SMiIiIOQb/I/D+Ij4+nf//+9O7dm4iICPLy8hg+fDgJCQmULFmS6dOnU7p0aVt3856Vk5PD8OHDSU9PJzc3l/79+1OrVi1GjBjBzZs3cXFxYcqUKQQEBNi6q/e0DRs2sGDBAlxcXBg4cCBt27YFYM+ePbz88sscO3bMth28h/3+b0RycvIt37/vvfcecXFxmEwmOnTowCuvvGLrrt8zJk+ezH//+19u3rxJnz592LFjB0eOHMHHxweAl156ibZt23L06FFGjhwJQPv27RkwYIAtuy02oqLnb8rOziY2NpbmzZtbtq1ZswZfX1+mTp3K6tWr+fbbb2nfvr0Ne3lv27lzJ3Xr1uWVV17h3LlzvPjiizz44IN0796dsLAwVqxYweLFixk6dKitu3rPyszMZNasWaxbt47s7GxmzJhB27Ztyc3NZd68eSoo/we3+hvx/vvvF3r/du3albi4OFatWoXRaOTxxx+na9eueu3vwFdffcXx48dZvXo1mZmZPPXUUzRr1ox//vOftGvXrsCxY8aMITY2ltq1axMdHU1OTg4lSpSwUc/FVlT0/E1ubm7Mnz+f+fPnW7bt3LmTgQMHAtCjRw9bdc1uhIWFWW4nJycTFBTEuHHjcHd3B8DX15cjR47Yqnt2Yf/+/TRv3hwvLy+8vLyIjY0FYM6cOfTs2ZMpU6bYuIf3rlv9jbjV+9fb25vc3Fxu3LhBfn4+Tk5O+jC+Q40bN6ZevXoAlCpVipycHPLz8wsdl5aWRnZ2NnXq1AHg3XffLdJ+SvGhNT1/k4uLCx4eHgW2nTt3jt27dxMZGcngwYPJysqyUe/sS3h4ONHR0YwcORJPT0+cnZ3Jz89n5cqVdO7c2dbdu6clJSVx/fp1+vbtS8+ePdm/fz+nT5/m6NGjdOrUydbdu6fd6m/Erd6/5cqV47HHHqNdu3a0a9eO8PBwvLy8bNTre4uzszOenp4ArF27ltatW+Ps7Mzy5cvp1asXgwcPJiMjg3PnzlG6dGmGDx9OeHg4S5YssW3HxWaU9NxFJpOJkJAQoqKimD17NnPnzmXYsGG27tY9b9WqVfz000+8/vrrbNiwAaPRyNChQ2nWrFmBqQP5e7Kyspg5cybnz5+nV69e1KhRg9GjR9u6W3YrPz+/wPs3MTGRrVu3sm3bNm7evEl4eDhhYWGUKVPG1l29Z2zbto21a9eyaNEiDh8+jI+PD7Vr12bevHnMnDmTLl26kJSUxKxZs/Dw8KBHjx60aNGC6tWr27rrUsSU9NxF/v7+NG7cGICWLVty4sQJG/fo3nb48GGSk5MBqF27Nvn5+WRkZDBixAgqVapEVFSUjXt47ytTpgwNGjTAxcWFihUr4uTkxIkTJ4iOjqZ79+5cvHiRiIgIW3fTrvz+/Xvo0CHq169PiRIl8Pb2pmbNmsTHx9u4l/eOPXv2MGfOHObPn4+3tzfNmzendu3aAISGhhIfH0+ZMmWoXr06vr6+lChRgkaNGnH8+HEb91xsQUXPXdS6dWv27NkDwJEjRwgJCbFxj+5t3377LYsWLQJ+nZPfu3cvrq6ulrVT8r9p2bIlX331FUajkczMTEwmE9u2bWPNmjWsWbOGwMBAli9fbutu2o0NGzYUev9WrFiRw4cPYzQaycvLIz4+nuDgYBv28t5x5coVJk+ezNy5cy1na7366qskJiYCEBcXR/Xq1QkODubatWtkZWVhNBr56aefqFKlii27LjZiMJlMJlt34l50+PBhJk2axLlz53BxcSEoKIh33nmHt956i9TUVDw9PZk0aRL+/v627uo96/r164waNYrk5GSuX79OVFQU8+bNIzc317LmoWrVqsTExNi2o/e4VatWsXbtWgD69etX4IzD0NBQduzYYauu3dNu9TciPT0dd3f3Qu/f6dOns2/fPgAee+wxevfubcOe3ztWr17NjBkzCnzBfPrpp1m+fDklSpTA09OTiRMnUqZMGQ4ePMj48eMxGAy0atWKV1991YY9F1tR0SMiIiIOQdNbIiIi4hBU9IiIiIhDUNEjIiIiDkFFj4iIiDgEFT0iIiLiEFT0iBQjSUlJtG7dutD2mjVrsnPnTv71r38V2rdv3z4iIyMLbU9ISCA0NPRv9SMuLo7nnnvubz327zh27BgRERFERETQvXt3XVNNRKxCl6EQuUe0atWq0JWj7cXIkSOJjo6mefPmbN++nbfffptly5bZulsiYmdU9IjcI9avX09cXBzvvPMO27Zt47333qNs2bJUqlTJcsx3333HuHHj8PPzs1xRGuDSpUuMGzeOjIwMrl69yj/+8Q86d+7MjBkzyMrK4sKFCyQkJNC0aVPGjBnzh30wGo2MGzeOU6dOcePGDerXr8/o0aMZMmQILVq04OmnnwbMVxOvUaMGTzzxxB+2m5SUxPnz5xk2bBhLliyx/GBfmTJldLFeEbEKFT0i96A333yTxYsXU7VqVcaPH2/ZPnnyZKKjo2nTpg2LFy+2bH///fdp1aoVzzzzDNnZ2Tz55JO0aNECgB9//JHly5eTl5dH8+bNb3uJj0uXLlGzZk1iY2MB868Hx8fHEx4ezvTp03n66afJz89nz549REdH8+677/5hu0lJSSxfvhyDwWB5fpPJxPz583nmmWfu6uslIgIqekSKnYyMjFuu0flFZmYmubm5VK1aFYBmzZpx7NgxwLw2plGjRpbtv0wRxcXFcejQIT755BMAXFxcSEpKAqBRo0Y4Ozvj7OyMr68vly5d+sO2S5UqRXJyMj169MDNzY3U1FQyMzNp2rQpGRkZJCYmkpSURKNGjfD29r5tu/Xr1y9Q8OTl5TF8+HBKlSrFCy+88LdeOxGR21HRI1LM+Pn5FVrPUrNmTcttk8lUoFjIz88vcKyTk1Oh7W5ubowbN44HHnigwLG7du3C2dm5wLbbXZlm48aNHDp0iBUrVuDi4mKZzgLo1q0bGzZsICUlhW7duv1pu66urgXG8Oqrr1KtWjWGDBlSYHwiIneLzt4Sucf4+vri7OzMmTNnACwXqgTzBSy///77QtsbNWrEpk2bAPOFXGNiYrh58+Zfbjs9PZ2QkBBcXFw4fPgwZ8+e5caNGwB07dqV7du3c/ToUZo0afKX2p09ezYhISFER0er4BERq1HSI3KPMRgMjBw5kgEDBhAcHFxgIfPrr79ObGws5cqV4/7777dsj4qKYvTo0Tz33HPcuHGDHj164OJy+3/+8fHxBabZQkNDeeyxx+jbty8RERE0bNiQF198kfHjx7NmzRp8fHwIDg4usID6TttduHAhNWrUKNDekiVLCqVQIiL/C11lXUTuisuXLxMeHs6KFSvw9fW1dXdERArR9JaI/M/Wrl3L888/z2uvvaaCR0SKLSU9IiIi4hCU9IiIiIhDUNEjIiIiDkFFj4iIiDgEFT0iIiLiEFT0iIiIiEP4fwoZFzWegEtsAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tahapan 6**.\n",
        "Percobaan ke-4 melanjutkan proses pencarian komposisi jumlah hidden neuron pada setiap hidden layer, namun pada percobaan ini akan dipertimbangkan jumlah hidden layer sejumlah 3. Percobaan pencarian jumlah hidden neuron masih dengan lingkup pencarian yang sama (16, 32, 64, 128, 256) dan penggunaan Sigmoid Activation Function di setiap hidden layer."
      ],
      "metadata": {
        "id": "5KXssytw6GPn"
      }
    }
  ]
}